I0726 14:13:28.310228 31263 caffe.cpp:217] Using GPUs 0
I0726 14:13:28.315888 31263 caffe.cpp:222] GPU 0: GeForce GTX 1080
I0726 14:13:29.102610 31263 solver.cpp:63] Initializing solver from parameters: 
train_net: "models/VGGNet/SHOPPE_2017/SSD_300x300/train.prototxt"
test_net: "models/VGGNet/SHOPPE_2017/SSD_300x300/test.prototxt"
test_iter: 13
test_interval: 1000
base_lr: 0.001
display: 10
max_iter: 120000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 5e-05
snapshot: 80000
snapshot_prefix: "models/VGGNet/SHOPPE_2017/SSD_300x300/VGG_SHOPPE_2017_SSD_300x300"
solver_mode: GPU
device_id: 0
debug_info: false
train_state {
  level: 0
  stage: ""
}
snapshot_after_train: true
test_initialization: false
average_loss: 10
stepvalue: 80000
stepvalue: 100000
stepvalue: 120000
iter_size: 4
type: "SGD"
eval_type: "detection"
ap_version: "11point"
I0726 14:13:29.102816 31263 solver.cpp:96] Creating training net from train_net file: models/VGGNet/SHOPPE_2017/SSD_300x300/train.prototxt
I0726 14:13:29.105240 31263 net.cpp:58] Initializing net from parameters: 
name: "VGG_SHOPPE_2017_SSD_300x300_train"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4
    }
  }
  data_param {
    source: "SHOPPE_2017/lmdb/SHOPPE_2017_trainval_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.1
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.3
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.7
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        min_jaccard_overlap: 0.9
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.3
        max_scale: 1
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2
      }
      sample_constraint {
        max_jaccard_overlap: 1
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/SHOPPE_2017/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 236
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 354
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 354
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 354
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 236
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 236
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1
    num_classes: 59
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
  }
}
I0726 14:13:29.105623 31263 layer_factory.hpp:77] Creating layer data
I0726 14:13:29.106147 31263 net.cpp:100] Creating Layer data
I0726 14:13:29.106158 31263 net.cpp:408] data -> data
I0726 14:13:29.106217 31263 net.cpp:408] data -> label
I0726 14:13:29.106834 31269 db_lmdb.cpp:35] Opened lmdb SHOPPE_2017/lmdb/SHOPPE_2017_trainval_lmdb
I0726 14:13:31.056650 31263 annotated_data_layer.cpp:62] output data size: 8,3,300,300
I0726 14:13:31.070686 31263 net.cpp:150] Setting up data
I0726 14:13:31.070713 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070718 31263 net.cpp:157] Top shape: 1 1 9 8 (72)
I0726 14:13:31.070742 31263 net.cpp:165] Memory required for data: 8640288
I0726 14:13:31.070752 31263 layer_factory.hpp:77] Creating layer data_data_0_split
I0726 14:13:31.070767 31263 net.cpp:100] Creating Layer data_data_0_split
I0726 14:13:31.070773 31263 net.cpp:434] data_data_0_split <- data
I0726 14:13:31.070807 31263 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0726 14:13:31.070816 31263 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0726 14:13:31.070822 31263 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0726 14:13:31.070827 31263 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0726 14:13:31.070830 31263 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0726 14:13:31.070833 31263 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0726 14:13:31.070837 31263 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0726 14:13:31.070912 31263 net.cpp:150] Setting up data_data_0_split
I0726 14:13:31.070917 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070920 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070922 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070924 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070927 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070930 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070931 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.070933 31263 net.cpp:165] Memory required for data: 69120288
I0726 14:13:31.070935 31263 layer_factory.hpp:77] Creating layer conv1_1
I0726 14:13:31.070947 31263 net.cpp:100] Creating Layer conv1_1
I0726 14:13:31.070950 31263 net.cpp:434] conv1_1 <- data_data_0_split_0
I0726 14:13:31.070953 31263 net.cpp:408] conv1_1 -> conv1_1
I0726 14:13:31.072260 31263 net.cpp:150] Setting up conv1_1
I0726 14:13:31.072271 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.072274 31263 net.cpp:165] Memory required for data: 253440288
I0726 14:13:31.072288 31263 layer_factory.hpp:77] Creating layer relu1_1
I0726 14:13:31.072295 31263 net.cpp:100] Creating Layer relu1_1
I0726 14:13:31.072298 31263 net.cpp:434] relu1_1 <- conv1_1
I0726 14:13:31.072301 31263 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0726 14:13:31.072311 31263 net.cpp:150] Setting up relu1_1
I0726 14:13:31.072315 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.072317 31263 net.cpp:165] Memory required for data: 437760288
I0726 14:13:31.072319 31263 layer_factory.hpp:77] Creating layer conv1_2
I0726 14:13:31.072325 31263 net.cpp:100] Creating Layer conv1_2
I0726 14:13:31.072329 31263 net.cpp:434] conv1_2 <- conv1_1
I0726 14:13:31.072332 31263 net.cpp:408] conv1_2 -> conv1_2
I0726 14:13:31.073266 31263 net.cpp:150] Setting up conv1_2
I0726 14:13:31.073274 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.073277 31263 net.cpp:165] Memory required for data: 622080288
I0726 14:13:31.073282 31263 layer_factory.hpp:77] Creating layer relu1_2
I0726 14:13:31.073287 31263 net.cpp:100] Creating Layer relu1_2
I0726 14:13:31.073289 31263 net.cpp:434] relu1_2 <- conv1_2
I0726 14:13:31.073295 31263 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0726 14:13:31.073299 31263 net.cpp:150] Setting up relu1_2
I0726 14:13:31.073302 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.073303 31263 net.cpp:165] Memory required for data: 806400288
I0726 14:13:31.073305 31263 layer_factory.hpp:77] Creating layer pool1
I0726 14:13:31.073312 31263 net.cpp:100] Creating Layer pool1
I0726 14:13:31.073313 31263 net.cpp:434] pool1 <- conv1_2
I0726 14:13:31.073317 31263 net.cpp:408] pool1 -> pool1
I0726 14:13:31.073348 31263 net.cpp:150] Setting up pool1
I0726 14:13:31.073352 31263 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0726 14:13:31.073354 31263 net.cpp:165] Memory required for data: 852480288
I0726 14:13:31.073356 31263 layer_factory.hpp:77] Creating layer conv2_1
I0726 14:13:31.073361 31263 net.cpp:100] Creating Layer conv2_1
I0726 14:13:31.073364 31263 net.cpp:434] conv2_1 <- pool1
I0726 14:13:31.073385 31263 net.cpp:408] conv2_1 -> conv2_1
I0726 14:13:31.073997 31263 net.cpp:150] Setting up conv2_1
I0726 14:13:31.074002 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.074003 31263 net.cpp:165] Memory required for data: 944640288
I0726 14:13:31.074008 31263 layer_factory.hpp:77] Creating layer relu2_1
I0726 14:13:31.074012 31263 net.cpp:100] Creating Layer relu2_1
I0726 14:13:31.074018 31263 net.cpp:434] relu2_1 <- conv2_1
I0726 14:13:31.074020 31263 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0726 14:13:31.074023 31263 net.cpp:150] Setting up relu2_1
I0726 14:13:31.074025 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.074028 31263 net.cpp:165] Memory required for data: 1036800288
I0726 14:13:31.074029 31263 layer_factory.hpp:77] Creating layer conv2_2
I0726 14:13:31.074034 31263 net.cpp:100] Creating Layer conv2_2
I0726 14:13:31.074039 31263 net.cpp:434] conv2_2 <- conv2_1
I0726 14:13:31.074051 31263 net.cpp:408] conv2_2 -> conv2_2
I0726 14:13:31.075165 31263 net.cpp:150] Setting up conv2_2
I0726 14:13:31.075171 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.075175 31263 net.cpp:165] Memory required for data: 1128960288
I0726 14:13:31.075181 31263 layer_factory.hpp:77] Creating layer relu2_2
I0726 14:13:31.075186 31263 net.cpp:100] Creating Layer relu2_2
I0726 14:13:31.075191 31263 net.cpp:434] relu2_2 <- conv2_2
I0726 14:13:31.075194 31263 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0726 14:13:31.075201 31263 net.cpp:150] Setting up relu2_2
I0726 14:13:31.075232 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.075237 31263 net.cpp:165] Memory required for data: 1221120288
I0726 14:13:31.075239 31263 layer_factory.hpp:77] Creating layer pool2
I0726 14:13:31.075245 31263 net.cpp:100] Creating Layer pool2
I0726 14:13:31.075249 31263 net.cpp:434] pool2 <- conv2_2
I0726 14:13:31.075253 31263 net.cpp:408] pool2 -> pool2
I0726 14:13:31.075281 31263 net.cpp:150] Setting up pool2
I0726 14:13:31.075287 31263 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0726 14:13:31.075289 31263 net.cpp:165] Memory required for data: 1244160288
I0726 14:13:31.075292 31263 layer_factory.hpp:77] Creating layer conv3_1
I0726 14:13:31.075300 31263 net.cpp:100] Creating Layer conv3_1
I0726 14:13:31.075304 31263 net.cpp:434] conv3_1 <- pool2
I0726 14:13:31.075310 31263 net.cpp:408] conv3_1 -> conv3_1
I0726 14:13:31.079373 31263 net.cpp:150] Setting up conv3_1
I0726 14:13:31.079391 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.079394 31263 net.cpp:165] Memory required for data: 1290240288
I0726 14:13:31.079408 31263 layer_factory.hpp:77] Creating layer relu3_1
I0726 14:13:31.079452 31263 net.cpp:100] Creating Layer relu3_1
I0726 14:13:31.079478 31263 net.cpp:434] relu3_1 <- conv3_1
I0726 14:13:31.079485 31263 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0726 14:13:31.079495 31263 net.cpp:150] Setting up relu3_1
I0726 14:13:31.079499 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.079502 31263 net.cpp:165] Memory required for data: 1336320288
I0726 14:13:31.079506 31263 layer_factory.hpp:77] Creating layer conv3_2
I0726 14:13:31.079516 31263 net.cpp:100] Creating Layer conv3_2
I0726 14:13:31.079520 31263 net.cpp:434] conv3_2 <- conv3_1
I0726 14:13:31.079526 31263 net.cpp:408] conv3_2 -> conv3_2
I0726 14:13:31.084363 31263 net.cpp:150] Setting up conv3_2
I0726 14:13:31.084417 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.084424 31263 net.cpp:165] Memory required for data: 1382400288
I0726 14:13:31.084437 31263 layer_factory.hpp:77] Creating layer relu3_2
I0726 14:13:31.084465 31263 net.cpp:100] Creating Layer relu3_2
I0726 14:13:31.084472 31263 net.cpp:434] relu3_2 <- conv3_2
I0726 14:13:31.084484 31263 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0726 14:13:31.084499 31263 net.cpp:150] Setting up relu3_2
I0726 14:13:31.084504 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.084507 31263 net.cpp:165] Memory required for data: 1428480288
I0726 14:13:31.084511 31263 layer_factory.hpp:77] Creating layer conv3_3
I0726 14:13:31.084558 31263 net.cpp:100] Creating Layer conv3_3
I0726 14:13:31.084563 31263 net.cpp:434] conv3_3 <- conv3_2
I0726 14:13:31.084568 31263 net.cpp:408] conv3_3 -> conv3_3
I0726 14:13:31.091737 31263 net.cpp:150] Setting up conv3_3
I0726 14:13:31.091758 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.091763 31263 net.cpp:165] Memory required for data: 1474560288
I0726 14:13:31.091773 31263 layer_factory.hpp:77] Creating layer relu3_3
I0726 14:13:31.091783 31263 net.cpp:100] Creating Layer relu3_3
I0726 14:13:31.091789 31263 net.cpp:434] relu3_3 <- conv3_3
I0726 14:13:31.091796 31263 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0726 14:13:31.091805 31263 net.cpp:150] Setting up relu3_3
I0726 14:13:31.091810 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.091812 31263 net.cpp:165] Memory required for data: 1520640288
I0726 14:13:31.091817 31263 layer_factory.hpp:77] Creating layer pool3
I0726 14:13:31.091825 31263 net.cpp:100] Creating Layer pool3
I0726 14:13:31.091828 31263 net.cpp:434] pool3 <- conv3_3
I0726 14:13:31.091833 31263 net.cpp:408] pool3 -> pool3
I0726 14:13:31.091871 31263 net.cpp:150] Setting up pool3
I0726 14:13:31.091886 31263 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0726 14:13:31.091892 31263 net.cpp:165] Memory required for data: 1532469536
I0726 14:13:31.091897 31263 layer_factory.hpp:77] Creating layer conv4_1
I0726 14:13:31.091912 31263 net.cpp:100] Creating Layer conv4_1
I0726 14:13:31.091917 31263 net.cpp:434] conv4_1 <- pool3
I0726 14:13:31.091922 31263 net.cpp:408] conv4_1 -> conv4_1
I0726 14:13:31.139770 31263 net.cpp:150] Setting up conv4_1
I0726 14:13:31.139806 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.139820 31263 net.cpp:165] Memory required for data: 1556128032
I0726 14:13:31.139837 31263 layer_factory.hpp:77] Creating layer relu4_1
I0726 14:13:31.139853 31263 net.cpp:100] Creating Layer relu4_1
I0726 14:13:31.139859 31263 net.cpp:434] relu4_1 <- conv4_1
I0726 14:13:31.139866 31263 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0726 14:13:31.139880 31263 net.cpp:150] Setting up relu4_1
I0726 14:13:31.139885 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.139889 31263 net.cpp:165] Memory required for data: 1579786528
I0726 14:13:31.139894 31263 layer_factory.hpp:77] Creating layer conv4_2
I0726 14:13:31.139904 31263 net.cpp:100] Creating Layer conv4_2
I0726 14:13:31.139916 31263 net.cpp:434] conv4_2 <- conv4_1
I0726 14:13:31.139925 31263 net.cpp:408] conv4_2 -> conv4_2
I0726 14:13:31.171293 31263 net.cpp:150] Setting up conv4_2
I0726 14:13:31.171325 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.171335 31263 net.cpp:165] Memory required for data: 1603445024
I0726 14:13:31.171372 31263 layer_factory.hpp:77] Creating layer relu4_2
I0726 14:13:31.171382 31263 net.cpp:100] Creating Layer relu4_2
I0726 14:13:31.171392 31263 net.cpp:434] relu4_2 <- conv4_2
I0726 14:13:31.171406 31263 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0726 14:13:31.172026 31263 net.cpp:150] Setting up relu4_2
I0726 14:13:31.172051 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.172070 31263 net.cpp:165] Memory required for data: 1627103520
I0726 14:13:31.172076 31263 layer_factory.hpp:77] Creating layer conv4_3
I0726 14:13:31.172092 31263 net.cpp:100] Creating Layer conv4_3
I0726 14:13:31.172098 31263 net.cpp:434] conv4_3 <- conv4_2
I0726 14:13:31.172107 31263 net.cpp:408] conv4_3 -> conv4_3
I0726 14:13:31.202309 31263 net.cpp:150] Setting up conv4_3
I0726 14:13:31.202342 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.202344 31263 net.cpp:165] Memory required for data: 1650762016
I0726 14:13:31.202353 31263 layer_factory.hpp:77] Creating layer relu4_3
I0726 14:13:31.202363 31263 net.cpp:100] Creating Layer relu4_3
I0726 14:13:31.202368 31263 net.cpp:434] relu4_3 <- conv4_3
I0726 14:13:31.202376 31263 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0726 14:13:31.202390 31263 net.cpp:150] Setting up relu4_3
I0726 14:13:31.202426 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.202450 31263 net.cpp:165] Memory required for data: 1674420512
I0726 14:13:31.202453 31263 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0726 14:13:31.202458 31263 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0726 14:13:31.202466 31263 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0726 14:13:31.202476 31263 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0726 14:13:31.202484 31263 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0726 14:13:31.202510 31263 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0726 14:13:31.202515 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.202519 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.202523 31263 net.cpp:165] Memory required for data: 1721737504
I0726 14:13:31.202527 31263 layer_factory.hpp:77] Creating layer pool4
I0726 14:13:31.202533 31263 net.cpp:100] Creating Layer pool4
I0726 14:13:31.202538 31263 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0726 14:13:31.202543 31263 net.cpp:408] pool4 -> pool4
I0726 14:13:31.202567 31263 net.cpp:150] Setting up pool4
I0726 14:13:31.202574 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.202575 31263 net.cpp:165] Memory required for data: 1727652128
I0726 14:13:31.202580 31263 layer_factory.hpp:77] Creating layer conv5_1
I0726 14:13:31.202589 31263 net.cpp:100] Creating Layer conv5_1
I0726 14:13:31.202594 31263 net.cpp:434] conv5_1 <- pool4
I0726 14:13:31.202600 31263 net.cpp:408] conv5_1 -> conv5_1
I0726 14:13:31.228423 31263 net.cpp:150] Setting up conv5_1
I0726 14:13:31.228453 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.228456 31263 net.cpp:165] Memory required for data: 1733566752
I0726 14:13:31.228467 31263 layer_factory.hpp:77] Creating layer relu5_1
I0726 14:13:31.228478 31263 net.cpp:100] Creating Layer relu5_1
I0726 14:13:31.228485 31263 net.cpp:434] relu5_1 <- conv5_1
I0726 14:13:31.228497 31263 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0726 14:13:31.228515 31263 net.cpp:150] Setting up relu5_1
I0726 14:13:31.228530 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.228533 31263 net.cpp:165] Memory required for data: 1739481376
I0726 14:13:31.228536 31263 layer_factory.hpp:77] Creating layer conv5_2
I0726 14:13:31.228551 31263 net.cpp:100] Creating Layer conv5_2
I0726 14:13:31.228556 31263 net.cpp:434] conv5_2 <- conv5_1
I0726 14:13:31.228564 31263 net.cpp:408] conv5_2 -> conv5_2
I0726 14:13:31.293792 31263 net.cpp:150] Setting up conv5_2
I0726 14:13:31.293862 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.293872 31263 net.cpp:165] Memory required for data: 1745396000
I0726 14:13:31.293897 31263 layer_factory.hpp:77] Creating layer relu5_2
I0726 14:13:31.293918 31263 net.cpp:100] Creating Layer relu5_2
I0726 14:13:31.293932 31263 net.cpp:434] relu5_2 <- conv5_2
I0726 14:13:31.293946 31263 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0726 14:13:31.293972 31263 net.cpp:150] Setting up relu5_2
I0726 14:13:31.293983 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.293992 31263 net.cpp:165] Memory required for data: 1751310624
I0726 14:13:31.294000 31263 layer_factory.hpp:77] Creating layer conv5_3
I0726 14:13:31.294024 31263 net.cpp:100] Creating Layer conv5_3
I0726 14:13:31.294034 31263 net.cpp:434] conv5_3 <- conv5_2
I0726 14:13:31.294050 31263 net.cpp:408] conv5_3 -> conv5_3
I0726 14:13:31.338276 31263 net.cpp:150] Setting up conv5_3
I0726 14:13:31.338330 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.338338 31263 net.cpp:165] Memory required for data: 1757225248
I0726 14:13:31.338361 31263 layer_factory.hpp:77] Creating layer relu5_3
I0726 14:13:31.338395 31263 net.cpp:100] Creating Layer relu5_3
I0726 14:13:31.338412 31263 net.cpp:434] relu5_3 <- conv5_3
I0726 14:13:31.338431 31263 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0726 14:13:31.338467 31263 net.cpp:150] Setting up relu5_3
I0726 14:13:31.338479 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.338529 31263 net.cpp:165] Memory required for data: 1763139872
I0726 14:13:31.338541 31263 layer_factory.hpp:77] Creating layer pool5
I0726 14:13:31.338557 31263 net.cpp:100] Creating Layer pool5
I0726 14:13:31.338567 31263 net.cpp:434] pool5 <- conv5_3
I0726 14:13:31.338583 31263 net.cpp:408] pool5 -> pool5
I0726 14:13:31.338692 31263 net.cpp:150] Setting up pool5
I0726 14:13:31.338706 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.338712 31263 net.cpp:165] Memory required for data: 1769054496
I0726 14:13:31.338721 31263 layer_factory.hpp:77] Creating layer fc6
I0726 14:13:31.338747 31263 net.cpp:100] Creating Layer fc6
I0726 14:13:31.338757 31263 net.cpp:434] fc6 <- pool5
I0726 14:13:31.338771 31263 net.cpp:408] fc6 -> fc6
I0726 14:13:31.418769 31263 net.cpp:150] Setting up fc6
I0726 14:13:31.418817 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.418824 31263 net.cpp:165] Memory required for data: 1780883744
I0726 14:13:31.418848 31263 layer_factory.hpp:77] Creating layer relu6
I0726 14:13:31.418884 31263 net.cpp:100] Creating Layer relu6
I0726 14:13:31.418896 31263 net.cpp:434] relu6 <- fc6
I0726 14:13:31.418913 31263 net.cpp:395] relu6 -> fc6 (in-place)
I0726 14:13:31.418939 31263 net.cpp:150] Setting up relu6
I0726 14:13:31.418954 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.418963 31263 net.cpp:165] Memory required for data: 1792712992
I0726 14:13:31.418970 31263 layer_factory.hpp:77] Creating layer fc7
I0726 14:13:31.418992 31263 net.cpp:100] Creating Layer fc7
I0726 14:13:31.419003 31263 net.cpp:434] fc7 <- fc6
I0726 14:13:31.419019 31263 net.cpp:408] fc7 -> fc7
I0726 14:13:31.429843 31263 net.cpp:150] Setting up fc7
I0726 14:13:31.429869 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.429873 31263 net.cpp:165] Memory required for data: 1804542240
I0726 14:13:31.429883 31263 layer_factory.hpp:77] Creating layer relu7
I0726 14:13:31.429893 31263 net.cpp:100] Creating Layer relu7
I0726 14:13:31.429898 31263 net.cpp:434] relu7 <- fc7
I0726 14:13:31.429904 31263 net.cpp:395] relu7 -> fc7 (in-place)
I0726 14:13:31.429934 31263 net.cpp:150] Setting up relu7
I0726 14:13:31.429939 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.429941 31263 net.cpp:165] Memory required for data: 1816371488
I0726 14:13:31.429944 31263 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0726 14:13:31.429950 31263 net.cpp:100] Creating Layer fc7_relu7_0_split
I0726 14:13:31.429952 31263 net.cpp:434] fc7_relu7_0_split <- fc7
I0726 14:13:31.429957 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0726 14:13:31.429965 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0726 14:13:31.429975 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0726 14:13:31.429980 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0726 14:13:31.430027 31263 net.cpp:150] Setting up fc7_relu7_0_split
I0726 14:13:31.430032 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.430037 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.430042 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.430044 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.430047 31263 net.cpp:165] Memory required for data: 1863688480
I0726 14:13:31.430048 31263 layer_factory.hpp:77] Creating layer conv6_1
I0726 14:13:31.430058 31263 net.cpp:100] Creating Layer conv6_1
I0726 14:13:31.430061 31263 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0726 14:13:31.430068 31263 net.cpp:408] conv6_1 -> conv6_1
I0726 14:13:31.432842 31263 net.cpp:150] Setting up conv6_1
I0726 14:13:31.432859 31263 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0726 14:13:31.432862 31263 net.cpp:165] Memory required for data: 1866645792
I0726 14:13:31.432873 31263 layer_factory.hpp:77] Creating layer conv6_1_relu
I0726 14:13:31.432894 31263 net.cpp:100] Creating Layer conv6_1_relu
I0726 14:13:31.432909 31263 net.cpp:434] conv6_1_relu <- conv6_1
I0726 14:13:31.432916 31263 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0726 14:13:31.432945 31263 net.cpp:150] Setting up conv6_1_relu
I0726 14:13:31.432955 31263 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0726 14:13:31.432957 31263 net.cpp:165] Memory required for data: 1869603104
I0726 14:13:31.432960 31263 layer_factory.hpp:77] Creating layer conv6_2
I0726 14:13:31.432971 31263 net.cpp:100] Creating Layer conv6_2
I0726 14:13:31.432976 31263 net.cpp:434] conv6_2 <- conv6_1
I0726 14:13:31.432983 31263 net.cpp:408] conv6_2 -> conv6_2
I0726 14:13:31.442031 31263 net.cpp:150] Setting up conv6_2
I0726 14:13:31.442082 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.442085 31263 net.cpp:165] Memory required for data: 1871241504
I0726 14:13:31.442106 31263 layer_factory.hpp:77] Creating layer conv6_2_relu
I0726 14:13:31.442119 31263 net.cpp:100] Creating Layer conv6_2_relu
I0726 14:13:31.442126 31263 net.cpp:434] conv6_2_relu <- conv6_2
I0726 14:13:31.442134 31263 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0726 14:13:31.442147 31263 net.cpp:150] Setting up conv6_2_relu
I0726 14:13:31.442157 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.442162 31263 net.cpp:165] Memory required for data: 1872879904
I0726 14:13:31.442164 31263 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0726 14:13:31.442170 31263 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0726 14:13:31.442173 31263 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0726 14:13:31.442178 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0726 14:13:31.442185 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0726 14:13:31.442190 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0726 14:13:31.442194 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0726 14:13:31.442245 31263 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0726 14:13:31.442250 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.442255 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.442258 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.442262 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.442265 31263 net.cpp:165] Memory required for data: 1879433504
I0726 14:13:31.442268 31263 layer_factory.hpp:77] Creating layer conv7_1
I0726 14:13:31.442277 31263 net.cpp:100] Creating Layer conv7_1
I0726 14:13:31.442282 31263 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0726 14:13:31.442288 31263 net.cpp:408] conv7_1 -> conv7_1
I0726 14:13:31.442878 31263 net.cpp:150] Setting up conv7_1
I0726 14:13:31.442884 31263 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0726 14:13:31.442888 31263 net.cpp:165] Memory required for data: 1879843104
I0726 14:13:31.442894 31263 layer_factory.hpp:77] Creating layer conv7_1_relu
I0726 14:13:31.442899 31263 net.cpp:100] Creating Layer conv7_1_relu
I0726 14:13:31.442903 31263 net.cpp:434] conv7_1_relu <- conv7_1
I0726 14:13:31.442909 31263 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0726 14:13:31.442914 31263 net.cpp:150] Setting up conv7_1_relu
I0726 14:13:31.442919 31263 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0726 14:13:31.442921 31263 net.cpp:165] Memory required for data: 1880252704
I0726 14:13:31.442925 31263 layer_factory.hpp:77] Creating layer conv7_2
I0726 14:13:31.442934 31263 net.cpp:100] Creating Layer conv7_2
I0726 14:13:31.442936 31263 net.cpp:434] conv7_2 <- conv7_1
I0726 14:13:31.442942 31263 net.cpp:408] conv7_2 -> conv7_2
I0726 14:13:31.445763 31263 net.cpp:150] Setting up conv7_2
I0726 14:13:31.445781 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.445785 31263 net.cpp:165] Memory required for data: 1880457504
I0726 14:13:31.445792 31263 layer_factory.hpp:77] Creating layer conv7_2_relu
I0726 14:13:31.445801 31263 net.cpp:100] Creating Layer conv7_2_relu
I0726 14:13:31.445806 31263 net.cpp:434] conv7_2_relu <- conv7_2
I0726 14:13:31.445811 31263 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0726 14:13:31.445845 31263 net.cpp:150] Setting up conv7_2_relu
I0726 14:13:31.445852 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.445853 31263 net.cpp:165] Memory required for data: 1880662304
I0726 14:13:31.445858 31263 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0726 14:13:31.445866 31263 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0726 14:13:31.445870 31263 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0726 14:13:31.445876 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0726 14:13:31.445883 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0726 14:13:31.445896 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0726 14:13:31.445905 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0726 14:13:31.445969 31263 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0726 14:13:31.445976 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.445979 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.445983 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.445988 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.445991 31263 net.cpp:165] Memory required for data: 1881481504
I0726 14:13:31.445994 31263 layer_factory.hpp:77] Creating layer conv8_1
I0726 14:13:31.446003 31263 net.cpp:100] Creating Layer conv8_1
I0726 14:13:31.446007 31263 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0726 14:13:31.446013 31263 net.cpp:408] conv8_1 -> conv8_1
I0726 14:13:31.446409 31263 net.cpp:150] Setting up conv8_1
I0726 14:13:31.446416 31263 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0726 14:13:31.446419 31263 net.cpp:165] Memory required for data: 1881583904
I0726 14:13:31.446425 31263 layer_factory.hpp:77] Creating layer conv8_1_relu
I0726 14:13:31.446430 31263 net.cpp:100] Creating Layer conv8_1_relu
I0726 14:13:31.446435 31263 net.cpp:434] conv8_1_relu <- conv8_1
I0726 14:13:31.446440 31263 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0726 14:13:31.446446 31263 net.cpp:150] Setting up conv8_1_relu
I0726 14:13:31.446450 31263 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0726 14:13:31.446455 31263 net.cpp:165] Memory required for data: 1881686304
I0726 14:13:31.446457 31263 layer_factory.hpp:77] Creating layer conv8_2
I0726 14:13:31.446466 31263 net.cpp:100] Creating Layer conv8_2
I0726 14:13:31.446470 31263 net.cpp:434] conv8_2 <- conv8_1
I0726 14:13:31.446477 31263 net.cpp:408] conv8_2 -> conv8_2
I0726 14:13:31.449867 31263 net.cpp:150] Setting up conv8_2
I0726 14:13:31.449975 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.450009 31263 net.cpp:165] Memory required for data: 1881760032
I0726 14:13:31.450039 31263 layer_factory.hpp:77] Creating layer conv8_2_relu
I0726 14:13:31.450074 31263 net.cpp:100] Creating Layer conv8_2_relu
I0726 14:13:31.450093 31263 net.cpp:434] conv8_2_relu <- conv8_2
I0726 14:13:31.450119 31263 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0726 14:13:31.450139 31263 net.cpp:150] Setting up conv8_2_relu
I0726 14:13:31.450150 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.450153 31263 net.cpp:165] Memory required for data: 1881833760
I0726 14:13:31.450157 31263 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0726 14:13:31.450165 31263 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0726 14:13:31.450167 31263 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0726 14:13:31.450173 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0726 14:13:31.450188 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0726 14:13:31.450199 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0726 14:13:31.450206 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0726 14:13:31.450269 31263 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0726 14:13:31.450299 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.450359 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.450364 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.450368 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.450371 31263 net.cpp:165] Memory required for data: 1882128672
I0726 14:13:31.450376 31263 layer_factory.hpp:77] Creating layer conv9_1
I0726 14:13:31.450387 31263 net.cpp:100] Creating Layer conv9_1
I0726 14:13:31.450392 31263 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0726 14:13:31.450397 31263 net.cpp:408] conv9_1 -> conv9_1
I0726 14:13:31.450757 31263 net.cpp:150] Setting up conv9_1
I0726 14:13:31.450763 31263 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0726 14:13:31.450767 31263 net.cpp:165] Memory required for data: 1882165536
I0726 14:13:31.450773 31263 layer_factory.hpp:77] Creating layer conv9_1_relu
I0726 14:13:31.450778 31263 net.cpp:100] Creating Layer conv9_1_relu
I0726 14:13:31.450783 31263 net.cpp:434] conv9_1_relu <- conv9_1
I0726 14:13:31.450786 31263 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0726 14:13:31.450793 31263 net.cpp:150] Setting up conv9_1_relu
I0726 14:13:31.450799 31263 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0726 14:13:31.450803 31263 net.cpp:165] Memory required for data: 1882202400
I0726 14:13:31.450805 31263 layer_factory.hpp:77] Creating layer conv9_2
I0726 14:13:31.450814 31263 net.cpp:100] Creating Layer conv9_2
I0726 14:13:31.450817 31263 net.cpp:434] conv9_2 <- conv9_1
I0726 14:13:31.450824 31263 net.cpp:408] conv9_2 -> conv9_2
I0726 14:13:31.453783 31263 net.cpp:150] Setting up conv9_2
I0726 14:13:31.453811 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.453816 31263 net.cpp:165] Memory required for data: 1882210592
I0726 14:13:31.453832 31263 layer_factory.hpp:77] Creating layer conv9_2_relu
I0726 14:13:31.453846 31263 net.cpp:100] Creating Layer conv9_2_relu
I0726 14:13:31.453853 31263 net.cpp:434] conv9_2_relu <- conv9_2
I0726 14:13:31.453860 31263 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0726 14:13:31.453871 31263 net.cpp:150] Setting up conv9_2_relu
I0726 14:13:31.453889 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.453892 31263 net.cpp:165] Memory required for data: 1882218784
I0726 14:13:31.453896 31263 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0726 14:13:31.453903 31263 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0726 14:13:31.453907 31263 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0726 14:13:31.453912 31263 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0726 14:13:31.453920 31263 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0726 14:13:31.453927 31263 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0726 14:13:31.453975 31263 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0726 14:13:31.453980 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.453985 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.453989 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.453992 31263 net.cpp:165] Memory required for data: 1882243360
I0726 14:13:31.453995 31263 layer_factory.hpp:77] Creating layer conv4_3_norm
I0726 14:13:31.454015 31263 net.cpp:100] Creating Layer conv4_3_norm
I0726 14:13:31.454018 31263 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0726 14:13:31.454025 31263 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0726 14:13:31.454144 31263 net.cpp:150] Setting up conv4_3_norm
I0726 14:13:31.454149 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.454152 31263 net.cpp:165] Memory required for data: 1905901856
I0726 14:13:31.454159 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0726 14:13:31.454164 31263 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0726 14:13:31.454167 31263 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0726 14:13:31.454174 31263 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0726 14:13:31.454203 31263 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0726 14:13:31.454210 31263 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0726 14:13:31.454248 31263 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0726 14:13:31.454254 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.454258 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.454262 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.454267 31263 net.cpp:165] Memory required for data: 1976877344
I0726 14:13:31.454269 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0726 14:13:31.454279 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0726 14:13:31.454284 31263 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0726 14:13:31.454290 31263 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0726 14:13:31.454928 31263 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0726 14:13:31.454934 31263 net.cpp:157] Top shape: 8 16 38 38 (184832)
I0726 14:13:31.454937 31263 net.cpp:165] Memory required for data: 1977616672
I0726 14:13:31.454944 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0726 14:13:31.454958 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0726 14:13:31.454962 31263 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0726 14:13:31.454967 31263 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0726 14:13:31.455031 31263 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0726 14:13:31.455037 31263 net.cpp:157] Top shape: 8 38 38 16 (184832)
I0726 14:13:31.455040 31263 net.cpp:165] Memory required for data: 1978356000
I0726 14:13:31.455044 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0726 14:13:31.455049 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0726 14:13:31.455054 31263 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0726 14:13:31.455058 31263 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0726 14:13:31.455090 31263 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0726 14:13:31.455097 31263 net.cpp:157] Top shape: 8 23104 (184832)
I0726 14:13:31.455101 31263 net.cpp:165] Memory required for data: 1979095328
I0726 14:13:31.455102 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0726 14:13:31.455144 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0726 14:13:31.455148 31263 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0726 14:13:31.455155 31263 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0726 14:13:31.464342 31263 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0726 14:13:31.464371 31263 net.cpp:157] Top shape: 8 236 38 38 (2726272)
I0726 14:13:31.464375 31263 net.cpp:165] Memory required for data: 1990000416
I0726 14:13:31.464388 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0726 14:13:31.464406 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0726 14:13:31.464413 31263 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0726 14:13:31.464426 31263 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0726 14:13:31.464517 31263 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0726 14:13:31.464524 31263 net.cpp:157] Top shape: 8 38 38 236 (2726272)
I0726 14:13:31.464526 31263 net.cpp:165] Memory required for data: 2000905504
I0726 14:13:31.464529 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0726 14:13:31.464535 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0726 14:13:31.464540 31263 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0726 14:13:31.464543 31263 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0726 14:13:31.464563 31263 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0726 14:13:31.464570 31263 net.cpp:157] Top shape: 8 340784 (2726272)
I0726 14:13:31.464588 31263 net.cpp:165] Memory required for data: 2011810592
I0726 14:13:31.464591 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0726 14:13:31.464604 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0726 14:13:31.464609 31263 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0726 14:13:31.464622 31263 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0726 14:13:31.464632 31263 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0726 14:13:31.464660 31263 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0726 14:13:31.464666 31263 net.cpp:157] Top shape: 1 2 23104 (46208)
I0726 14:13:31.464669 31263 net.cpp:165] Memory required for data: 2011995424
I0726 14:13:31.464673 31263 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0726 14:13:31.464682 31263 net.cpp:100] Creating Layer fc7_mbox_loc
I0726 14:13:31.464687 31263 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0726 14:13:31.464694 31263 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0726 14:13:31.466321 31263 net.cpp:150] Setting up fc7_mbox_loc
I0726 14:13:31.466329 31263 net.cpp:157] Top shape: 8 24 19 19 (69312)
I0726 14:13:31.466333 31263 net.cpp:165] Memory required for data: 2012272672
I0726 14:13:31.466339 31263 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0726 14:13:31.466346 31263 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0726 14:13:31.466349 31263 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0726 14:13:31.466356 31263 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0726 14:13:31.466421 31263 net.cpp:150] Setting up fc7_mbox_loc_perm
I0726 14:13:31.466428 31263 net.cpp:157] Top shape: 8 19 19 24 (69312)
I0726 14:13:31.466430 31263 net.cpp:165] Memory required for data: 2012549920
I0726 14:13:31.466434 31263 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0726 14:13:31.466439 31263 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0726 14:13:31.466442 31263 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0726 14:13:31.466447 31263 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0726 14:13:31.466467 31263 net.cpp:150] Setting up fc7_mbox_loc_flat
I0726 14:13:31.466473 31263 net.cpp:157] Top shape: 8 8664 (69312)
I0726 14:13:31.466477 31263 net.cpp:165] Memory required for data: 2012827168
I0726 14:13:31.466480 31263 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0726 14:13:31.466488 31263 net.cpp:100] Creating Layer fc7_mbox_conf
I0726 14:13:31.466492 31263 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0726 14:13:31.466498 31263 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0726 14:13:31.498580 31263 net.cpp:150] Setting up fc7_mbox_conf
I0726 14:13:31.498610 31263 net.cpp:157] Top shape: 8 354 19 19 (1022352)
I0726 14:13:31.498613 31263 net.cpp:165] Memory required for data: 2016916576
I0726 14:13:31.498628 31263 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0726 14:13:31.498644 31263 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0726 14:13:31.498677 31263 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0726 14:13:31.498687 31263 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0726 14:13:31.498762 31263 net.cpp:150] Setting up fc7_mbox_conf_perm
I0726 14:13:31.498769 31263 net.cpp:157] Top shape: 8 19 19 354 (1022352)
I0726 14:13:31.498772 31263 net.cpp:165] Memory required for data: 2021005984
I0726 14:13:31.498775 31263 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0726 14:13:31.498781 31263 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0726 14:13:31.498786 31263 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0726 14:13:31.498791 31263 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0726 14:13:31.498811 31263 net.cpp:150] Setting up fc7_mbox_conf_flat
I0726 14:13:31.498816 31263 net.cpp:157] Top shape: 8 127794 (1022352)
I0726 14:13:31.498819 31263 net.cpp:165] Memory required for data: 2025095392
I0726 14:13:31.498823 31263 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0726 14:13:31.498829 31263 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0726 14:13:31.498874 31263 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0726 14:13:31.498880 31263 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0726 14:13:31.498888 31263 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0726 14:13:31.498914 31263 net.cpp:150] Setting up fc7_mbox_priorbox
I0726 14:13:31.498919 31263 net.cpp:157] Top shape: 1 2 8664 (17328)
I0726 14:13:31.498922 31263 net.cpp:165] Memory required for data: 2025164704
I0726 14:13:31.498926 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0726 14:13:31.498935 31263 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0726 14:13:31.498940 31263 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0726 14:13:31.498947 31263 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0726 14:13:31.499886 31263 net.cpp:150] Setting up conv6_2_mbox_loc
I0726 14:13:31.499893 31263 net.cpp:157] Top shape: 8 24 10 10 (19200)
I0726 14:13:31.499897 31263 net.cpp:165] Memory required for data: 2025241504
I0726 14:13:31.499903 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0726 14:13:31.499909 31263 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0726 14:13:31.499913 31263 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0726 14:13:31.499918 31263 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0726 14:13:31.499984 31263 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0726 14:13:31.499990 31263 net.cpp:157] Top shape: 8 10 10 24 (19200)
I0726 14:13:31.499994 31263 net.cpp:165] Memory required for data: 2025318304
I0726 14:13:31.499997 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0726 14:13:31.500002 31263 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0726 14:13:31.500006 31263 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0726 14:13:31.500013 31263 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0726 14:13:31.500036 31263 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0726 14:13:31.500041 31263 net.cpp:157] Top shape: 8 2400 (19200)
I0726 14:13:31.500046 31263 net.cpp:165] Memory required for data: 2025395104
I0726 14:13:31.500048 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0726 14:13:31.500057 31263 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0726 14:13:31.500061 31263 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0726 14:13:31.500068 31263 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0726 14:13:31.513723 31263 net.cpp:150] Setting up conv6_2_mbox_conf
I0726 14:13:31.513747 31263 net.cpp:157] Top shape: 8 354 10 10 (283200)
I0726 14:13:31.513751 31263 net.cpp:165] Memory required for data: 2026527904
I0726 14:13:31.513762 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0726 14:13:31.513774 31263 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0726 14:13:31.513783 31263 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0726 14:13:31.513792 31263 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0726 14:13:31.513865 31263 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0726 14:13:31.513871 31263 net.cpp:157] Top shape: 8 10 10 354 (283200)
I0726 14:13:31.513873 31263 net.cpp:165] Memory required for data: 2027660704
I0726 14:13:31.513877 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0726 14:13:31.513882 31263 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0726 14:13:31.513886 31263 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0726 14:13:31.513890 31263 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0726 14:13:31.513909 31263 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0726 14:13:31.513916 31263 net.cpp:157] Top shape: 8 35400 (283200)
I0726 14:13:31.513918 31263 net.cpp:165] Memory required for data: 2028793504
I0726 14:13:31.513922 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0726 14:13:31.513928 31263 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0726 14:13:31.513932 31263 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0726 14:13:31.513978 31263 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0726 14:13:31.513985 31263 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0726 14:13:31.514010 31263 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0726 14:13:31.514017 31263 net.cpp:157] Top shape: 1 2 2400 (4800)
I0726 14:13:31.514019 31263 net.cpp:165] Memory required for data: 2028812704
I0726 14:13:31.514024 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0726 14:13:31.514031 31263 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0726 14:13:31.514036 31263 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0726 14:13:31.514044 31263 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0726 14:13:31.514556 31263 net.cpp:150] Setting up conv7_2_mbox_loc
I0726 14:13:31.514564 31263 net.cpp:157] Top shape: 8 24 5 5 (4800)
I0726 14:13:31.514566 31263 net.cpp:165] Memory required for data: 2028831904
I0726 14:13:31.514572 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0726 14:13:31.514578 31263 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0726 14:13:31.514582 31263 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0726 14:13:31.514587 31263 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0726 14:13:31.514654 31263 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0726 14:13:31.514659 31263 net.cpp:157] Top shape: 8 5 5 24 (4800)
I0726 14:13:31.514662 31263 net.cpp:165] Memory required for data: 2028851104
I0726 14:13:31.514667 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0726 14:13:31.514670 31263 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0726 14:13:31.514674 31263 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0726 14:13:31.514679 31263 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0726 14:13:31.514699 31263 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0726 14:13:31.514704 31263 net.cpp:157] Top shape: 8 600 (4800)
I0726 14:13:31.514708 31263 net.cpp:165] Memory required for data: 2028870304
I0726 14:13:31.514710 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0726 14:13:31.514719 31263 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0726 14:13:31.514721 31263 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0726 14:13:31.514727 31263 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0726 14:13:31.521214 31263 net.cpp:150] Setting up conv7_2_mbox_conf
I0726 14:13:31.521239 31263 net.cpp:157] Top shape: 8 354 5 5 (70800)
I0726 14:13:31.521242 31263 net.cpp:165] Memory required for data: 2029153504
I0726 14:13:31.521255 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0726 14:13:31.521267 31263 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0726 14:13:31.521276 31263 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0726 14:13:31.521286 31263 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0726 14:13:31.521385 31263 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0726 14:13:31.521391 31263 net.cpp:157] Top shape: 8 5 5 354 (70800)
I0726 14:13:31.521395 31263 net.cpp:165] Memory required for data: 2029436704
I0726 14:13:31.521399 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0726 14:13:31.521404 31263 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0726 14:13:31.521407 31263 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0726 14:13:31.521414 31263 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0726 14:13:31.521440 31263 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0726 14:13:31.521445 31263 net.cpp:157] Top shape: 8 8850 (70800)
I0726 14:13:31.521448 31263 net.cpp:165] Memory required for data: 2029719904
I0726 14:13:31.521451 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0726 14:13:31.521457 31263 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0726 14:13:31.521461 31263 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0726 14:13:31.521467 31263 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0726 14:13:31.521473 31263 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0726 14:13:31.521517 31263 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0726 14:13:31.521522 31263 net.cpp:157] Top shape: 1 2 600 (1200)
I0726 14:13:31.521524 31263 net.cpp:165] Memory required for data: 2029724704
I0726 14:13:31.521528 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0726 14:13:31.521538 31263 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0726 14:13:31.521541 31263 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0726 14:13:31.521548 31263 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0726 14:13:31.521945 31263 net.cpp:150] Setting up conv8_2_mbox_loc
I0726 14:13:31.521952 31263 net.cpp:157] Top shape: 8 16 3 3 (1152)
I0726 14:13:31.521955 31263 net.cpp:165] Memory required for data: 2029729312
I0726 14:13:31.521970 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0726 14:13:31.521978 31263 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0726 14:13:31.521982 31263 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0726 14:13:31.521988 31263 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0726 14:13:31.522053 31263 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0726 14:13:31.522058 31263 net.cpp:157] Top shape: 8 3 3 16 (1152)
I0726 14:13:31.522060 31263 net.cpp:165] Memory required for data: 2029733920
I0726 14:13:31.522063 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0726 14:13:31.522068 31263 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0726 14:13:31.522073 31263 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0726 14:13:31.522078 31263 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0726 14:13:31.522095 31263 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0726 14:13:31.522101 31263 net.cpp:157] Top shape: 8 144 (1152)
I0726 14:13:31.522104 31263 net.cpp:165] Memory required for data: 2029738528
I0726 14:13:31.522107 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0726 14:13:31.522114 31263 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0726 14:13:31.522119 31263 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0726 14:13:31.522125 31263 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0726 14:13:31.526568 31263 net.cpp:150] Setting up conv8_2_mbox_conf
I0726 14:13:31.526588 31263 net.cpp:157] Top shape: 8 236 3 3 (16992)
I0726 14:13:31.526592 31263 net.cpp:165] Memory required for data: 2029806496
I0726 14:13:31.526603 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0726 14:13:31.526614 31263 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0726 14:13:31.526623 31263 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0726 14:13:31.526631 31263 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0726 14:13:31.526705 31263 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0726 14:13:31.526710 31263 net.cpp:157] Top shape: 8 3 3 236 (16992)
I0726 14:13:31.526715 31263 net.cpp:165] Memory required for data: 2029874464
I0726 14:13:31.526717 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0726 14:13:31.526727 31263 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0726 14:13:31.526731 31263 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0726 14:13:31.526739 31263 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0726 14:13:31.526762 31263 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0726 14:13:31.526767 31263 net.cpp:157] Top shape: 8 2124 (16992)
I0726 14:13:31.526772 31263 net.cpp:165] Memory required for data: 2029942432
I0726 14:13:31.526774 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0726 14:13:31.526780 31263 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0726 14:13:31.526784 31263 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0726 14:13:31.526790 31263 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0726 14:13:31.526796 31263 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0726 14:13:31.526823 31263 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0726 14:13:31.526839 31263 net.cpp:157] Top shape: 1 2 144 (288)
I0726 14:13:31.526842 31263 net.cpp:165] Memory required for data: 2029943584
I0726 14:13:31.526845 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0726 14:13:31.526855 31263 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0726 14:13:31.526859 31263 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0726 14:13:31.526866 31263 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0726 14:13:31.527269 31263 net.cpp:150] Setting up conv9_2_mbox_loc
I0726 14:13:31.527276 31263 net.cpp:157] Top shape: 8 16 1 1 (128)
I0726 14:13:31.527278 31263 net.cpp:165] Memory required for data: 2029944096
I0726 14:13:31.527285 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0726 14:13:31.527292 31263 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0726 14:13:31.527294 31263 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0726 14:13:31.527300 31263 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0726 14:13:31.527364 31263 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0726 14:13:31.527369 31263 net.cpp:157] Top shape: 8 1 1 16 (128)
I0726 14:13:31.527372 31263 net.cpp:165] Memory required for data: 2029944608
I0726 14:13:31.527376 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0726 14:13:31.527381 31263 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0726 14:13:31.527385 31263 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0726 14:13:31.527390 31263 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0726 14:13:31.527410 31263 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0726 14:13:31.527423 31263 net.cpp:157] Top shape: 8 16 (128)
I0726 14:13:31.527426 31263 net.cpp:165] Memory required for data: 2029945120
I0726 14:13:31.527429 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0726 14:13:31.527441 31263 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0726 14:13:31.527446 31263 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0726 14:13:31.527457 31263 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0726 14:13:31.533038 31263 net.cpp:150] Setting up conv9_2_mbox_conf
I0726 14:13:31.533180 31263 net.cpp:157] Top shape: 8 236 1 1 (1888)
I0726 14:13:31.533196 31263 net.cpp:165] Memory required for data: 2029952672
I0726 14:13:31.533231 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0726 14:13:31.533279 31263 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0726 14:13:31.533308 31263 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0726 14:13:31.533365 31263 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0726 14:13:31.533459 31263 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0726 14:13:31.533465 31263 net.cpp:157] Top shape: 8 1 1 236 (1888)
I0726 14:13:31.533468 31263 net.cpp:165] Memory required for data: 2029960224
I0726 14:13:31.533473 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0726 14:13:31.533478 31263 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0726 14:13:31.533481 31263 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0726 14:13:31.533488 31263 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0726 14:13:31.533510 31263 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0726 14:13:31.533516 31263 net.cpp:157] Top shape: 8 236 (1888)
I0726 14:13:31.533521 31263 net.cpp:165] Memory required for data: 2029967776
I0726 14:13:31.533525 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0726 14:13:31.533534 31263 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0726 14:13:31.533537 31263 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0726 14:13:31.533543 31263 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0726 14:13:31.533550 31263 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0726 14:13:31.533579 31263 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0726 14:13:31.533584 31263 net.cpp:157] Top shape: 1 2 16 (32)
I0726 14:13:31.533587 31263 net.cpp:165] Memory required for data: 2029967904
I0726 14:13:31.533608 31263 layer_factory.hpp:77] Creating layer mbox_loc
I0726 14:13:31.533618 31263 net.cpp:100] Creating Layer mbox_loc
I0726 14:13:31.533625 31263 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0726 14:13:31.533632 31263 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0726 14:13:31.533637 31263 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0726 14:13:31.533643 31263 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0726 14:13:31.533649 31263 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0726 14:13:31.533654 31263 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0726 14:13:31.533659 31263 net.cpp:408] mbox_loc -> mbox_loc
I0726 14:13:31.533685 31263 net.cpp:150] Setting up mbox_loc
I0726 14:13:31.533691 31263 net.cpp:157] Top shape: 8 34928 (279424)
I0726 14:13:31.533694 31263 net.cpp:165] Memory required for data: 2031085600
I0726 14:13:31.533697 31263 layer_factory.hpp:77] Creating layer mbox_conf
I0726 14:13:31.533704 31263 net.cpp:100] Creating Layer mbox_conf
I0726 14:13:31.533707 31263 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0726 14:13:31.533712 31263 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0726 14:13:31.533717 31263 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0726 14:13:31.533722 31263 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0726 14:13:31.533728 31263 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0726 14:13:31.533732 31263 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0726 14:13:31.533737 31263 net.cpp:408] mbox_conf -> mbox_conf
I0726 14:13:31.533758 31263 net.cpp:150] Setting up mbox_conf
I0726 14:13:31.533763 31263 net.cpp:157] Top shape: 8 515188 (4121504)
I0726 14:13:31.533766 31263 net.cpp:165] Memory required for data: 2047571616
I0726 14:13:31.533771 31263 layer_factory.hpp:77] Creating layer mbox_priorbox
I0726 14:13:31.533776 31263 net.cpp:100] Creating Layer mbox_priorbox
I0726 14:13:31.533779 31263 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0726 14:13:31.533787 31263 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0726 14:13:31.533795 31263 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0726 14:13:31.533802 31263 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0726 14:13:31.533807 31263 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0726 14:13:31.533810 31263 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0726 14:13:31.533815 31263 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0726 14:13:31.533834 31263 net.cpp:150] Setting up mbox_priorbox
I0726 14:13:31.533839 31263 net.cpp:157] Top shape: 1 2 34928 (69856)
I0726 14:13:31.533843 31263 net.cpp:165] Memory required for data: 2047851040
I0726 14:13:31.533846 31263 layer_factory.hpp:77] Creating layer mbox_loss
I0726 14:13:31.533859 31263 net.cpp:100] Creating Layer mbox_loss
I0726 14:13:31.533862 31263 net.cpp:434] mbox_loss <- mbox_loc
I0726 14:13:31.533867 31263 net.cpp:434] mbox_loss <- mbox_conf
I0726 14:13:31.533871 31263 net.cpp:434] mbox_loss <- mbox_priorbox
I0726 14:13:31.533876 31263 net.cpp:434] mbox_loss <- label
I0726 14:13:31.533884 31263 net.cpp:408] mbox_loss -> mbox_loss
I0726 14:13:31.533927 31263 layer_factory.hpp:77] Creating layer mbox_loss_smooth_L1_loc
I0726 14:13:31.534009 31263 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0726 14:13:31.534018 31263 layer_factory.hpp:77] Creating layer mbox_loss_softmax_conf
I0726 14:13:31.534096 31263 net.cpp:150] Setting up mbox_loss
I0726 14:13:31.534101 31263 net.cpp:157] Top shape: (1)
I0726 14:13:31.534103 31263 net.cpp:160]     with loss weight 1
I0726 14:13:31.534123 31263 net.cpp:165] Memory required for data: 2047851044
I0726 14:13:31.534127 31263 net.cpp:226] mbox_loss needs backward computation.
I0726 14:13:31.534132 31263 net.cpp:228] mbox_priorbox does not need backward computation.
I0726 14:13:31.534139 31263 net.cpp:226] mbox_conf needs backward computation.
I0726 14:13:31.534145 31263 net.cpp:226] mbox_loc needs backward computation.
I0726 14:13:31.534150 31263 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0726 14:13:31.534164 31263 net.cpp:226] conv9_2_mbox_conf_flat needs backward computation.
I0726 14:13:31.534168 31263 net.cpp:226] conv9_2_mbox_conf_perm needs backward computation.
I0726 14:13:31.534173 31263 net.cpp:226] conv9_2_mbox_conf needs backward computation.
I0726 14:13:31.534176 31263 net.cpp:226] conv9_2_mbox_loc_flat needs backward computation.
I0726 14:13:31.534180 31263 net.cpp:226] conv9_2_mbox_loc_perm needs backward computation.
I0726 14:13:31.534184 31263 net.cpp:226] conv9_2_mbox_loc needs backward computation.
I0726 14:13:31.534189 31263 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0726 14:13:31.534194 31263 net.cpp:226] conv8_2_mbox_conf_flat needs backward computation.
I0726 14:13:31.534198 31263 net.cpp:226] conv8_2_mbox_conf_perm needs backward computation.
I0726 14:13:31.534202 31263 net.cpp:226] conv8_2_mbox_conf needs backward computation.
I0726 14:13:31.534206 31263 net.cpp:226] conv8_2_mbox_loc_flat needs backward computation.
I0726 14:13:31.534210 31263 net.cpp:226] conv8_2_mbox_loc_perm needs backward computation.
I0726 14:13:31.534214 31263 net.cpp:226] conv8_2_mbox_loc needs backward computation.
I0726 14:13:31.534219 31263 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0726 14:13:31.534224 31263 net.cpp:226] conv7_2_mbox_conf_flat needs backward computation.
I0726 14:13:31.534227 31263 net.cpp:226] conv7_2_mbox_conf_perm needs backward computation.
I0726 14:13:31.534230 31263 net.cpp:226] conv7_2_mbox_conf needs backward computation.
I0726 14:13:31.534245 31263 net.cpp:226] conv7_2_mbox_loc_flat needs backward computation.
I0726 14:13:31.534257 31263 net.cpp:226] conv7_2_mbox_loc_perm needs backward computation.
I0726 14:13:31.534261 31263 net.cpp:226] conv7_2_mbox_loc needs backward computation.
I0726 14:13:31.534265 31263 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0726 14:13:31.534271 31263 net.cpp:226] conv6_2_mbox_conf_flat needs backward computation.
I0726 14:13:31.534274 31263 net.cpp:226] conv6_2_mbox_conf_perm needs backward computation.
I0726 14:13:31.534278 31263 net.cpp:226] conv6_2_mbox_conf needs backward computation.
I0726 14:13:31.534282 31263 net.cpp:226] conv6_2_mbox_loc_flat needs backward computation.
I0726 14:13:31.534286 31263 net.cpp:226] conv6_2_mbox_loc_perm needs backward computation.
I0726 14:13:31.534291 31263 net.cpp:226] conv6_2_mbox_loc needs backward computation.
I0726 14:13:31.534294 31263 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0726 14:13:31.534298 31263 net.cpp:226] fc7_mbox_conf_flat needs backward computation.
I0726 14:13:31.534303 31263 net.cpp:226] fc7_mbox_conf_perm needs backward computation.
I0726 14:13:31.534307 31263 net.cpp:226] fc7_mbox_conf needs backward computation.
I0726 14:13:31.534312 31263 net.cpp:226] fc7_mbox_loc_flat needs backward computation.
I0726 14:13:31.534315 31263 net.cpp:226] fc7_mbox_loc_perm needs backward computation.
I0726 14:13:31.534319 31263 net.cpp:226] fc7_mbox_loc needs backward computation.
I0726 14:13:31.534324 31263 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0726 14:13:31.534328 31263 net.cpp:226] conv4_3_norm_mbox_conf_flat needs backward computation.
I0726 14:13:31.534332 31263 net.cpp:226] conv4_3_norm_mbox_conf_perm needs backward computation.
I0726 14:13:31.534337 31263 net.cpp:226] conv4_3_norm_mbox_conf needs backward computation.
I0726 14:13:31.534342 31263 net.cpp:226] conv4_3_norm_mbox_loc_flat needs backward computation.
I0726 14:13:31.534345 31263 net.cpp:226] conv4_3_norm_mbox_loc_perm needs backward computation.
I0726 14:13:31.534349 31263 net.cpp:226] conv4_3_norm_mbox_loc needs backward computation.
I0726 14:13:31.534353 31263 net.cpp:226] conv4_3_norm_conv4_3_norm_0_split needs backward computation.
I0726 14:13:31.534358 31263 net.cpp:226] conv4_3_norm needs backward computation.
I0726 14:13:31.534363 31263 net.cpp:226] conv9_2_conv9_2_relu_0_split needs backward computation.
I0726 14:13:31.534366 31263 net.cpp:226] conv9_2_relu needs backward computation.
I0726 14:13:31.534375 31263 net.cpp:226] conv9_2 needs backward computation.
I0726 14:13:31.534380 31263 net.cpp:226] conv9_1_relu needs backward computation.
I0726 14:13:31.534384 31263 net.cpp:226] conv9_1 needs backward computation.
I0726 14:13:31.534387 31263 net.cpp:226] conv8_2_conv8_2_relu_0_split needs backward computation.
I0726 14:13:31.534391 31263 net.cpp:226] conv8_2_relu needs backward computation.
I0726 14:13:31.534395 31263 net.cpp:226] conv8_2 needs backward computation.
I0726 14:13:31.534399 31263 net.cpp:226] conv8_1_relu needs backward computation.
I0726 14:13:31.534404 31263 net.cpp:226] conv8_1 needs backward computation.
I0726 14:13:31.534406 31263 net.cpp:226] conv7_2_conv7_2_relu_0_split needs backward computation.
I0726 14:13:31.534410 31263 net.cpp:226] conv7_2_relu needs backward computation.
I0726 14:13:31.534422 31263 net.cpp:226] conv7_2 needs backward computation.
I0726 14:13:31.534426 31263 net.cpp:226] conv7_1_relu needs backward computation.
I0726 14:13:31.534430 31263 net.cpp:226] conv7_1 needs backward computation.
I0726 14:13:31.534435 31263 net.cpp:226] conv6_2_conv6_2_relu_0_split needs backward computation.
I0726 14:13:31.534438 31263 net.cpp:226] conv6_2_relu needs backward computation.
I0726 14:13:31.534442 31263 net.cpp:226] conv6_2 needs backward computation.
I0726 14:13:31.534446 31263 net.cpp:226] conv6_1_relu needs backward computation.
I0726 14:13:31.534451 31263 net.cpp:226] conv6_1 needs backward computation.
I0726 14:13:31.534454 31263 net.cpp:226] fc7_relu7_0_split needs backward computation.
I0726 14:13:31.534458 31263 net.cpp:226] relu7 needs backward computation.
I0726 14:13:31.534461 31263 net.cpp:226] fc7 needs backward computation.
I0726 14:13:31.534466 31263 net.cpp:226] relu6 needs backward computation.
I0726 14:13:31.534469 31263 net.cpp:226] fc6 needs backward computation.
I0726 14:13:31.534473 31263 net.cpp:226] pool5 needs backward computation.
I0726 14:13:31.534477 31263 net.cpp:226] relu5_3 needs backward computation.
I0726 14:13:31.534482 31263 net.cpp:226] conv5_3 needs backward computation.
I0726 14:13:31.534485 31263 net.cpp:226] relu5_2 needs backward computation.
I0726 14:13:31.534489 31263 net.cpp:226] conv5_2 needs backward computation.
I0726 14:13:31.534492 31263 net.cpp:226] relu5_1 needs backward computation.
I0726 14:13:31.534497 31263 net.cpp:226] conv5_1 needs backward computation.
I0726 14:13:31.534499 31263 net.cpp:226] pool4 needs backward computation.
I0726 14:13:31.534504 31263 net.cpp:226] conv4_3_relu4_3_0_split needs backward computation.
I0726 14:13:31.534507 31263 net.cpp:226] relu4_3 needs backward computation.
I0726 14:13:31.534512 31263 net.cpp:226] conv4_3 needs backward computation.
I0726 14:13:31.534515 31263 net.cpp:226] relu4_2 needs backward computation.
I0726 14:13:31.534519 31263 net.cpp:226] conv4_2 needs backward computation.
I0726 14:13:31.534523 31263 net.cpp:226] relu4_1 needs backward computation.
I0726 14:13:31.534526 31263 net.cpp:226] conv4_1 needs backward computation.
I0726 14:13:31.534530 31263 net.cpp:226] pool3 needs backward computation.
I0726 14:13:31.534534 31263 net.cpp:226] relu3_3 needs backward computation.
I0726 14:13:31.534538 31263 net.cpp:226] conv3_3 needs backward computation.
I0726 14:13:31.534541 31263 net.cpp:226] relu3_2 needs backward computation.
I0726 14:13:31.534545 31263 net.cpp:226] conv3_2 needs backward computation.
I0726 14:13:31.534548 31263 net.cpp:226] relu3_1 needs backward computation.
I0726 14:13:31.534553 31263 net.cpp:226] conv3_1 needs backward computation.
I0726 14:13:31.534556 31263 net.cpp:226] pool2 needs backward computation.
I0726 14:13:31.534559 31263 net.cpp:226] relu2_2 needs backward computation.
I0726 14:13:31.534564 31263 net.cpp:226] conv2_2 needs backward computation.
I0726 14:13:31.534566 31263 net.cpp:226] relu2_1 needs backward computation.
I0726 14:13:31.534570 31263 net.cpp:226] conv2_1 needs backward computation.
I0726 14:13:31.534574 31263 net.cpp:226] pool1 needs backward computation.
I0726 14:13:31.534579 31263 net.cpp:226] relu1_2 needs backward computation.
I0726 14:13:31.534586 31263 net.cpp:226] conv1_2 needs backward computation.
I0726 14:13:31.534591 31263 net.cpp:226] relu1_1 needs backward computation.
I0726 14:13:31.534595 31263 net.cpp:226] conv1_1 needs backward computation.
I0726 14:13:31.534600 31263 net.cpp:228] data_data_0_split does not need backward computation.
I0726 14:13:31.534605 31263 net.cpp:228] data does not need backward computation.
I0726 14:13:31.534608 31263 net.cpp:270] This network produces output mbox_loss
I0726 14:13:31.534675 31263 net.cpp:283] Network initialization done.
I0726 14:13:31.536547 31263 solver.cpp:196] Creating test net (#0) specified by test_net file: models/VGGNet/SHOPPE_2017/SSD_300x300/test.prototxt
I0726 14:13:31.537206 31263 net.cpp:58] Initializing net from parameters: 
name: "VGG_SHOPPE_2017_SSD_300x300_test"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_value: 104
    mean_value: 117
    mean_value: 123
    resize_param {
      prob: 1
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
    }
  }
  data_param {
    source: "SHOPPE_2017/lmdb/SHOPPE_2017_test_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
    }
    label_map_file: "data/SHOPPE_2017/labelmap_voc.prototxt"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_3"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_3"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 1
  }
}
layer {
  name: "relu5_3"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_3"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "fc6"
  type: "Convolution"
  bottom: "pool5"
  top: "fc6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 6
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    dilation: 6
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc6"
  top: "fc6"
}
layer {
  name: "fc7"
  type: "Convolution"
  bottom: "fc6"
  top: "fc7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu7"
  type: "ReLU"
  bottom: "fc7"
  top: "fc7"
}
layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "fc7"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "conv8_1"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv8_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_1_relu"
  type: "ReLU"
  bottom: "conv8_1"
  top: "conv8_1"
}
layer {
  name: "conv8_2"
  type: "Convolution"
  bottom: "conv8_1"
  top: "conv8_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_relu"
  type: "ReLU"
  bottom: "conv8_2"
  top: "conv8_2"
}
layer {
  name: "conv9_1"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv9_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_1_relu"
  type: "ReLU"
  bottom: "conv9_1"
  top: "conv9_1"
}
layer {
  name: "conv9_2"
  type: "Convolution"
  bottom: "conv9_1"
  top: "conv9_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_relu"
  type: "ReLU"
  bottom: "conv9_2"
  top: "conv9_2"
}
layer {
  name: "conv4_3_norm"
  type: "Normalize"
  bottom: "conv4_3"
  top: "conv4_3_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20
    }
    channel_shared: false
  }
}
layer {
  name: "conv4_3_norm_mbox_loc"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_loc"
  top: "conv4_3_norm_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_loc_perm"
  top: "conv4_3_norm_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf"
  type: "Convolution"
  bottom: "conv4_3_norm"
  top: "conv4_3_norm_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 236
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_perm"
  type: "Permute"
  bottom: "conv4_3_norm_mbox_conf"
  top: "conv4_3_norm_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv4_3_norm_mbox_conf_perm"
  top: "conv4_3_norm_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv4_3_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv4_3_norm"
  bottom: "data"
  top: "conv4_3_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30
    max_size: 60
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 8
    offset: 0.5
  }
}
layer {
  name: "fc7_mbox_loc"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_loc_perm"
  type: "Permute"
  bottom: "fc7_mbox_loc"
  top: "fc7_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_loc_flat"
  type: "Flatten"
  bottom: "fc7_mbox_loc_perm"
  top: "fc7_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_conf"
  type: "Convolution"
  bottom: "fc7"
  top: "fc7_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 354
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc7_mbox_conf_perm"
  type: "Permute"
  bottom: "fc7_mbox_conf"
  top: "fc7_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "fc7_mbox_conf_flat"
  type: "Flatten"
  bottom: "fc7_mbox_conf_perm"
  top: "fc7_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "fc7_mbox_priorbox"
  type: "PriorBox"
  bottom: "fc7"
  bottom: "data"
  top: "fc7_mbox_priorbox"
  prior_box_param {
    min_size: 60
    max_size: 111
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 16
    offset: 0.5
  }
}
layer {
  name: "conv6_2_mbox_loc"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_loc"
  top: "conv6_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_loc_perm"
  top: "conv6_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_conf"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 354
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv6_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv6_2_mbox_conf"
  top: "conv6_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv6_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv6_2_mbox_conf_perm"
  top: "conv6_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv6_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv6_2"
  bottom: "data"
  top: "conv6_2_mbox_priorbox"
  prior_box_param {
    min_size: 111
    max_size: 162
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 32
    offset: 0.5
  }
}
layer {
  name: "conv7_2_mbox_loc"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 24
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_loc"
  top: "conv7_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_loc_perm"
  top: "conv7_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_conf"
  type: "Convolution"
  bottom: "conv7_2"
  top: "conv7_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 354
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv7_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv7_2_mbox_conf"
  top: "conv7_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv7_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv7_2_mbox_conf_perm"
  top: "conv7_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv7_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv7_2"
  bottom: "data"
  top: "conv7_2_mbox_priorbox"
  prior_box_param {
    min_size: 162
    max_size: 213
    aspect_ratio: 2
    aspect_ratio: 3
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 64
    offset: 0.5
  }
}
layer {
  name: "conv8_2_mbox_loc"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_loc"
  top: "conv8_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_loc_perm"
  top: "conv8_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_conf"
  type: "Convolution"
  bottom: "conv8_2"
  top: "conv8_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 236
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv8_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv8_2_mbox_conf"
  top: "conv8_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv8_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv8_2_mbox_conf_perm"
  top: "conv8_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv8_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv8_2"
  bottom: "data"
  top: "conv8_2_mbox_priorbox"
  prior_box_param {
    min_size: 213
    max_size: 264
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 100
    offset: 0.5
  }
}
layer {
  name: "conv9_2_mbox_loc"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_loc"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_loc_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_loc"
  top: "conv9_2_mbox_loc_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_loc_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_loc_perm"
  top: "conv9_2_mbox_loc_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_conf"
  type: "Convolution"
  bottom: "conv9_2"
  top: "conv9_2_mbox_conf"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 236
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "conv9_2_mbox_conf_perm"
  type: "Permute"
  bottom: "conv9_2_mbox_conf"
  top: "conv9_2_mbox_conf_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "conv9_2_mbox_conf_flat"
  type: "Flatten"
  bottom: "conv9_2_mbox_conf_perm"
  top: "conv9_2_mbox_conf_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "conv9_2_mbox_priorbox"
  type: "PriorBox"
  bottom: "conv9_2"
  bottom: "data"
  top: "conv9_2_mbox_priorbox"
  prior_box_param {
    min_size: 264
    max_size: 315
    aspect_ratio: 2
    flip: true
    clip: false
    variance: 0.1
    variance: 0.1
    variance: 0.2
    variance: 0.2
    step: 300
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_loc_flat"
  bottom: "fc7_mbox_loc_flat"
  bottom: "conv6_2_mbox_loc_flat"
  bottom: "conv7_2_mbox_loc_flat"
  bottom: "conv8_2_mbox_loc_flat"
  bottom: "conv9_2_mbox_loc_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_conf_flat"
  bottom: "fc7_mbox_conf_flat"
  bottom: "conv6_2_mbox_conf_flat"
  bottom: "conv7_2_mbox_conf_flat"
  bottom: "conv8_2_mbox_conf_flat"
  bottom: "conv9_2_mbox_conf_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "conv4_3_norm_mbox_priorbox"
  bottom: "fc7_mbox_priorbox"
  bottom: "conv6_2_mbox_priorbox"
  bottom: "conv7_2_mbox_priorbox"
  bottom: "conv8_2_mbox_priorbox"
  bottom: "conv9_2_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_reshape"
  type: "Reshape"
  bottom: "mbox_conf"
  top: "mbox_conf_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: -1
      dim: 59
    }
  }
}
layer {
  name: "mbox_conf_softmax"
  type: "Softmax"
  bottom: "mbox_conf_reshape"
  top: "mbox_conf_softmax"
  softmax_param {
    axis: 2
  }
}
layer {
  name: "mbox_conf_flatten"
  type: "Flatten"
  bottom: "mbox_conf_softmax"
  top: "mbox_conf_flatten"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "detection_out"
  type: "DetectionOutput"
  bottom: "mbox_loc"
  bottom: "mbox_conf_flatten"
  bottom: "mbox_priorbox"
  top: "detection_out"
  include {
    phase: TEST
  }
  detection_output_param {
    num_classes: 59
    share_location: true
    background_label_id: 0
    nms_param {
      nms_threshold: 0.45
      top_k: 400
    }
    save_output_param {
      output_directory: "/home/legion/data/SHOPPE_2017/results/SSD_300x300/Main"
      output_name_prefix: "comp4_det_test_"
      output_format: "VOC"
      label_map_file: "data/SHOPPE_2017/labelmap_voc.prototxt"
      name_size_file: "data/SHOPPE_2017/test_name_size.txt"
      num_test_image: 100
    }
    code_type: CENTER_SIZE
    keep_top_k: 200
    confidence_threshold: 0.01
  }
}
layer {
  name: "detection_eval"
  type: "DetectionEvaluate"
  bottom: "detection_out"
  bottom: "label"
  top: "detection_eval"
  include {
    phase: TEST
  }
  detection_evaluate_param {
    num_classes: 59
    background_label_id: 0
    overlap_threshold: 0.5
    evaluate_difficult_gt: false
    name_size_file: "data/SHOPPE_2017/test_name_size.txt"
  }
}
I0726 14:13:31.537696 31263 layer_factory.hpp:77] Creating layer data
I0726 14:13:31.606330 31263 net.cpp:100] Creating Layer data
I0726 14:13:31.606376 31263 net.cpp:408] data -> data
I0726 14:13:31.606407 31263 net.cpp:408] data -> label
I0726 14:13:31.607053 31278 db_lmdb.cpp:35] Opened lmdb SHOPPE_2017/lmdb/SHOPPE_2017_test_lmdb
I0726 14:13:31.610049 31263 annotated_data_layer.cpp:62] output data size: 8,3,300,300
I0726 14:13:31.637646 31263 net.cpp:150] Setting up data
I0726 14:13:31.637704 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.637727 31263 net.cpp:157] Top shape: 1 1 13 8 (104)
I0726 14:13:31.637740 31263 net.cpp:165] Memory required for data: 8640416
I0726 14:13:31.637756 31263 layer_factory.hpp:77] Creating layer data_data_0_split
I0726 14:13:31.637778 31263 net.cpp:100] Creating Layer data_data_0_split
I0726 14:13:31.637799 31263 net.cpp:434] data_data_0_split <- data
I0726 14:13:31.637815 31263 net.cpp:408] data_data_0_split -> data_data_0_split_0
I0726 14:13:31.637836 31263 net.cpp:408] data_data_0_split -> data_data_0_split_1
I0726 14:13:31.637853 31263 net.cpp:408] data_data_0_split -> data_data_0_split_2
I0726 14:13:31.637871 31263 net.cpp:408] data_data_0_split -> data_data_0_split_3
I0726 14:13:31.637888 31263 net.cpp:408] data_data_0_split -> data_data_0_split_4
I0726 14:13:31.637904 31263 net.cpp:408] data_data_0_split -> data_data_0_split_5
I0726 14:13:31.637919 31263 net.cpp:408] data_data_0_split -> data_data_0_split_6
I0726 14:13:31.638053 31263 net.cpp:150] Setting up data_data_0_split
I0726 14:13:31.638072 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.638087 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.638099 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.638111 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.638123 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.638134 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.638146 31263 net.cpp:157] Top shape: 8 3 300 300 (2160000)
I0726 14:13:31.638164 31263 net.cpp:165] Memory required for data: 69120416
I0726 14:13:31.638190 31263 layer_factory.hpp:77] Creating layer conv1_1
I0726 14:13:31.638211 31263 net.cpp:100] Creating Layer conv1_1
I0726 14:13:31.638222 31263 net.cpp:434] conv1_1 <- data_data_0_split_0
I0726 14:13:31.638237 31263 net.cpp:408] conv1_1 -> conv1_1
I0726 14:13:31.638661 31263 net.cpp:150] Setting up conv1_1
I0726 14:13:31.638684 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.638697 31263 net.cpp:165] Memory required for data: 253440416
I0726 14:13:31.638720 31263 layer_factory.hpp:77] Creating layer relu1_1
I0726 14:13:31.638734 31263 net.cpp:100] Creating Layer relu1_1
I0726 14:13:31.638747 31263 net.cpp:434] relu1_1 <- conv1_1
I0726 14:13:31.638761 31263 net.cpp:395] relu1_1 -> conv1_1 (in-place)
I0726 14:13:31.638778 31263 net.cpp:150] Setting up relu1_1
I0726 14:13:31.638792 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.638803 31263 net.cpp:165] Memory required for data: 437760416
I0726 14:13:31.638814 31263 layer_factory.hpp:77] Creating layer conv1_2
I0726 14:13:31.638833 31263 net.cpp:100] Creating Layer conv1_2
I0726 14:13:31.638845 31263 net.cpp:434] conv1_2 <- conv1_1
I0726 14:13:31.638860 31263 net.cpp:408] conv1_2 -> conv1_2
I0726 14:13:31.639678 31263 net.cpp:150] Setting up conv1_2
I0726 14:13:31.639700 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.639714 31263 net.cpp:165] Memory required for data: 622080416
I0726 14:13:31.639744 31263 layer_factory.hpp:77] Creating layer relu1_2
I0726 14:13:31.639757 31263 net.cpp:100] Creating Layer relu1_2
I0726 14:13:31.639770 31263 net.cpp:434] relu1_2 <- conv1_2
I0726 14:13:31.639783 31263 net.cpp:395] relu1_2 -> conv1_2 (in-place)
I0726 14:13:31.639803 31263 net.cpp:150] Setting up relu1_2
I0726 14:13:31.639818 31263 net.cpp:157] Top shape: 8 64 300 300 (46080000)
I0726 14:13:31.639832 31263 net.cpp:165] Memory required for data: 806400416
I0726 14:13:31.639842 31263 layer_factory.hpp:77] Creating layer pool1
I0726 14:13:31.639856 31263 net.cpp:100] Creating Layer pool1
I0726 14:13:31.639868 31263 net.cpp:434] pool1 <- conv1_2
I0726 14:13:31.639883 31263 net.cpp:408] pool1 -> pool1
I0726 14:13:31.639933 31263 net.cpp:150] Setting up pool1
I0726 14:13:31.639950 31263 net.cpp:157] Top shape: 8 64 150 150 (11520000)
I0726 14:13:31.639961 31263 net.cpp:165] Memory required for data: 852480416
I0726 14:13:31.639971 31263 layer_factory.hpp:77] Creating layer conv2_1
I0726 14:13:31.639988 31263 net.cpp:100] Creating Layer conv2_1
I0726 14:13:31.639999 31263 net.cpp:434] conv2_1 <- pool1
I0726 14:13:31.640014 31263 net.cpp:408] conv2_1 -> conv2_1
I0726 14:13:31.641132 31263 net.cpp:150] Setting up conv2_1
I0726 14:13:31.641162 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.641175 31263 net.cpp:165] Memory required for data: 944640416
I0726 14:13:31.641192 31263 layer_factory.hpp:77] Creating layer relu2_1
I0726 14:13:31.641208 31263 net.cpp:100] Creating Layer relu2_1
I0726 14:13:31.641221 31263 net.cpp:434] relu2_1 <- conv2_1
I0726 14:13:31.641233 31263 net.cpp:395] relu2_1 -> conv2_1 (in-place)
I0726 14:13:31.641248 31263 net.cpp:150] Setting up relu2_1
I0726 14:13:31.641263 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.641273 31263 net.cpp:165] Memory required for data: 1036800416
I0726 14:13:31.641284 31263 layer_factory.hpp:77] Creating layer conv2_2
I0726 14:13:31.641300 31263 net.cpp:100] Creating Layer conv2_2
I0726 14:13:31.641312 31263 net.cpp:434] conv2_2 <- conv2_1
I0726 14:13:31.641327 31263 net.cpp:408] conv2_2 -> conv2_2
I0726 14:13:31.643816 31263 net.cpp:150] Setting up conv2_2
I0726 14:13:31.643856 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.643872 31263 net.cpp:165] Memory required for data: 1128960416
I0726 14:13:31.643887 31263 layer_factory.hpp:77] Creating layer relu2_2
I0726 14:13:31.643900 31263 net.cpp:100] Creating Layer relu2_2
I0726 14:13:31.643913 31263 net.cpp:434] relu2_2 <- conv2_2
I0726 14:13:31.643925 31263 net.cpp:395] relu2_2 -> conv2_2 (in-place)
I0726 14:13:31.643949 31263 net.cpp:150] Setting up relu2_2
I0726 14:13:31.643973 31263 net.cpp:157] Top shape: 8 128 150 150 (23040000)
I0726 14:13:31.643985 31263 net.cpp:165] Memory required for data: 1221120416
I0726 14:13:31.643996 31263 layer_factory.hpp:77] Creating layer pool2
I0726 14:13:31.644008 31263 net.cpp:100] Creating Layer pool2
I0726 14:13:31.644021 31263 net.cpp:434] pool2 <- conv2_2
I0726 14:13:31.644033 31263 net.cpp:408] pool2 -> pool2
I0726 14:13:31.644083 31263 net.cpp:150] Setting up pool2
I0726 14:13:31.644098 31263 net.cpp:157] Top shape: 8 128 75 75 (5760000)
I0726 14:13:31.644109 31263 net.cpp:165] Memory required for data: 1244160416
I0726 14:13:31.644120 31263 layer_factory.hpp:77] Creating layer conv3_1
I0726 14:13:31.644143 31263 net.cpp:100] Creating Layer conv3_1
I0726 14:13:31.644155 31263 net.cpp:434] conv3_1 <- pool2
I0726 14:13:31.644168 31263 net.cpp:408] conv3_1 -> conv3_1
I0726 14:13:31.648674 31263 net.cpp:150] Setting up conv3_1
I0726 14:13:31.648733 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.648747 31263 net.cpp:165] Memory required for data: 1290240416
I0726 14:13:31.648769 31263 layer_factory.hpp:77] Creating layer relu3_1
I0726 14:13:31.648792 31263 net.cpp:100] Creating Layer relu3_1
I0726 14:13:31.648805 31263 net.cpp:434] relu3_1 <- conv3_1
I0726 14:13:31.648836 31263 net.cpp:395] relu3_1 -> conv3_1 (in-place)
I0726 14:13:31.648855 31263 net.cpp:150] Setting up relu3_1
I0726 14:13:31.648869 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.648880 31263 net.cpp:165] Memory required for data: 1336320416
I0726 14:13:31.648890 31263 layer_factory.hpp:77] Creating layer conv3_2
I0726 14:13:31.648905 31263 net.cpp:100] Creating Layer conv3_2
I0726 14:13:31.648917 31263 net.cpp:434] conv3_2 <- conv3_1
I0726 14:13:31.648931 31263 net.cpp:408] conv3_2 -> conv3_2
I0726 14:13:31.656383 31263 net.cpp:150] Setting up conv3_2
I0726 14:13:31.656442 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.656456 31263 net.cpp:165] Memory required for data: 1382400416
I0726 14:13:31.656486 31263 layer_factory.hpp:77] Creating layer relu3_2
I0726 14:13:31.656500 31263 net.cpp:100] Creating Layer relu3_2
I0726 14:13:31.656512 31263 net.cpp:434] relu3_2 <- conv3_2
I0726 14:13:31.656524 31263 net.cpp:395] relu3_2 -> conv3_2 (in-place)
I0726 14:13:31.656541 31263 net.cpp:150] Setting up relu3_2
I0726 14:13:31.656561 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.656570 31263 net.cpp:165] Memory required for data: 1428480416
I0726 14:13:31.656580 31263 layer_factory.hpp:77] Creating layer conv3_3
I0726 14:13:31.656599 31263 net.cpp:100] Creating Layer conv3_3
I0726 14:13:31.656610 31263 net.cpp:434] conv3_3 <- conv3_2
I0726 14:13:31.656621 31263 net.cpp:408] conv3_3 -> conv3_3
I0726 14:13:31.664482 31263 net.cpp:150] Setting up conv3_3
I0726 14:13:31.664554 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.664567 31263 net.cpp:165] Memory required for data: 1474560416
I0726 14:13:31.664587 31263 layer_factory.hpp:77] Creating layer relu3_3
I0726 14:13:31.664629 31263 net.cpp:100] Creating Layer relu3_3
I0726 14:13:31.664640 31263 net.cpp:434] relu3_3 <- conv3_3
I0726 14:13:31.664654 31263 net.cpp:395] relu3_3 -> conv3_3 (in-place)
I0726 14:13:31.664671 31263 net.cpp:150] Setting up relu3_3
I0726 14:13:31.664681 31263 net.cpp:157] Top shape: 8 256 75 75 (11520000)
I0726 14:13:31.664691 31263 net.cpp:165] Memory required for data: 1520640416
I0726 14:13:31.664700 31263 layer_factory.hpp:77] Creating layer pool3
I0726 14:13:31.664711 31263 net.cpp:100] Creating Layer pool3
I0726 14:13:31.664721 31263 net.cpp:434] pool3 <- conv3_3
I0726 14:13:31.664733 31263 net.cpp:408] pool3 -> pool3
I0726 14:13:31.664785 31263 net.cpp:150] Setting up pool3
I0726 14:13:31.664798 31263 net.cpp:157] Top shape: 8 256 38 38 (2957312)
I0726 14:13:31.664808 31263 net.cpp:165] Memory required for data: 1532469664
I0726 14:13:31.664818 31263 layer_factory.hpp:77] Creating layer conv4_1
I0726 14:13:31.664840 31263 net.cpp:100] Creating Layer conv4_1
I0726 14:13:31.664863 31263 net.cpp:434] conv4_1 <- pool3
I0726 14:13:31.664890 31263 net.cpp:408] conv4_1 -> conv4_1
I0726 14:13:31.679460 31263 net.cpp:150] Setting up conv4_1
I0726 14:13:31.679556 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.679570 31263 net.cpp:165] Memory required for data: 1556128160
I0726 14:13:31.679589 31263 layer_factory.hpp:77] Creating layer relu4_1
I0726 14:13:31.679610 31263 net.cpp:100] Creating Layer relu4_1
I0726 14:13:31.679622 31263 net.cpp:434] relu4_1 <- conv4_1
I0726 14:13:31.679636 31263 net.cpp:395] relu4_1 -> conv4_1 (in-place)
I0726 14:13:31.679653 31263 net.cpp:150] Setting up relu4_1
I0726 14:13:31.679666 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.679674 31263 net.cpp:165] Memory required for data: 1579786656
I0726 14:13:31.679684 31263 layer_factory.hpp:77] Creating layer conv4_2
I0726 14:13:31.679702 31263 net.cpp:100] Creating Layer conv4_2
I0726 14:13:31.679711 31263 net.cpp:434] conv4_2 <- conv4_1
I0726 14:13:31.679723 31263 net.cpp:408] conv4_2 -> conv4_2
I0726 14:13:31.707685 31263 net.cpp:150] Setting up conv4_2
I0726 14:13:31.707798 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.707814 31263 net.cpp:165] Memory required for data: 1603445152
I0726 14:13:31.707868 31263 layer_factory.hpp:77] Creating layer relu4_2
I0726 14:13:31.707885 31263 net.cpp:100] Creating Layer relu4_2
I0726 14:13:31.707896 31263 net.cpp:434] relu4_2 <- conv4_2
I0726 14:13:31.707911 31263 net.cpp:395] relu4_2 -> conv4_2 (in-place)
I0726 14:13:31.707927 31263 net.cpp:150] Setting up relu4_2
I0726 14:13:31.707938 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.707947 31263 net.cpp:165] Memory required for data: 1627103648
I0726 14:13:31.707957 31263 layer_factory.hpp:77] Creating layer conv4_3
I0726 14:13:31.707974 31263 net.cpp:100] Creating Layer conv4_3
I0726 14:13:31.707984 31263 net.cpp:434] conv4_3 <- conv4_2
I0726 14:13:31.707996 31263 net.cpp:408] conv4_3 -> conv4_3
I0726 14:13:31.736480 31263 net.cpp:150] Setting up conv4_3
I0726 14:13:31.736568 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.736582 31263 net.cpp:165] Memory required for data: 1650762144
I0726 14:13:31.736599 31263 layer_factory.hpp:77] Creating layer relu4_3
I0726 14:13:31.736614 31263 net.cpp:100] Creating Layer relu4_3
I0726 14:13:31.736625 31263 net.cpp:434] relu4_3 <- conv4_3
I0726 14:13:31.736659 31263 net.cpp:395] relu4_3 -> conv4_3 (in-place)
I0726 14:13:31.736680 31263 net.cpp:150] Setting up relu4_3
I0726 14:13:31.736692 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.736701 31263 net.cpp:165] Memory required for data: 1674420640
I0726 14:13:31.736711 31263 layer_factory.hpp:77] Creating layer conv4_3_relu4_3_0_split
I0726 14:13:31.736721 31263 net.cpp:100] Creating Layer conv4_3_relu4_3_0_split
I0726 14:13:31.736732 31263 net.cpp:434] conv4_3_relu4_3_0_split <- conv4_3
I0726 14:13:31.736744 31263 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_0
I0726 14:13:31.736757 31263 net.cpp:408] conv4_3_relu4_3_0_split -> conv4_3_relu4_3_0_split_1
I0726 14:13:31.736806 31263 net.cpp:150] Setting up conv4_3_relu4_3_0_split
I0726 14:13:31.736819 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.736830 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.736841 31263 net.cpp:165] Memory required for data: 1721737632
I0726 14:13:31.736851 31263 layer_factory.hpp:77] Creating layer pool4
I0726 14:13:31.736863 31263 net.cpp:100] Creating Layer pool4
I0726 14:13:31.736873 31263 net.cpp:434] pool4 <- conv4_3_relu4_3_0_split_0
I0726 14:13:31.736886 31263 net.cpp:408] pool4 -> pool4
I0726 14:13:31.736927 31263 net.cpp:150] Setting up pool4
I0726 14:13:31.736941 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.736950 31263 net.cpp:165] Memory required for data: 1727652256
I0726 14:13:31.736960 31263 layer_factory.hpp:77] Creating layer conv5_1
I0726 14:13:31.736976 31263 net.cpp:100] Creating Layer conv5_1
I0726 14:13:31.736995 31263 net.cpp:434] conv5_1 <- pool4
I0726 14:13:31.737022 31263 net.cpp:408] conv5_1 -> conv5_1
I0726 14:13:31.771160 31263 net.cpp:150] Setting up conv5_1
I0726 14:13:31.771226 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.771241 31263 net.cpp:165] Memory required for data: 1733566880
I0726 14:13:31.771260 31263 layer_factory.hpp:77] Creating layer relu5_1
I0726 14:13:31.771282 31263 net.cpp:100] Creating Layer relu5_1
I0726 14:13:31.771296 31263 net.cpp:434] relu5_1 <- conv5_1
I0726 14:13:31.771311 31263 net.cpp:395] relu5_1 -> conv5_1 (in-place)
I0726 14:13:31.771340 31263 net.cpp:150] Setting up relu5_1
I0726 14:13:31.771354 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.771365 31263 net.cpp:165] Memory required for data: 1739481504
I0726 14:13:31.771376 31263 layer_factory.hpp:77] Creating layer conv5_2
I0726 14:13:31.771394 31263 net.cpp:100] Creating Layer conv5_2
I0726 14:13:31.771405 31263 net.cpp:434] conv5_2 <- conv5_1
I0726 14:13:31.771453 31263 net.cpp:408] conv5_2 -> conv5_2
I0726 14:13:31.799942 31263 net.cpp:150] Setting up conv5_2
I0726 14:13:31.800130 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.800144 31263 net.cpp:165] Memory required for data: 1745396128
I0726 14:13:31.800174 31263 layer_factory.hpp:77] Creating layer relu5_2
I0726 14:13:31.800199 31263 net.cpp:100] Creating Layer relu5_2
I0726 14:13:31.800235 31263 net.cpp:434] relu5_2 <- conv5_2
I0726 14:13:31.800256 31263 net.cpp:395] relu5_2 -> conv5_2 (in-place)
I0726 14:13:31.800287 31263 net.cpp:150] Setting up relu5_2
I0726 14:13:31.800299 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.800308 31263 net.cpp:165] Memory required for data: 1751310752
I0726 14:13:31.800318 31263 layer_factory.hpp:77] Creating layer conv5_3
I0726 14:13:31.800339 31263 net.cpp:100] Creating Layer conv5_3
I0726 14:13:31.800351 31263 net.cpp:434] conv5_3 <- conv5_2
I0726 14:13:31.800366 31263 net.cpp:408] conv5_3 -> conv5_3
I0726 14:13:31.830325 31263 net.cpp:150] Setting up conv5_3
I0726 14:13:31.830420 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.830435 31263 net.cpp:165] Memory required for data: 1757225376
I0726 14:13:31.830451 31263 layer_factory.hpp:77] Creating layer relu5_3
I0726 14:13:31.830469 31263 net.cpp:100] Creating Layer relu5_3
I0726 14:13:31.830487 31263 net.cpp:434] relu5_3 <- conv5_3
I0726 14:13:31.830502 31263 net.cpp:395] relu5_3 -> conv5_3 (in-place)
I0726 14:13:31.830519 31263 net.cpp:150] Setting up relu5_3
I0726 14:13:31.830530 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.830539 31263 net.cpp:165] Memory required for data: 1763140000
I0726 14:13:31.830549 31263 layer_factory.hpp:77] Creating layer pool5
I0726 14:13:31.830561 31263 net.cpp:100] Creating Layer pool5
I0726 14:13:31.830571 31263 net.cpp:434] pool5 <- conv5_3
I0726 14:13:31.830582 31263 net.cpp:408] pool5 -> pool5
I0726 14:13:31.830651 31263 net.cpp:150] Setting up pool5
I0726 14:13:31.830663 31263 net.cpp:157] Top shape: 8 512 19 19 (1478656)
I0726 14:13:31.830672 31263 net.cpp:165] Memory required for data: 1769054624
I0726 14:13:31.830682 31263 layer_factory.hpp:77] Creating layer fc6
I0726 14:13:31.830698 31263 net.cpp:100] Creating Layer fc6
I0726 14:13:31.830708 31263 net.cpp:434] fc6 <- pool5
I0726 14:13:31.830720 31263 net.cpp:408] fc6 -> fc6
I0726 14:13:31.889031 31263 net.cpp:150] Setting up fc6
I0726 14:13:31.889438 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.889473 31263 net.cpp:165] Memory required for data: 1780883872
I0726 14:13:31.889528 31263 layer_factory.hpp:77] Creating layer relu6
I0726 14:13:31.889581 31263 net.cpp:100] Creating Layer relu6
I0726 14:13:31.889636 31263 net.cpp:434] relu6 <- fc6
I0726 14:13:31.889683 31263 net.cpp:395] relu6 -> fc6 (in-place)
I0726 14:13:31.889763 31263 net.cpp:150] Setting up relu6
I0726 14:13:31.889856 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.889875 31263 net.cpp:165] Memory required for data: 1792713120
I0726 14:13:31.889945 31263 layer_factory.hpp:77] Creating layer fc7
I0726 14:13:31.890189 31263 net.cpp:100] Creating Layer fc7
I0726 14:13:31.890211 31263 net.cpp:434] fc7 <- fc6
I0726 14:13:31.890239 31263 net.cpp:408] fc7 -> fc7
I0726 14:13:31.903575 31263 net.cpp:150] Setting up fc7
I0726 14:13:31.903648 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.903661 31263 net.cpp:165] Memory required for data: 1804542368
I0726 14:13:31.903681 31263 layer_factory.hpp:77] Creating layer relu7
I0726 14:13:31.903697 31263 net.cpp:100] Creating Layer relu7
I0726 14:13:31.903708 31263 net.cpp:434] relu7 <- fc7
I0726 14:13:31.903723 31263 net.cpp:395] relu7 -> fc7 (in-place)
I0726 14:13:31.903740 31263 net.cpp:150] Setting up relu7
I0726 14:13:31.903754 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.903779 31263 net.cpp:165] Memory required for data: 1816371616
I0726 14:13:31.903789 31263 layer_factory.hpp:77] Creating layer fc7_relu7_0_split
I0726 14:13:31.903800 31263 net.cpp:100] Creating Layer fc7_relu7_0_split
I0726 14:13:31.903810 31263 net.cpp:434] fc7_relu7_0_split <- fc7
I0726 14:13:31.903822 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_0
I0726 14:13:31.903836 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_1
I0726 14:13:31.903853 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_2
I0726 14:13:31.903867 31263 net.cpp:408] fc7_relu7_0_split -> fc7_relu7_0_split_3
I0726 14:13:31.903934 31263 net.cpp:150] Setting up fc7_relu7_0_split
I0726 14:13:31.903946 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.903957 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.903967 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.903977 31263 net.cpp:157] Top shape: 8 1024 19 19 (2957312)
I0726 14:13:31.903986 31263 net.cpp:165] Memory required for data: 1863688608
I0726 14:13:31.903996 31263 layer_factory.hpp:77] Creating layer conv6_1
I0726 14:13:31.904012 31263 net.cpp:100] Creating Layer conv6_1
I0726 14:13:31.904022 31263 net.cpp:434] conv6_1 <- fc7_relu7_0_split_0
I0726 14:13:31.904034 31263 net.cpp:408] conv6_1 -> conv6_1
I0726 14:13:31.907891 31263 net.cpp:150] Setting up conv6_1
I0726 14:13:31.907933 31263 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0726 14:13:31.907944 31263 net.cpp:165] Memory required for data: 1866645920
I0726 14:13:31.907959 31263 layer_factory.hpp:77] Creating layer conv6_1_relu
I0726 14:13:31.907979 31263 net.cpp:100] Creating Layer conv6_1_relu
I0726 14:13:31.907989 31263 net.cpp:434] conv6_1_relu <- conv6_1
I0726 14:13:31.908001 31263 net.cpp:395] conv6_1_relu -> conv6_1 (in-place)
I0726 14:13:31.908017 31263 net.cpp:150] Setting up conv6_1_relu
I0726 14:13:31.908030 31263 net.cpp:157] Top shape: 8 256 19 19 (739328)
I0726 14:13:31.908038 31263 net.cpp:165] Memory required for data: 1869603232
I0726 14:13:31.908048 31263 layer_factory.hpp:77] Creating layer conv6_2
I0726 14:13:31.908063 31263 net.cpp:100] Creating Layer conv6_2
I0726 14:13:31.908076 31263 net.cpp:434] conv6_2 <- conv6_1
I0726 14:13:31.908098 31263 net.cpp:408] conv6_2 -> conv6_2
I0726 14:13:31.922897 31263 net.cpp:150] Setting up conv6_2
I0726 14:13:31.923002 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.923015 31263 net.cpp:165] Memory required for data: 1871241632
I0726 14:13:31.923043 31263 layer_factory.hpp:77] Creating layer conv6_2_relu
I0726 14:13:31.923058 31263 net.cpp:100] Creating Layer conv6_2_relu
I0726 14:13:31.923074 31263 net.cpp:434] conv6_2_relu <- conv6_2
I0726 14:13:31.923090 31263 net.cpp:395] conv6_2_relu -> conv6_2 (in-place)
I0726 14:13:31.923107 31263 net.cpp:150] Setting up conv6_2_relu
I0726 14:13:31.923118 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.923127 31263 net.cpp:165] Memory required for data: 1872880032
I0726 14:13:31.923142 31263 layer_factory.hpp:77] Creating layer conv6_2_conv6_2_relu_0_split
I0726 14:13:31.923161 31263 net.cpp:100] Creating Layer conv6_2_conv6_2_relu_0_split
I0726 14:13:31.923171 31263 net.cpp:434] conv6_2_conv6_2_relu_0_split <- conv6_2
I0726 14:13:31.923192 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_0
I0726 14:13:31.923234 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_1
I0726 14:13:31.923247 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_2
I0726 14:13:31.923259 31263 net.cpp:408] conv6_2_conv6_2_relu_0_split -> conv6_2_conv6_2_relu_0_split_3
I0726 14:13:31.923346 31263 net.cpp:150] Setting up conv6_2_conv6_2_relu_0_split
I0726 14:13:31.923358 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.923368 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.923378 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.923388 31263 net.cpp:157] Top shape: 8 512 10 10 (409600)
I0726 14:13:31.923403 31263 net.cpp:165] Memory required for data: 1879433632
I0726 14:13:31.923425 31263 layer_factory.hpp:77] Creating layer conv7_1
I0726 14:13:31.923447 31263 net.cpp:100] Creating Layer conv7_1
I0726 14:13:31.923457 31263 net.cpp:434] conv7_1 <- conv6_2_conv6_2_relu_0_split_0
I0726 14:13:31.923470 31263 net.cpp:408] conv7_1 -> conv7_1
I0726 14:13:31.924386 31263 net.cpp:150] Setting up conv7_1
I0726 14:13:31.924405 31263 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0726 14:13:31.924414 31263 net.cpp:165] Memory required for data: 1879843232
I0726 14:13:31.924427 31263 layer_factory.hpp:77] Creating layer conv7_1_relu
I0726 14:13:31.924443 31263 net.cpp:100] Creating Layer conv7_1_relu
I0726 14:13:31.924453 31263 net.cpp:434] conv7_1_relu <- conv7_1
I0726 14:13:31.924463 31263 net.cpp:395] conv7_1_relu -> conv7_1 (in-place)
I0726 14:13:31.924476 31263 net.cpp:150] Setting up conv7_1_relu
I0726 14:13:31.924486 31263 net.cpp:157] Top shape: 8 128 10 10 (102400)
I0726 14:13:31.924505 31263 net.cpp:165] Memory required for data: 1880252832
I0726 14:13:31.924516 31263 layer_factory.hpp:77] Creating layer conv7_2
I0726 14:13:31.924535 31263 net.cpp:100] Creating Layer conv7_2
I0726 14:13:31.924545 31263 net.cpp:434] conv7_2 <- conv7_1
I0726 14:13:31.924556 31263 net.cpp:408] conv7_2 -> conv7_2
I0726 14:13:31.929446 31263 net.cpp:150] Setting up conv7_2
I0726 14:13:31.929615 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.929641 31263 net.cpp:165] Memory required for data: 1880457632
I0726 14:13:31.929656 31263 layer_factory.hpp:77] Creating layer conv7_2_relu
I0726 14:13:31.929672 31263 net.cpp:100] Creating Layer conv7_2_relu
I0726 14:13:31.929683 31263 net.cpp:434] conv7_2_relu <- conv7_2
I0726 14:13:31.929697 31263 net.cpp:395] conv7_2_relu -> conv7_2 (in-place)
I0726 14:13:31.929715 31263 net.cpp:150] Setting up conv7_2_relu
I0726 14:13:31.929726 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.929736 31263 net.cpp:165] Memory required for data: 1880662432
I0726 14:13:31.929747 31263 layer_factory.hpp:77] Creating layer conv7_2_conv7_2_relu_0_split
I0726 14:13:31.929767 31263 net.cpp:100] Creating Layer conv7_2_conv7_2_relu_0_split
I0726 14:13:31.929777 31263 net.cpp:434] conv7_2_conv7_2_relu_0_split <- conv7_2
I0726 14:13:31.929790 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_0
I0726 14:13:31.929805 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_1
I0726 14:13:31.929818 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_2
I0726 14:13:31.929831 31263 net.cpp:408] conv7_2_conv7_2_relu_0_split -> conv7_2_conv7_2_relu_0_split_3
I0726 14:13:31.929908 31263 net.cpp:150] Setting up conv7_2_conv7_2_relu_0_split
I0726 14:13:31.929920 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.929932 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.929944 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.929956 31263 net.cpp:157] Top shape: 8 256 5 5 (51200)
I0726 14:13:31.929965 31263 net.cpp:165] Memory required for data: 1881481632
I0726 14:13:31.929975 31263 layer_factory.hpp:77] Creating layer conv8_1
I0726 14:13:31.929991 31263 net.cpp:100] Creating Layer conv8_1
I0726 14:13:31.930008 31263 net.cpp:434] conv8_1 <- conv7_2_conv7_2_relu_0_split_0
I0726 14:13:31.930032 31263 net.cpp:408] conv8_1 -> conv8_1
I0726 14:13:31.930609 31263 net.cpp:150] Setting up conv8_1
I0726 14:13:31.930625 31263 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0726 14:13:31.930636 31263 net.cpp:165] Memory required for data: 1881584032
I0726 14:13:31.930652 31263 layer_factory.hpp:77] Creating layer conv8_1_relu
I0726 14:13:31.930667 31263 net.cpp:100] Creating Layer conv8_1_relu
I0726 14:13:31.930678 31263 net.cpp:434] conv8_1_relu <- conv8_1
I0726 14:13:31.930691 31263 net.cpp:395] conv8_1_relu -> conv8_1 (in-place)
I0726 14:13:31.930703 31263 net.cpp:150] Setting up conv8_1_relu
I0726 14:13:31.930716 31263 net.cpp:157] Top shape: 8 128 5 5 (25600)
I0726 14:13:31.930724 31263 net.cpp:165] Memory required for data: 1881686432
I0726 14:13:31.930734 31263 layer_factory.hpp:77] Creating layer conv8_2
I0726 14:13:31.930748 31263 net.cpp:100] Creating Layer conv8_2
I0726 14:13:31.930758 31263 net.cpp:434] conv8_2 <- conv8_1
I0726 14:13:31.930771 31263 net.cpp:408] conv8_2 -> conv8_2
I0726 14:13:31.934896 31263 net.cpp:150] Setting up conv8_2
I0726 14:13:31.934939 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.934952 31263 net.cpp:165] Memory required for data: 1881760160
I0726 14:13:31.934965 31263 layer_factory.hpp:77] Creating layer conv8_2_relu
I0726 14:13:31.934980 31263 net.cpp:100] Creating Layer conv8_2_relu
I0726 14:13:31.934993 31263 net.cpp:434] conv8_2_relu <- conv8_2
I0726 14:13:31.935004 31263 net.cpp:395] conv8_2_relu -> conv8_2 (in-place)
I0726 14:13:31.935020 31263 net.cpp:150] Setting up conv8_2_relu
I0726 14:13:31.935039 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.935050 31263 net.cpp:165] Memory required for data: 1881833888
I0726 14:13:31.935058 31263 layer_factory.hpp:77] Creating layer conv8_2_conv8_2_relu_0_split
I0726 14:13:31.935070 31263 net.cpp:100] Creating Layer conv8_2_conv8_2_relu_0_split
I0726 14:13:31.935081 31263 net.cpp:434] conv8_2_conv8_2_relu_0_split <- conv8_2
I0726 14:13:31.935092 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_0
I0726 14:13:31.935106 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_1
I0726 14:13:31.935117 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_2
I0726 14:13:31.935132 31263 net.cpp:408] conv8_2_conv8_2_relu_0_split -> conv8_2_conv8_2_relu_0_split_3
I0726 14:13:31.935220 31263 net.cpp:150] Setting up conv8_2_conv8_2_relu_0_split
I0726 14:13:31.935232 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.935243 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.935255 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.935264 31263 net.cpp:157] Top shape: 8 256 3 3 (18432)
I0726 14:13:31.935272 31263 net.cpp:165] Memory required for data: 1882128800
I0726 14:13:31.935282 31263 layer_factory.hpp:77] Creating layer conv9_1
I0726 14:13:31.935297 31263 net.cpp:100] Creating Layer conv9_1
I0726 14:13:31.935307 31263 net.cpp:434] conv9_1 <- conv8_2_conv8_2_relu_0_split_0
I0726 14:13:31.935320 31263 net.cpp:408] conv9_1 -> conv9_1
I0726 14:13:31.936851 31263 net.cpp:150] Setting up conv9_1
I0726 14:13:31.936882 31263 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0726 14:13:31.936892 31263 net.cpp:165] Memory required for data: 1882165664
I0726 14:13:31.936906 31263 layer_factory.hpp:77] Creating layer conv9_1_relu
I0726 14:13:31.936919 31263 net.cpp:100] Creating Layer conv9_1_relu
I0726 14:13:31.936930 31263 net.cpp:434] conv9_1_relu <- conv9_1
I0726 14:13:31.936941 31263 net.cpp:395] conv9_1_relu -> conv9_1 (in-place)
I0726 14:13:31.936956 31263 net.cpp:150] Setting up conv9_1_relu
I0726 14:13:31.936967 31263 net.cpp:157] Top shape: 8 128 3 3 (9216)
I0726 14:13:31.936978 31263 net.cpp:165] Memory required for data: 1882202528
I0726 14:13:31.936987 31263 layer_factory.hpp:77] Creating layer conv9_2
I0726 14:13:31.937002 31263 net.cpp:100] Creating Layer conv9_2
I0726 14:13:31.937012 31263 net.cpp:434] conv9_2 <- conv9_1
I0726 14:13:31.937031 31263 net.cpp:408] conv9_2 -> conv9_2
I0726 14:13:31.941581 31263 net.cpp:150] Setting up conv9_2
I0726 14:13:31.941644 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.941658 31263 net.cpp:165] Memory required for data: 1882210720
I0726 14:13:31.941673 31263 layer_factory.hpp:77] Creating layer conv9_2_relu
I0726 14:13:31.941694 31263 net.cpp:100] Creating Layer conv9_2_relu
I0726 14:13:31.941709 31263 net.cpp:434] conv9_2_relu <- conv9_2
I0726 14:13:31.941723 31263 net.cpp:395] conv9_2_relu -> conv9_2 (in-place)
I0726 14:13:31.941742 31263 net.cpp:150] Setting up conv9_2_relu
I0726 14:13:31.941753 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.941762 31263 net.cpp:165] Memory required for data: 1882218912
I0726 14:13:31.941772 31263 layer_factory.hpp:77] Creating layer conv9_2_conv9_2_relu_0_split
I0726 14:13:31.941788 31263 net.cpp:100] Creating Layer conv9_2_conv9_2_relu_0_split
I0726 14:13:31.941798 31263 net.cpp:434] conv9_2_conv9_2_relu_0_split <- conv9_2
I0726 14:13:31.941814 31263 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_0
I0726 14:13:31.941828 31263 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_1
I0726 14:13:31.941845 31263 net.cpp:408] conv9_2_conv9_2_relu_0_split -> conv9_2_conv9_2_relu_0_split_2
I0726 14:13:31.941936 31263 net.cpp:150] Setting up conv9_2_conv9_2_relu_0_split
I0726 14:13:31.941952 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.941967 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.941980 31263 net.cpp:157] Top shape: 8 256 1 1 (2048)
I0726 14:13:31.941992 31263 net.cpp:165] Memory required for data: 1882243488
I0726 14:13:31.942001 31263 layer_factory.hpp:77] Creating layer conv4_3_norm
I0726 14:13:31.942018 31263 net.cpp:100] Creating Layer conv4_3_norm
I0726 14:13:31.942030 31263 net.cpp:434] conv4_3_norm <- conv4_3_relu4_3_0_split_1
I0726 14:13:31.942049 31263 net.cpp:408] conv4_3_norm -> conv4_3_norm
I0726 14:13:31.942312 31263 net.cpp:150] Setting up conv4_3_norm
I0726 14:13:31.942334 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.942347 31263 net.cpp:165] Memory required for data: 1905901984
I0726 14:13:31.942359 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_conv4_3_norm_0_split
I0726 14:13:31.942373 31263 net.cpp:100] Creating Layer conv4_3_norm_conv4_3_norm_0_split
I0726 14:13:31.942385 31263 net.cpp:434] conv4_3_norm_conv4_3_norm_0_split <- conv4_3_norm
I0726 14:13:31.942401 31263 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_0
I0726 14:13:31.942417 31263 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_1
I0726 14:13:31.942435 31263 net.cpp:408] conv4_3_norm_conv4_3_norm_0_split -> conv4_3_norm_conv4_3_norm_0_split_2
I0726 14:13:31.942512 31263 net.cpp:150] Setting up conv4_3_norm_conv4_3_norm_0_split
I0726 14:13:31.942528 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.942541 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.942555 31263 net.cpp:157] Top shape: 8 512 38 38 (5914624)
I0726 14:13:31.942564 31263 net.cpp:165] Memory required for data: 1976877472
I0726 14:13:31.942579 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc
I0726 14:13:31.942598 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc
I0726 14:13:31.942611 31263 net.cpp:434] conv4_3_norm_mbox_loc <- conv4_3_norm_conv4_3_norm_0_split_0
I0726 14:13:31.942627 31263 net.cpp:408] conv4_3_norm_mbox_loc -> conv4_3_norm_mbox_loc
I0726 14:13:31.943960 31263 net.cpp:150] Setting up conv4_3_norm_mbox_loc
I0726 14:13:31.943979 31263 net.cpp:157] Top shape: 8 16 38 38 (184832)
I0726 14:13:31.943990 31263 net.cpp:165] Memory required for data: 1977616800
I0726 14:13:31.944007 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_perm
I0726 14:13:31.944020 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_perm
I0726 14:13:31.944033 31263 net.cpp:434] conv4_3_norm_mbox_loc_perm <- conv4_3_norm_mbox_loc
I0726 14:13:31.944054 31263 net.cpp:408] conv4_3_norm_mbox_loc_perm -> conv4_3_norm_mbox_loc_perm
I0726 14:13:31.944211 31263 net.cpp:150] Setting up conv4_3_norm_mbox_loc_perm
I0726 14:13:31.944228 31263 net.cpp:157] Top shape: 8 38 38 16 (184832)
I0726 14:13:31.944242 31263 net.cpp:165] Memory required for data: 1978356128
I0726 14:13:31.944252 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_loc_flat
I0726 14:13:31.944269 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_loc_flat
I0726 14:13:31.944283 31263 net.cpp:434] conv4_3_norm_mbox_loc_flat <- conv4_3_norm_mbox_loc_perm
I0726 14:13:31.944301 31263 net.cpp:408] conv4_3_norm_mbox_loc_flat -> conv4_3_norm_mbox_loc_flat
I0726 14:13:31.944355 31263 net.cpp:150] Setting up conv4_3_norm_mbox_loc_flat
I0726 14:13:31.944372 31263 net.cpp:157] Top shape: 8 23104 (184832)
I0726 14:13:31.944387 31263 net.cpp:165] Memory required for data: 1979095456
I0726 14:13:31.944398 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf
I0726 14:13:31.944429 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf
I0726 14:13:31.944442 31263 net.cpp:434] conv4_3_norm_mbox_conf <- conv4_3_norm_conv4_3_norm_0_split_1
I0726 14:13:31.944461 31263 net.cpp:408] conv4_3_norm_mbox_conf -> conv4_3_norm_mbox_conf
I0726 14:13:32.007657 31263 net.cpp:150] Setting up conv4_3_norm_mbox_conf
I0726 14:13:32.007721 31263 net.cpp:157] Top shape: 8 236 38 38 (2726272)
I0726 14:13:32.007736 31263 net.cpp:165] Memory required for data: 1990000544
I0726 14:13:32.007760 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_perm
I0726 14:13:32.007778 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_perm
I0726 14:13:32.007810 31263 net.cpp:434] conv4_3_norm_mbox_conf_perm <- conv4_3_norm_mbox_conf
I0726 14:13:32.007827 31263 net.cpp:408] conv4_3_norm_mbox_conf_perm -> conv4_3_norm_mbox_conf_perm
I0726 14:13:32.007962 31263 net.cpp:150] Setting up conv4_3_norm_mbox_conf_perm
I0726 14:13:32.007977 31263 net.cpp:157] Top shape: 8 38 38 236 (2726272)
I0726 14:13:32.007987 31263 net.cpp:165] Memory required for data: 2000905632
I0726 14:13:32.007997 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_conf_flat
I0726 14:13:32.008013 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_conf_flat
I0726 14:13:32.008023 31263 net.cpp:434] conv4_3_norm_mbox_conf_flat <- conv4_3_norm_mbox_conf_perm
I0726 14:13:32.008039 31263 net.cpp:408] conv4_3_norm_mbox_conf_flat -> conv4_3_norm_mbox_conf_flat
I0726 14:13:32.008076 31263 net.cpp:150] Setting up conv4_3_norm_mbox_conf_flat
I0726 14:13:32.008091 31263 net.cpp:157] Top shape: 8 340784 (2726272)
I0726 14:13:32.008100 31263 net.cpp:165] Memory required for data: 2011810720
I0726 14:13:32.008110 31263 layer_factory.hpp:77] Creating layer conv4_3_norm_mbox_priorbox
I0726 14:13:32.008126 31263 net.cpp:100] Creating Layer conv4_3_norm_mbox_priorbox
I0726 14:13:32.008136 31263 net.cpp:434] conv4_3_norm_mbox_priorbox <- conv4_3_norm_conv4_3_norm_0_split_2
I0726 14:13:32.008152 31263 net.cpp:434] conv4_3_norm_mbox_priorbox <- data_data_0_split_1
I0726 14:13:32.008163 31263 net.cpp:408] conv4_3_norm_mbox_priorbox -> conv4_3_norm_mbox_priorbox
I0726 14:13:32.008200 31263 net.cpp:150] Setting up conv4_3_norm_mbox_priorbox
I0726 14:13:32.008214 31263 net.cpp:157] Top shape: 1 2 23104 (46208)
I0726 14:13:32.008224 31263 net.cpp:165] Memory required for data: 2011995552
I0726 14:13:32.008232 31263 layer_factory.hpp:77] Creating layer fc7_mbox_loc
I0726 14:13:32.008263 31263 net.cpp:100] Creating Layer fc7_mbox_loc
I0726 14:13:32.008275 31263 net.cpp:434] fc7_mbox_loc <- fc7_relu7_0_split_1
I0726 14:13:32.008288 31263 net.cpp:408] fc7_mbox_loc -> fc7_mbox_loc
I0726 14:13:32.011623 31263 net.cpp:150] Setting up fc7_mbox_loc
I0726 14:13:32.011647 31263 net.cpp:157] Top shape: 8 24 19 19 (69312)
I0726 14:13:32.011659 31263 net.cpp:165] Memory required for data: 2012272800
I0726 14:13:32.011687 31263 layer_factory.hpp:77] Creating layer fc7_mbox_loc_perm
I0726 14:13:32.011703 31263 net.cpp:100] Creating Layer fc7_mbox_loc_perm
I0726 14:13:32.011729 31263 net.cpp:434] fc7_mbox_loc_perm <- fc7_mbox_loc
I0726 14:13:32.011768 31263 net.cpp:408] fc7_mbox_loc_perm -> fc7_mbox_loc_perm
I0726 14:13:32.011986 31263 net.cpp:150] Setting up fc7_mbox_loc_perm
I0726 14:13:32.012006 31263 net.cpp:157] Top shape: 8 19 19 24 (69312)
I0726 14:13:32.012019 31263 net.cpp:165] Memory required for data: 2012550048
I0726 14:13:32.012033 31263 layer_factory.hpp:77] Creating layer fc7_mbox_loc_flat
I0726 14:13:32.012051 31263 net.cpp:100] Creating Layer fc7_mbox_loc_flat
I0726 14:13:32.012065 31263 net.cpp:434] fc7_mbox_loc_flat <- fc7_mbox_loc_perm
I0726 14:13:32.012081 31263 net.cpp:408] fc7_mbox_loc_flat -> fc7_mbox_loc_flat
I0726 14:13:32.012138 31263 net.cpp:150] Setting up fc7_mbox_loc_flat
I0726 14:13:32.012157 31263 net.cpp:157] Top shape: 8 8664 (69312)
I0726 14:13:32.012171 31263 net.cpp:165] Memory required for data: 2012827296
I0726 14:13:32.012186 31263 layer_factory.hpp:77] Creating layer fc7_mbox_conf
I0726 14:13:32.012212 31263 net.cpp:100] Creating Layer fc7_mbox_conf
I0726 14:13:32.012226 31263 net.cpp:434] fc7_mbox_conf <- fc7_relu7_0_split_2
I0726 14:13:32.012248 31263 net.cpp:408] fc7_mbox_conf -> fc7_mbox_conf
I0726 14:13:32.084367 31263 net.cpp:150] Setting up fc7_mbox_conf
I0726 14:13:32.084408 31263 net.cpp:157] Top shape: 8 354 19 19 (1022352)
I0726 14:13:32.084412 31263 net.cpp:165] Memory required for data: 2016916704
I0726 14:13:32.084430 31263 layer_factory.hpp:77] Creating layer fc7_mbox_conf_perm
I0726 14:13:32.084442 31263 net.cpp:100] Creating Layer fc7_mbox_conf_perm
I0726 14:13:32.084455 31263 net.cpp:434] fc7_mbox_conf_perm <- fc7_mbox_conf
I0726 14:13:32.084467 31263 net.cpp:408] fc7_mbox_conf_perm -> fc7_mbox_conf_perm
I0726 14:13:32.084561 31263 net.cpp:150] Setting up fc7_mbox_conf_perm
I0726 14:13:32.084568 31263 net.cpp:157] Top shape: 8 19 19 354 (1022352)
I0726 14:13:32.084573 31263 net.cpp:165] Memory required for data: 2021006112
I0726 14:13:32.084575 31263 layer_factory.hpp:77] Creating layer fc7_mbox_conf_flat
I0726 14:13:32.084580 31263 net.cpp:100] Creating Layer fc7_mbox_conf_flat
I0726 14:13:32.084588 31263 net.cpp:434] fc7_mbox_conf_flat <- fc7_mbox_conf_perm
I0726 14:13:32.084594 31263 net.cpp:408] fc7_mbox_conf_flat -> fc7_mbox_conf_flat
I0726 14:13:32.084617 31263 net.cpp:150] Setting up fc7_mbox_conf_flat
I0726 14:13:32.084622 31263 net.cpp:157] Top shape: 8 127794 (1022352)
I0726 14:13:32.084630 31263 net.cpp:165] Memory required for data: 2025095520
I0726 14:13:32.084635 31263 layer_factory.hpp:77] Creating layer fc7_mbox_priorbox
I0726 14:13:32.084658 31263 net.cpp:100] Creating Layer fc7_mbox_priorbox
I0726 14:13:32.084666 31263 net.cpp:434] fc7_mbox_priorbox <- fc7_relu7_0_split_3
I0726 14:13:32.084676 31263 net.cpp:434] fc7_mbox_priorbox <- data_data_0_split_2
I0726 14:13:32.084684 31263 net.cpp:408] fc7_mbox_priorbox -> fc7_mbox_priorbox
I0726 14:13:32.084710 31263 net.cpp:150] Setting up fc7_mbox_priorbox
I0726 14:13:32.084717 31263 net.cpp:157] Top shape: 1 2 8664 (17328)
I0726 14:13:32.084719 31263 net.cpp:165] Memory required for data: 2025164832
I0726 14:13:32.084722 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc
I0726 14:13:32.084733 31263 net.cpp:100] Creating Layer conv6_2_mbox_loc
I0726 14:13:32.084738 31263 net.cpp:434] conv6_2_mbox_loc <- conv6_2_conv6_2_relu_0_split_1
I0726 14:13:32.084745 31263 net.cpp:408] conv6_2_mbox_loc -> conv6_2_mbox_loc
I0726 14:13:32.085868 31263 net.cpp:150] Setting up conv6_2_mbox_loc
I0726 14:13:32.085877 31263 net.cpp:157] Top shape: 8 24 10 10 (19200)
I0726 14:13:32.085880 31263 net.cpp:165] Memory required for data: 2025241632
I0726 14:13:32.085888 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_perm
I0726 14:13:32.085896 31263 net.cpp:100] Creating Layer conv6_2_mbox_loc_perm
I0726 14:13:32.085901 31263 net.cpp:434] conv6_2_mbox_loc_perm <- conv6_2_mbox_loc
I0726 14:13:32.085909 31263 net.cpp:408] conv6_2_mbox_loc_perm -> conv6_2_mbox_loc_perm
I0726 14:13:32.085995 31263 net.cpp:150] Setting up conv6_2_mbox_loc_perm
I0726 14:13:32.086001 31263 net.cpp:157] Top shape: 8 10 10 24 (19200)
I0726 14:13:32.086004 31263 net.cpp:165] Memory required for data: 2025318432
I0726 14:13:32.086038 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_loc_flat
I0726 14:13:32.086045 31263 net.cpp:100] Creating Layer conv6_2_mbox_loc_flat
I0726 14:13:32.086053 31263 net.cpp:434] conv6_2_mbox_loc_flat <- conv6_2_mbox_loc_perm
I0726 14:13:32.086058 31263 net.cpp:408] conv6_2_mbox_loc_flat -> conv6_2_mbox_loc_flat
I0726 14:13:32.086083 31263 net.cpp:150] Setting up conv6_2_mbox_loc_flat
I0726 14:13:32.086088 31263 net.cpp:157] Top shape: 8 2400 (19200)
I0726 14:13:32.086094 31263 net.cpp:165] Memory required for data: 2025395232
I0726 14:13:32.086099 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf
I0726 14:13:32.086108 31263 net.cpp:100] Creating Layer conv6_2_mbox_conf
I0726 14:13:32.086113 31263 net.cpp:434] conv6_2_mbox_conf <- conv6_2_conv6_2_relu_0_split_2
I0726 14:13:32.086122 31263 net.cpp:408] conv6_2_mbox_conf -> conv6_2_mbox_conf
I0726 14:13:32.196043 31263 net.cpp:150] Setting up conv6_2_mbox_conf
I0726 14:13:32.196106 31263 net.cpp:157] Top shape: 8 354 10 10 (283200)
I0726 14:13:32.196120 31263 net.cpp:165] Memory required for data: 2026528032
I0726 14:13:32.196148 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_perm
I0726 14:13:32.196174 31263 net.cpp:100] Creating Layer conv6_2_mbox_conf_perm
I0726 14:13:32.196192 31263 net.cpp:434] conv6_2_mbox_conf_perm <- conv6_2_mbox_conf
I0726 14:13:32.196213 31263 net.cpp:408] conv6_2_mbox_conf_perm -> conv6_2_mbox_conf_perm
I0726 14:13:32.196411 31263 net.cpp:150] Setting up conv6_2_mbox_conf_perm
I0726 14:13:32.196429 31263 net.cpp:157] Top shape: 8 10 10 354 (283200)
I0726 14:13:32.196444 31263 net.cpp:165] Memory required for data: 2027660832
I0726 14:13:32.196455 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_conf_flat
I0726 14:13:32.196471 31263 net.cpp:100] Creating Layer conv6_2_mbox_conf_flat
I0726 14:13:32.196490 31263 net.cpp:434] conv6_2_mbox_conf_flat <- conv6_2_mbox_conf_perm
I0726 14:13:32.196506 31263 net.cpp:408] conv6_2_mbox_conf_flat -> conv6_2_mbox_conf_flat
I0726 14:13:32.196557 31263 net.cpp:150] Setting up conv6_2_mbox_conf_flat
I0726 14:13:32.196565 31263 net.cpp:157] Top shape: 8 35400 (283200)
I0726 14:13:32.196583 31263 net.cpp:165] Memory required for data: 2028793632
I0726 14:13:32.196593 31263 layer_factory.hpp:77] Creating layer conv6_2_mbox_priorbox
I0726 14:13:32.196610 31263 net.cpp:100] Creating Layer conv6_2_mbox_priorbox
I0726 14:13:32.196622 31263 net.cpp:434] conv6_2_mbox_priorbox <- conv6_2_conv6_2_relu_0_split_3
I0726 14:13:32.196640 31263 net.cpp:434] conv6_2_mbox_priorbox <- data_data_0_split_3
I0726 14:13:32.196655 31263 net.cpp:408] conv6_2_mbox_priorbox -> conv6_2_mbox_priorbox
I0726 14:13:32.196713 31263 net.cpp:150] Setting up conv6_2_mbox_priorbox
I0726 14:13:32.196729 31263 net.cpp:157] Top shape: 1 2 2400 (4800)
I0726 14:13:32.196741 31263 net.cpp:165] Memory required for data: 2028812832
I0726 14:13:32.196749 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc
I0726 14:13:32.196776 31263 net.cpp:100] Creating Layer conv7_2_mbox_loc
I0726 14:13:32.196782 31263 net.cpp:434] conv7_2_mbox_loc <- conv7_2_conv7_2_relu_0_split_1
I0726 14:13:32.196795 31263 net.cpp:408] conv7_2_mbox_loc -> conv7_2_mbox_loc
I0726 14:13:32.197850 31263 net.cpp:150] Setting up conv7_2_mbox_loc
I0726 14:13:32.197862 31263 net.cpp:157] Top shape: 8 24 5 5 (4800)
I0726 14:13:32.197868 31263 net.cpp:165] Memory required for data: 2028832032
I0726 14:13:32.197882 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_perm
I0726 14:13:32.197892 31263 net.cpp:100] Creating Layer conv7_2_mbox_loc_perm
I0726 14:13:32.197901 31263 net.cpp:434] conv7_2_mbox_loc_perm <- conv7_2_mbox_loc
I0726 14:13:32.197909 31263 net.cpp:408] conv7_2_mbox_loc_perm -> conv7_2_mbox_loc_perm
I0726 14:13:32.198065 31263 net.cpp:150] Setting up conv7_2_mbox_loc_perm
I0726 14:13:32.198076 31263 net.cpp:157] Top shape: 8 5 5 24 (4800)
I0726 14:13:32.198082 31263 net.cpp:165] Memory required for data: 2028851232
I0726 14:13:32.198089 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_loc_flat
I0726 14:13:32.198153 31263 net.cpp:100] Creating Layer conv7_2_mbox_loc_flat
I0726 14:13:32.198164 31263 net.cpp:434] conv7_2_mbox_loc_flat <- conv7_2_mbox_loc_perm
I0726 14:13:32.198176 31263 net.cpp:408] conv7_2_mbox_loc_flat -> conv7_2_mbox_loc_flat
I0726 14:13:32.198216 31263 net.cpp:150] Setting up conv7_2_mbox_loc_flat
I0726 14:13:32.198228 31263 net.cpp:157] Top shape: 8 600 (4800)
I0726 14:13:32.198235 31263 net.cpp:165] Memory required for data: 2028870432
I0726 14:13:32.198241 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf
I0726 14:13:32.198256 31263 net.cpp:100] Creating Layer conv7_2_mbox_conf
I0726 14:13:32.198266 31263 net.cpp:434] conv7_2_mbox_conf <- conv7_2_conv7_2_relu_0_split_2
I0726 14:13:32.198282 31263 net.cpp:408] conv7_2_mbox_conf -> conv7_2_mbox_conf
I0726 14:13:32.238338 31263 net.cpp:150] Setting up conv7_2_mbox_conf
I0726 14:13:32.238415 31263 net.cpp:157] Top shape: 8 354 5 5 (70800)
I0726 14:13:32.238451 31263 net.cpp:165] Memory required for data: 2029153632
I0726 14:13:32.238477 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_perm
I0726 14:13:32.238500 31263 net.cpp:100] Creating Layer conv7_2_mbox_conf_perm
I0726 14:13:32.238520 31263 net.cpp:434] conv7_2_mbox_conf_perm <- conv7_2_mbox_conf
I0726 14:13:32.238545 31263 net.cpp:408] conv7_2_mbox_conf_perm -> conv7_2_mbox_conf_perm
I0726 14:13:32.238737 31263 net.cpp:150] Setting up conv7_2_mbox_conf_perm
I0726 14:13:32.238759 31263 net.cpp:157] Top shape: 8 5 5 354 (70800)
I0726 14:13:32.238773 31263 net.cpp:165] Memory required for data: 2029436832
I0726 14:13:32.238788 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_conf_flat
I0726 14:13:32.238806 31263 net.cpp:100] Creating Layer conv7_2_mbox_conf_flat
I0726 14:13:32.238821 31263 net.cpp:434] conv7_2_mbox_conf_flat <- conv7_2_mbox_conf_perm
I0726 14:13:32.238842 31263 net.cpp:408] conv7_2_mbox_conf_flat -> conv7_2_mbox_conf_flat
I0726 14:13:32.238890 31263 net.cpp:150] Setting up conv7_2_mbox_conf_flat
I0726 14:13:32.238910 31263 net.cpp:157] Top shape: 8 8850 (70800)
I0726 14:13:32.238922 31263 net.cpp:165] Memory required for data: 2029720032
I0726 14:13:32.238937 31263 layer_factory.hpp:77] Creating layer conv7_2_mbox_priorbox
I0726 14:13:32.238955 31263 net.cpp:100] Creating Layer conv7_2_mbox_priorbox
I0726 14:13:32.238970 31263 net.cpp:434] conv7_2_mbox_priorbox <- conv7_2_conv7_2_relu_0_split_3
I0726 14:13:32.238986 31263 net.cpp:434] conv7_2_mbox_priorbox <- data_data_0_split_4
I0726 14:13:32.239004 31263 net.cpp:408] conv7_2_mbox_priorbox -> conv7_2_mbox_priorbox
I0726 14:13:32.239053 31263 net.cpp:150] Setting up conv7_2_mbox_priorbox
I0726 14:13:32.239069 31263 net.cpp:157] Top shape: 1 2 600 (1200)
I0726 14:13:32.239082 31263 net.cpp:165] Memory required for data: 2029724832
I0726 14:13:32.239094 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc
I0726 14:13:32.239115 31263 net.cpp:100] Creating Layer conv8_2_mbox_loc
I0726 14:13:32.239130 31263 net.cpp:434] conv8_2_mbox_loc <- conv8_2_conv8_2_relu_0_split_1
I0726 14:13:32.239151 31263 net.cpp:408] conv8_2_mbox_loc -> conv8_2_mbox_loc
I0726 14:13:32.239902 31263 net.cpp:150] Setting up conv8_2_mbox_loc
I0726 14:13:32.239924 31263 net.cpp:157] Top shape: 8 16 3 3 (1152)
I0726 14:13:32.239938 31263 net.cpp:165] Memory required for data: 2029729440
I0726 14:13:32.239969 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_perm
I0726 14:13:32.239985 31263 net.cpp:100] Creating Layer conv8_2_mbox_loc_perm
I0726 14:13:32.240000 31263 net.cpp:434] conv8_2_mbox_loc_perm <- conv8_2_mbox_loc
I0726 14:13:32.240017 31263 net.cpp:408] conv8_2_mbox_loc_perm -> conv8_2_mbox_loc_perm
I0726 14:13:32.240159 31263 net.cpp:150] Setting up conv8_2_mbox_loc_perm
I0726 14:13:32.240178 31263 net.cpp:157] Top shape: 8 3 3 16 (1152)
I0726 14:13:32.240192 31263 net.cpp:165] Memory required for data: 2029734048
I0726 14:13:32.240206 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_loc_flat
I0726 14:13:32.240232 31263 net.cpp:100] Creating Layer conv8_2_mbox_loc_flat
I0726 14:13:32.240290 31263 net.cpp:434] conv8_2_mbox_loc_flat <- conv8_2_mbox_loc_perm
I0726 14:13:32.240314 31263 net.cpp:408] conv8_2_mbox_loc_flat -> conv8_2_mbox_loc_flat
I0726 14:13:32.240375 31263 net.cpp:150] Setting up conv8_2_mbox_loc_flat
I0726 14:13:32.240398 31263 net.cpp:157] Top shape: 8 144 (1152)
I0726 14:13:32.240416 31263 net.cpp:165] Memory required for data: 2029738656
I0726 14:13:32.240432 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf
I0726 14:13:32.240456 31263 net.cpp:100] Creating Layer conv8_2_mbox_conf
I0726 14:13:32.240474 31263 net.cpp:434] conv8_2_mbox_conf <- conv8_2_conv8_2_relu_0_split_2
I0726 14:13:32.240500 31263 net.cpp:408] conv8_2_mbox_conf -> conv8_2_mbox_conf
I0726 14:13:32.305408 31263 net.cpp:150] Setting up conv8_2_mbox_conf
I0726 14:13:32.305447 31263 net.cpp:157] Top shape: 8 236 3 3 (16992)
I0726 14:13:32.305454 31263 net.cpp:165] Memory required for data: 2029806624
I0726 14:13:32.305485 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_perm
I0726 14:13:32.305503 31263 net.cpp:100] Creating Layer conv8_2_mbox_conf_perm
I0726 14:13:32.305589 31263 net.cpp:434] conv8_2_mbox_conf_perm <- conv8_2_mbox_conf
I0726 14:13:32.305608 31263 net.cpp:408] conv8_2_mbox_conf_perm -> conv8_2_mbox_conf_perm
I0726 14:13:32.305723 31263 net.cpp:150] Setting up conv8_2_mbox_conf_perm
I0726 14:13:32.305734 31263 net.cpp:157] Top shape: 8 3 3 236 (16992)
I0726 14:13:32.305738 31263 net.cpp:165] Memory required for data: 2029874592
I0726 14:13:32.305748 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_conf_flat
I0726 14:13:32.305758 31263 net.cpp:100] Creating Layer conv8_2_mbox_conf_flat
I0726 14:13:32.305764 31263 net.cpp:434] conv8_2_mbox_conf_flat <- conv8_2_mbox_conf_perm
I0726 14:13:32.305780 31263 net.cpp:408] conv8_2_mbox_conf_flat -> conv8_2_mbox_conf_flat
I0726 14:13:32.305810 31263 net.cpp:150] Setting up conv8_2_mbox_conf_flat
I0726 14:13:32.305824 31263 net.cpp:157] Top shape: 8 2124 (16992)
I0726 14:13:32.305831 31263 net.cpp:165] Memory required for data: 2029942560
I0726 14:13:32.305845 31263 layer_factory.hpp:77] Creating layer conv8_2_mbox_priorbox
I0726 14:13:32.305856 31263 net.cpp:100] Creating Layer conv8_2_mbox_priorbox
I0726 14:13:32.305867 31263 net.cpp:434] conv8_2_mbox_priorbox <- conv8_2_conv8_2_relu_0_split_3
I0726 14:13:32.305881 31263 net.cpp:434] conv8_2_mbox_priorbox <- data_data_0_split_5
I0726 14:13:32.305889 31263 net.cpp:408] conv8_2_mbox_priorbox -> conv8_2_mbox_priorbox
I0726 14:13:32.305936 31263 net.cpp:150] Setting up conv8_2_mbox_priorbox
I0726 14:13:32.305946 31263 net.cpp:157] Top shape: 1 2 144 (288)
I0726 14:13:32.305953 31263 net.cpp:165] Memory required for data: 2029943712
I0726 14:13:32.305965 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc
I0726 14:13:32.305977 31263 net.cpp:100] Creating Layer conv9_2_mbox_loc
I0726 14:13:32.305990 31263 net.cpp:434] conv9_2_mbox_loc <- conv9_2_conv9_2_relu_0_split_0
I0726 14:13:32.306006 31263 net.cpp:408] conv9_2_mbox_loc -> conv9_2_mbox_loc
I0726 14:13:32.306610 31263 net.cpp:150] Setting up conv9_2_mbox_loc
I0726 14:13:32.306627 31263 net.cpp:157] Top shape: 8 16 1 1 (128)
I0726 14:13:32.306639 31263 net.cpp:165] Memory required for data: 2029944224
I0726 14:13:32.306654 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_perm
I0726 14:13:32.306668 31263 net.cpp:100] Creating Layer conv9_2_mbox_loc_perm
I0726 14:13:32.306674 31263 net.cpp:434] conv9_2_mbox_loc_perm <- conv9_2_mbox_loc
I0726 14:13:32.306690 31263 net.cpp:408] conv9_2_mbox_loc_perm -> conv9_2_mbox_loc_perm
I0726 14:13:32.306810 31263 net.cpp:150] Setting up conv9_2_mbox_loc_perm
I0726 14:13:32.306823 31263 net.cpp:157] Top shape: 8 1 1 16 (128)
I0726 14:13:32.306826 31263 net.cpp:165] Memory required for data: 2029944736
I0726 14:13:32.306839 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_loc_flat
I0726 14:13:32.306850 31263 net.cpp:100] Creating Layer conv9_2_mbox_loc_flat
I0726 14:13:32.306854 31263 net.cpp:434] conv9_2_mbox_loc_flat <- conv9_2_mbox_loc_perm
I0726 14:13:32.306912 31263 net.cpp:408] conv9_2_mbox_loc_flat -> conv9_2_mbox_loc_flat
I0726 14:13:32.306944 31263 net.cpp:150] Setting up conv9_2_mbox_loc_flat
I0726 14:13:32.306957 31263 net.cpp:157] Top shape: 8 16 (128)
I0726 14:13:32.306962 31263 net.cpp:165] Memory required for data: 2029945248
I0726 14:13:32.306968 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf
I0726 14:13:32.306977 31263 net.cpp:100] Creating Layer conv9_2_mbox_conf
I0726 14:13:32.306983 31263 net.cpp:434] conv9_2_mbox_conf <- conv9_2_conv9_2_relu_0_split_1
I0726 14:13:32.306989 31263 net.cpp:408] conv9_2_mbox_conf -> conv9_2_mbox_conf
I0726 14:13:32.346290 31263 net.cpp:150] Setting up conv9_2_mbox_conf
I0726 14:13:32.346326 31263 net.cpp:157] Top shape: 8 236 1 1 (1888)
I0726 14:13:32.346331 31263 net.cpp:165] Memory required for data: 2029952800
I0726 14:13:32.346351 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_perm
I0726 14:13:32.346386 31263 net.cpp:100] Creating Layer conv9_2_mbox_conf_perm
I0726 14:13:32.346400 31263 net.cpp:434] conv9_2_mbox_conf_perm <- conv9_2_mbox_conf
I0726 14:13:32.346415 31263 net.cpp:408] conv9_2_mbox_conf_perm -> conv9_2_mbox_conf_perm
I0726 14:13:32.346539 31263 net.cpp:150] Setting up conv9_2_mbox_conf_perm
I0726 14:13:32.346545 31263 net.cpp:157] Top shape: 8 1 1 236 (1888)
I0726 14:13:32.346549 31263 net.cpp:165] Memory required for data: 2029960352
I0726 14:13:32.346554 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_conf_flat
I0726 14:13:32.346580 31263 net.cpp:100] Creating Layer conv9_2_mbox_conf_flat
I0726 14:13:32.346585 31263 net.cpp:434] conv9_2_mbox_conf_flat <- conv9_2_mbox_conf_perm
I0726 14:13:32.346590 31263 net.cpp:408] conv9_2_mbox_conf_flat -> conv9_2_mbox_conf_flat
I0726 14:13:32.346617 31263 net.cpp:150] Setting up conv9_2_mbox_conf_flat
I0726 14:13:32.346624 31263 net.cpp:157] Top shape: 8 236 (1888)
I0726 14:13:32.346631 31263 net.cpp:165] Memory required for data: 2029967904
I0726 14:13:32.346637 31263 layer_factory.hpp:77] Creating layer conv9_2_mbox_priorbox
I0726 14:13:32.346645 31263 net.cpp:100] Creating Layer conv9_2_mbox_priorbox
I0726 14:13:32.346650 31263 net.cpp:434] conv9_2_mbox_priorbox <- conv9_2_conv9_2_relu_0_split_2
I0726 14:13:32.346657 31263 net.cpp:434] conv9_2_mbox_priorbox <- data_data_0_split_6
I0726 14:13:32.346668 31263 net.cpp:408] conv9_2_mbox_priorbox -> conv9_2_mbox_priorbox
I0726 14:13:32.346702 31263 net.cpp:150] Setting up conv9_2_mbox_priorbox
I0726 14:13:32.346707 31263 net.cpp:157] Top shape: 1 2 16 (32)
I0726 14:13:32.346710 31263 net.cpp:165] Memory required for data: 2029968032
I0726 14:13:32.346714 31263 layer_factory.hpp:77] Creating layer mbox_loc
I0726 14:13:32.346722 31263 net.cpp:100] Creating Layer mbox_loc
I0726 14:13:32.346729 31263 net.cpp:434] mbox_loc <- conv4_3_norm_mbox_loc_flat
I0726 14:13:32.346735 31263 net.cpp:434] mbox_loc <- fc7_mbox_loc_flat
I0726 14:13:32.346741 31263 net.cpp:434] mbox_loc <- conv6_2_mbox_loc_flat
I0726 14:13:32.346747 31263 net.cpp:434] mbox_loc <- conv7_2_mbox_loc_flat
I0726 14:13:32.346756 31263 net.cpp:434] mbox_loc <- conv8_2_mbox_loc_flat
I0726 14:13:32.346760 31263 net.cpp:434] mbox_loc <- conv9_2_mbox_loc_flat
I0726 14:13:32.346766 31263 net.cpp:408] mbox_loc -> mbox_loc
I0726 14:13:32.346793 31263 net.cpp:150] Setting up mbox_loc
I0726 14:13:32.346801 31263 net.cpp:157] Top shape: 8 34928 (279424)
I0726 14:13:32.346803 31263 net.cpp:165] Memory required for data: 2031085728
I0726 14:13:32.346807 31263 layer_factory.hpp:77] Creating layer mbox_conf
I0726 14:13:32.346820 31263 net.cpp:100] Creating Layer mbox_conf
I0726 14:13:32.346824 31263 net.cpp:434] mbox_conf <- conv4_3_norm_mbox_conf_flat
I0726 14:13:32.346830 31263 net.cpp:434] mbox_conf <- fc7_mbox_conf_flat
I0726 14:13:32.346837 31263 net.cpp:434] mbox_conf <- conv6_2_mbox_conf_flat
I0726 14:13:32.346843 31263 net.cpp:434] mbox_conf <- conv7_2_mbox_conf_flat
I0726 14:13:32.346850 31263 net.cpp:434] mbox_conf <- conv8_2_mbox_conf_flat
I0726 14:13:32.346855 31263 net.cpp:434] mbox_conf <- conv9_2_mbox_conf_flat
I0726 14:13:32.346875 31263 net.cpp:408] mbox_conf -> mbox_conf
I0726 14:13:32.346904 31263 net.cpp:150] Setting up mbox_conf
I0726 14:13:32.346910 31263 net.cpp:157] Top shape: 8 515188 (4121504)
I0726 14:13:32.346915 31263 net.cpp:165] Memory required for data: 2047571744
I0726 14:13:32.346917 31263 layer_factory.hpp:77] Creating layer mbox_priorbox
I0726 14:13:32.346923 31263 net.cpp:100] Creating Layer mbox_priorbox
I0726 14:13:32.346926 31263 net.cpp:434] mbox_priorbox <- conv4_3_norm_mbox_priorbox
I0726 14:13:32.346930 31263 net.cpp:434] mbox_priorbox <- fc7_mbox_priorbox
I0726 14:13:32.346936 31263 net.cpp:434] mbox_priorbox <- conv6_2_mbox_priorbox
I0726 14:13:32.346943 31263 net.cpp:434] mbox_priorbox <- conv7_2_mbox_priorbox
I0726 14:13:32.346946 31263 net.cpp:434] mbox_priorbox <- conv8_2_mbox_priorbox
I0726 14:13:32.346952 31263 net.cpp:434] mbox_priorbox <- conv9_2_mbox_priorbox
I0726 14:13:32.346957 31263 net.cpp:408] mbox_priorbox -> mbox_priorbox
I0726 14:13:32.346982 31263 net.cpp:150] Setting up mbox_priorbox
I0726 14:13:32.346988 31263 net.cpp:157] Top shape: 1 2 34928 (69856)
I0726 14:13:32.346992 31263 net.cpp:165] Memory required for data: 2047851168
I0726 14:13:32.346995 31263 layer_factory.hpp:77] Creating layer mbox_conf_reshape
I0726 14:13:32.347007 31263 net.cpp:100] Creating Layer mbox_conf_reshape
I0726 14:13:32.347012 31263 net.cpp:434] mbox_conf_reshape <- mbox_conf
I0726 14:13:32.347018 31263 net.cpp:408] mbox_conf_reshape -> mbox_conf_reshape
I0726 14:13:32.347064 31263 net.cpp:150] Setting up mbox_conf_reshape
I0726 14:13:32.347075 31263 net.cpp:157] Top shape: 8 8732 59 (4121504)
I0726 14:13:32.347081 31263 net.cpp:165] Memory required for data: 2064337184
I0726 14:13:32.347087 31263 layer_factory.hpp:77] Creating layer mbox_conf_softmax
I0726 14:13:32.347098 31263 net.cpp:100] Creating Layer mbox_conf_softmax
I0726 14:13:32.347105 31263 net.cpp:434] mbox_conf_softmax <- mbox_conf_reshape
I0726 14:13:32.347115 31263 net.cpp:408] mbox_conf_softmax -> mbox_conf_softmax
I0726 14:13:32.347229 31263 net.cpp:150] Setting up mbox_conf_softmax
I0726 14:13:32.347239 31263 net.cpp:157] Top shape: 8 8732 59 (4121504)
I0726 14:13:32.347245 31263 net.cpp:165] Memory required for data: 2080823200
I0726 14:13:32.347252 31263 layer_factory.hpp:77] Creating layer mbox_conf_flatten
I0726 14:13:32.347268 31263 net.cpp:100] Creating Layer mbox_conf_flatten
I0726 14:13:32.347273 31263 net.cpp:434] mbox_conf_flatten <- mbox_conf_softmax
I0726 14:13:32.347283 31263 net.cpp:408] mbox_conf_flatten -> mbox_conf_flatten
I0726 14:13:32.347318 31263 net.cpp:150] Setting up mbox_conf_flatten
I0726 14:13:32.347328 31263 net.cpp:157] Top shape: 8 515188 (4121504)
I0726 14:13:32.347333 31263 net.cpp:165] Memory required for data: 2097309216
I0726 14:13:32.347340 31263 layer_factory.hpp:77] Creating layer detection_out
I0726 14:13:32.347365 31263 net.cpp:100] Creating Layer detection_out
I0726 14:13:32.347373 31263 net.cpp:434] detection_out <- mbox_loc
I0726 14:13:32.347383 31263 net.cpp:434] detection_out <- mbox_conf_flatten
I0726 14:13:32.347391 31263 net.cpp:434] detection_out <- mbox_priorbox
I0726 14:13:32.347398 31263 net.cpp:408] detection_out -> detection_out
I0726 14:13:32.349735 31263 net.cpp:150] Setting up detection_out
I0726 14:13:32.349746 31263 net.cpp:157] Top shape: 1 1 1 7 (7)
I0726 14:13:32.349752 31263 net.cpp:165] Memory required for data: 2097309244
I0726 14:13:32.349756 31263 layer_factory.hpp:77] Creating layer detection_eval
I0726 14:13:32.349766 31263 net.cpp:100] Creating Layer detection_eval
I0726 14:13:32.349771 31263 net.cpp:434] detection_eval <- detection_out
I0726 14:13:32.349779 31263 net.cpp:434] detection_eval <- label
I0726 14:13:32.349786 31263 net.cpp:408] detection_eval -> detection_eval
I0726 14:13:32.350378 31263 net.cpp:150] Setting up detection_eval
I0726 14:13:32.350389 31263 net.cpp:157] Top shape: 1 1 59 5 (295)
I0726 14:13:32.350397 31263 net.cpp:165] Memory required for data: 2097310424
I0726 14:13:32.350409 31263 net.cpp:228] detection_eval does not need backward computation.
I0726 14:13:32.350432 31263 net.cpp:228] detection_out does not need backward computation.
I0726 14:13:32.350442 31263 net.cpp:228] mbox_conf_flatten does not need backward computation.
I0726 14:13:32.350450 31263 net.cpp:228] mbox_conf_softmax does not need backward computation.
I0726 14:13:32.350457 31263 net.cpp:228] mbox_conf_reshape does not need backward computation.
I0726 14:13:32.350461 31263 net.cpp:228] mbox_priorbox does not need backward computation.
I0726 14:13:32.350466 31263 net.cpp:228] mbox_conf does not need backward computation.
I0726 14:13:32.350472 31263 net.cpp:228] mbox_loc does not need backward computation.
I0726 14:13:32.350479 31263 net.cpp:228] conv9_2_mbox_priorbox does not need backward computation.
I0726 14:13:32.350483 31263 net.cpp:228] conv9_2_mbox_conf_flat does not need backward computation.
I0726 14:13:32.350487 31263 net.cpp:228] conv9_2_mbox_conf_perm does not need backward computation.
I0726 14:13:32.350493 31263 net.cpp:228] conv9_2_mbox_conf does not need backward computation.
I0726 14:13:32.350497 31263 net.cpp:228] conv9_2_mbox_loc_flat does not need backward computation.
I0726 14:13:32.350502 31263 net.cpp:228] conv9_2_mbox_loc_perm does not need backward computation.
I0726 14:13:32.350504 31263 net.cpp:228] conv9_2_mbox_loc does not need backward computation.
I0726 14:13:32.350512 31263 net.cpp:228] conv8_2_mbox_priorbox does not need backward computation.
I0726 14:13:32.350517 31263 net.cpp:228] conv8_2_mbox_conf_flat does not need backward computation.
I0726 14:13:32.350522 31263 net.cpp:228] conv8_2_mbox_conf_perm does not need backward computation.
I0726 14:13:32.350528 31263 net.cpp:228] conv8_2_mbox_conf does not need backward computation.
I0726 14:13:32.350533 31263 net.cpp:228] conv8_2_mbox_loc_flat does not need backward computation.
I0726 14:13:32.350535 31263 net.cpp:228] conv8_2_mbox_loc_perm does not need backward computation.
I0726 14:13:32.350543 31263 net.cpp:228] conv8_2_mbox_loc does not need backward computation.
I0726 14:13:32.350546 31263 net.cpp:228] conv7_2_mbox_priorbox does not need backward computation.
I0726 14:13:32.350553 31263 net.cpp:228] conv7_2_mbox_conf_flat does not need backward computation.
I0726 14:13:32.350558 31263 net.cpp:228] conv7_2_mbox_conf_perm does not need backward computation.
I0726 14:13:32.350561 31263 net.cpp:228] conv7_2_mbox_conf does not need backward computation.
I0726 14:13:32.350564 31263 net.cpp:228] conv7_2_mbox_loc_flat does not need backward computation.
I0726 14:13:32.350571 31263 net.cpp:228] conv7_2_mbox_loc_perm does not need backward computation.
I0726 14:13:32.350575 31263 net.cpp:228] conv7_2_mbox_loc does not need backward computation.
I0726 14:13:32.350579 31263 net.cpp:228] conv6_2_mbox_priorbox does not need backward computation.
I0726 14:13:32.350586 31263 net.cpp:228] conv6_2_mbox_conf_flat does not need backward computation.
I0726 14:13:32.350590 31263 net.cpp:228] conv6_2_mbox_conf_perm does not need backward computation.
I0726 14:13:32.350594 31263 net.cpp:228] conv6_2_mbox_conf does not need backward computation.
I0726 14:13:32.350602 31263 net.cpp:228] conv6_2_mbox_loc_flat does not need backward computation.
I0726 14:13:32.350608 31263 net.cpp:228] conv6_2_mbox_loc_perm does not need backward computation.
I0726 14:13:32.350615 31263 net.cpp:228] conv6_2_mbox_loc does not need backward computation.
I0726 14:13:32.350620 31263 net.cpp:228] fc7_mbox_priorbox does not need backward computation.
I0726 14:13:32.350625 31263 net.cpp:228] fc7_mbox_conf_flat does not need backward computation.
I0726 14:13:32.350628 31263 net.cpp:228] fc7_mbox_conf_perm does not need backward computation.
I0726 14:13:32.350634 31263 net.cpp:228] fc7_mbox_conf does not need backward computation.
I0726 14:13:32.350639 31263 net.cpp:228] fc7_mbox_loc_flat does not need backward computation.
I0726 14:13:32.350642 31263 net.cpp:228] fc7_mbox_loc_perm does not need backward computation.
I0726 14:13:32.350648 31263 net.cpp:228] fc7_mbox_loc does not need backward computation.
I0726 14:13:32.350653 31263 net.cpp:228] conv4_3_norm_mbox_priorbox does not need backward computation.
I0726 14:13:32.350666 31263 net.cpp:228] conv4_3_norm_mbox_conf_flat does not need backward computation.
I0726 14:13:32.350669 31263 net.cpp:228] conv4_3_norm_mbox_conf_perm does not need backward computation.
I0726 14:13:32.350673 31263 net.cpp:228] conv4_3_norm_mbox_conf does not need backward computation.
I0726 14:13:32.350680 31263 net.cpp:228] conv4_3_norm_mbox_loc_flat does not need backward computation.
I0726 14:13:32.350683 31263 net.cpp:228] conv4_3_norm_mbox_loc_perm does not need backward computation.
I0726 14:13:32.350688 31263 net.cpp:228] conv4_3_norm_mbox_loc does not need backward computation.
I0726 14:13:32.350692 31263 net.cpp:228] conv4_3_norm_conv4_3_norm_0_split does not need backward computation.
I0726 14:13:32.350699 31263 net.cpp:228] conv4_3_norm does not need backward computation.
I0726 14:13:32.350703 31263 net.cpp:228] conv9_2_conv9_2_relu_0_split does not need backward computation.
I0726 14:13:32.350709 31263 net.cpp:228] conv9_2_relu does not need backward computation.
I0726 14:13:32.350714 31263 net.cpp:228] conv9_2 does not need backward computation.
I0726 14:13:32.350719 31263 net.cpp:228] conv9_1_relu does not need backward computation.
I0726 14:13:32.350723 31263 net.cpp:228] conv9_1 does not need backward computation.
I0726 14:13:32.350730 31263 net.cpp:228] conv8_2_conv8_2_relu_0_split does not need backward computation.
I0726 14:13:32.350734 31263 net.cpp:228] conv8_2_relu does not need backward computation.
I0726 14:13:32.350740 31263 net.cpp:228] conv8_2 does not need backward computation.
I0726 14:13:32.350745 31263 net.cpp:228] conv8_1_relu does not need backward computation.
I0726 14:13:32.350749 31263 net.cpp:228] conv8_1 does not need backward computation.
I0726 14:13:32.350752 31263 net.cpp:228] conv7_2_conv7_2_relu_0_split does not need backward computation.
I0726 14:13:32.350759 31263 net.cpp:228] conv7_2_relu does not need backward computation.
I0726 14:13:32.350764 31263 net.cpp:228] conv7_2 does not need backward computation.
I0726 14:13:32.350766 31263 net.cpp:228] conv7_1_relu does not need backward computation.
I0726 14:13:32.350772 31263 net.cpp:228] conv7_1 does not need backward computation.
I0726 14:13:32.350776 31263 net.cpp:228] conv6_2_conv6_2_relu_0_split does not need backward computation.
I0726 14:13:32.350785 31263 net.cpp:228] conv6_2_relu does not need backward computation.
I0726 14:13:32.350790 31263 net.cpp:228] conv6_2 does not need backward computation.
I0726 14:13:32.350797 31263 net.cpp:228] conv6_1_relu does not need backward computation.
I0726 14:13:32.350803 31263 net.cpp:228] conv6_1 does not need backward computation.
I0726 14:13:32.350813 31263 net.cpp:228] fc7_relu7_0_split does not need backward computation.
I0726 14:13:32.350821 31263 net.cpp:228] relu7 does not need backward computation.
I0726 14:13:32.350826 31263 net.cpp:228] fc7 does not need backward computation.
I0726 14:13:32.350834 31263 net.cpp:228] relu6 does not need backward computation.
I0726 14:13:32.350844 31263 net.cpp:228] fc6 does not need backward computation.
I0726 14:13:32.350852 31263 net.cpp:228] pool5 does not need backward computation.
I0726 14:13:32.350860 31263 net.cpp:228] relu5_3 does not need backward computation.
I0726 14:13:32.350867 31263 net.cpp:228] conv5_3 does not need backward computation.
I0726 14:13:32.350875 31263 net.cpp:228] relu5_2 does not need backward computation.
I0726 14:13:32.350883 31263 net.cpp:228] conv5_2 does not need backward computation.
I0726 14:13:32.350889 31263 net.cpp:228] relu5_1 does not need backward computation.
I0726 14:13:32.350896 31263 net.cpp:228] conv5_1 does not need backward computation.
I0726 14:13:32.350903 31263 net.cpp:228] pool4 does not need backward computation.
I0726 14:13:32.350913 31263 net.cpp:228] conv4_3_relu4_3_0_split does not need backward computation.
I0726 14:13:32.350919 31263 net.cpp:228] relu4_3 does not need backward computation.
I0726 14:13:32.350925 31263 net.cpp:228] conv4_3 does not need backward computation.
I0726 14:13:32.350934 31263 net.cpp:228] relu4_2 does not need backward computation.
I0726 14:13:32.350950 31263 net.cpp:228] conv4_2 does not need backward computation.
I0726 14:13:32.350957 31263 net.cpp:228] relu4_1 does not need backward computation.
I0726 14:13:32.350963 31263 net.cpp:228] conv4_1 does not need backward computation.
I0726 14:13:32.350972 31263 net.cpp:228] pool3 does not need backward computation.
I0726 14:13:32.350978 31263 net.cpp:228] relu3_3 does not need backward computation.
I0726 14:13:32.350986 31263 net.cpp:228] conv3_3 does not need backward computation.
I0726 14:13:32.350993 31263 net.cpp:228] relu3_2 does not need backward computation.
I0726 14:13:32.350999 31263 net.cpp:228] conv3_2 does not need backward computation.
I0726 14:13:32.351007 31263 net.cpp:228] relu3_1 does not need backward computation.
I0726 14:13:32.351014 31263 net.cpp:228] conv3_1 does not need backward computation.
I0726 14:13:32.351022 31263 net.cpp:228] pool2 does not need backward computation.
I0726 14:13:32.351029 31263 net.cpp:228] relu2_2 does not need backward computation.
I0726 14:13:32.351037 31263 net.cpp:228] conv2_2 does not need backward computation.
I0726 14:13:32.351043 31263 net.cpp:228] relu2_1 does not need backward computation.
I0726 14:13:32.351054 31263 net.cpp:228] conv2_1 does not need backward computation.
I0726 14:13:32.351061 31263 net.cpp:228] pool1 does not need backward computation.
I0726 14:13:32.351068 31263 net.cpp:228] relu1_2 does not need backward computation.
I0726 14:13:32.351074 31263 net.cpp:228] conv1_2 does not need backward computation.
I0726 14:13:32.351083 31263 net.cpp:228] relu1_1 does not need backward computation.
I0726 14:13:32.351089 31263 net.cpp:228] conv1_1 does not need backward computation.
I0726 14:13:32.351099 31263 net.cpp:228] data_data_0_split does not need backward computation.
I0726 14:13:32.351106 31263 net.cpp:228] data does not need backward computation.
I0726 14:13:32.351111 31263 net.cpp:270] This network produces output detection_eval
I0726 14:13:32.351222 31263 net.cpp:283] Network initialization done.
I0726 14:13:32.351686 31263 solver.cpp:75] Solver scaffolding done.
I0726 14:13:32.354490 31263 caffe.cpp:155] Finetuning from models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0726 14:13:32.717901 31263 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0726 14:13:32.717929 31263 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0726 14:13:32.717932 31263 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0726 14:13:32.749440 31263 net.cpp:761] Ignoring source layer drop6
I0726 14:13:32.752290 31263 net.cpp:761] Ignoring source layer drop7
I0726 14:13:32.752328 31263 net.cpp:761] Ignoring source layer fc8
I0726 14:13:32.752331 31263 net.cpp:761] Ignoring source layer prob
I0726 14:13:32.827067 31263 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: models/VGGNet/VGG_ILSVRC_16_layers_fc_reduced.caffemodel
I0726 14:13:32.827092 31263 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W0726 14:13:32.827098 31263 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
I0726 14:13:32.873749 31263 net.cpp:761] Ignoring source layer drop6
I0726 14:13:32.875298 31263 net.cpp:761] Ignoring source layer drop7
I0726 14:13:32.875311 31263 net.cpp:761] Ignoring source layer fc8
I0726 14:13:32.875316 31263 net.cpp:761] Ignoring source layer prob
I0726 14:13:32.877246 31263 caffe.cpp:251] Starting Optimization
I0726 14:13:32.877269 31263 solver.cpp:294] Solving VGG_SHOPPE_2017_SSD_300x300_train
I0726 14:13:32.877274 31263 solver.cpp:295] Learning Rate Policy: multistep
I0726 14:13:32.887168 31263 blocking_queue.cpp:50] Data layer prefetch queue empty
I0726 14:13:35.654819 31263 solver.cpp:243] Iteration 0, loss = 27.8868
I0726 14:13:35.655050 31263 solver.cpp:259]     Train net output #0: mbox_loss = 27.3598 (* 1 = 27.3598 loss)
I0726 14:13:35.655333 31263 sgd_solver.cpp:138] Iteration 0, lr = 0.001
I0726 14:14:04.938843 31263 solver.cpp:243] Iteration 10, loss = 21.6517
I0726 14:14:04.938966 31263 solver.cpp:259]     Train net output #0: mbox_loss = 19.7323 (* 1 = 19.7323 loss)
I0726 14:14:04.938973 31263 sgd_solver.cpp:138] Iteration 10, lr = 0.001
I0726 14:14:34.168840 31263 solver.cpp:243] Iteration 20, loss = 18.3021
I0726 14:14:34.168875 31263 solver.cpp:259]     Train net output #0: mbox_loss = 16.0606 (* 1 = 16.0606 loss)
I0726 14:14:34.168882 31263 sgd_solver.cpp:138] Iteration 20, lr = 0.001
I0726 14:15:03.488682 31263 solver.cpp:243] Iteration 30, loss = 13.5187
I0726 14:15:03.488837 31263 solver.cpp:259]     Train net output #0: mbox_loss = 11.2562 (* 1 = 11.2562 loss)
I0726 14:15:03.488847 31263 sgd_solver.cpp:138] Iteration 30, lr = 0.001
I0726 14:15:32.801337 31263 solver.cpp:243] Iteration 40, loss = 10.8994
I0726 14:15:32.801431 31263 solver.cpp:259]     Train net output #0: mbox_loss = 9.46112 (* 1 = 9.46112 loss)
I0726 14:15:32.801446 31263 sgd_solver.cpp:138] Iteration 40, lr = 0.001
I0726 14:16:02.423795 31263 solver.cpp:243] Iteration 50, loss = 9.84407
I0726 14:16:02.423905 31263 solver.cpp:259]     Train net output #0: mbox_loss = 9.71431 (* 1 = 9.71431 loss)
I0726 14:16:02.423914 31263 sgd_solver.cpp:138] Iteration 50, lr = 0.001
I0726 14:16:31.985582 31263 solver.cpp:243] Iteration 60, loss = 9.34653
I0726 14:16:31.985621 31263 solver.cpp:259]     Train net output #0: mbox_loss = 9.14587 (* 1 = 9.14587 loss)
I0726 14:16:31.985633 31263 sgd_solver.cpp:138] Iteration 60, lr = 0.001
I0726 14:17:01.702193 31263 solver.cpp:243] Iteration 70, loss = 8.76738
I0726 14:17:01.702353 31263 solver.cpp:259]     Train net output #0: mbox_loss = 8.08232 (* 1 = 8.08232 loss)
I0726 14:17:01.702363 31263 sgd_solver.cpp:138] Iteration 70, lr = 0.001
I0726 14:17:31.402397 31263 solver.cpp:243] Iteration 80, loss = 8.41215
I0726 14:17:31.402431 31263 solver.cpp:259]     Train net output #0: mbox_loss = 8.43845 (* 1 = 8.43845 loss)
I0726 14:17:31.402439 31263 sgd_solver.cpp:138] Iteration 80, lr = 0.001
I0726 14:18:00.750418 31263 solver.cpp:243] Iteration 90, loss = 8.22384
I0726 14:18:00.750564 31263 solver.cpp:259]     Train net output #0: mbox_loss = 8.86851 (* 1 = 8.86851 loss)
I0726 14:18:00.750576 31263 sgd_solver.cpp:138] Iteration 90, lr = 0.001
I0726 14:18:30.161464 31263 solver.cpp:243] Iteration 100, loss = 8.11069
I0726 14:18:30.161497 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.52926 (* 1 = 7.52926 loss)
I0726 14:18:30.161504 31263 sgd_solver.cpp:138] Iteration 100, lr = 0.001
I0726 14:18:59.627702 31263 solver.cpp:243] Iteration 110, loss = 7.84923
I0726 14:18:59.627925 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.61942 (* 1 = 7.61942 loss)
I0726 14:18:59.627938 31263 sgd_solver.cpp:138] Iteration 110, lr = 0.001
I0726 14:19:29.041401 31263 solver.cpp:243] Iteration 120, loss = 7.72409
I0726 14:19:29.041431 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.69097 (* 1 = 7.69097 loss)
I0726 14:19:29.041437 31263 sgd_solver.cpp:138] Iteration 120, lr = 0.001
I0726 14:19:58.573580 31263 solver.cpp:243] Iteration 130, loss = 7.53713
I0726 14:19:58.573724 31263 solver.cpp:259]     Train net output #0: mbox_loss = 8.98273 (* 1 = 8.98273 loss)
I0726 14:19:58.573756 31263 sgd_solver.cpp:138] Iteration 130, lr = 0.001
I0726 14:20:29.223357 31263 solver.cpp:243] Iteration 140, loss = 7.60959
I0726 14:20:29.223546 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.27056 (* 1 = 7.27056 loss)
I0726 14:20:29.223556 31263 sgd_solver.cpp:138] Iteration 140, lr = 0.001
I0726 14:20:58.757644 31263 solver.cpp:243] Iteration 150, loss = 7.55703
I0726 14:20:58.757686 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.80393 (* 1 = 7.80393 loss)
I0726 14:20:58.757695 31263 sgd_solver.cpp:138] Iteration 150, lr = 0.001
I0726 14:21:28.090584 31263 solver.cpp:243] Iteration 160, loss = 7.41628
I0726 14:21:28.090804 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.6411 (* 1 = 7.6411 loss)
I0726 14:21:28.090838 31263 sgd_solver.cpp:138] Iteration 160, lr = 0.001
I0726 14:21:57.555168 31263 solver.cpp:243] Iteration 170, loss = 7.23398
I0726 14:21:57.555204 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.15606 (* 1 = 7.15606 loss)
I0726 14:21:57.555212 31263 sgd_solver.cpp:138] Iteration 170, lr = 0.001
I0726 14:22:27.019423 31263 solver.cpp:243] Iteration 180, loss = 7.37277
I0726 14:22:27.019552 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.61956 (* 1 = 7.61956 loss)
I0726 14:22:27.019560 31263 sgd_solver.cpp:138] Iteration 180, lr = 0.001
I0726 14:22:56.329674 31263 solver.cpp:243] Iteration 190, loss = 7.15414
I0726 14:22:56.329705 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.49162 (* 1 = 6.49162 loss)
I0726 14:22:56.329711 31263 sgd_solver.cpp:138] Iteration 190, lr = 0.001
I0726 14:23:26.950986 31263 solver.cpp:243] Iteration 200, loss = 7.10469
I0726 14:23:26.951140 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.93913 (* 1 = 6.93913 loss)
I0726 14:23:26.951148 31263 sgd_solver.cpp:138] Iteration 200, lr = 0.001
I0726 14:23:56.415289 31263 solver.cpp:243] Iteration 210, loss = 7.16682
I0726 14:23:56.415323 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.025 (* 1 = 7.025 loss)
I0726 14:23:56.415329 31263 sgd_solver.cpp:138] Iteration 210, lr = 0.001
I0726 14:24:25.974783 31263 solver.cpp:243] Iteration 220, loss = 7.00828
I0726 14:24:25.974930 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.28283 (* 1 = 7.28283 loss)
I0726 14:24:25.974949 31263 sgd_solver.cpp:138] Iteration 220, lr = 0.001
I0726 14:24:55.580427 31263 solver.cpp:243] Iteration 230, loss = 7.05124
I0726 14:24:55.580518 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.68023 (* 1 = 7.68023 loss)
I0726 14:24:55.580531 31263 sgd_solver.cpp:138] Iteration 230, lr = 0.001
I0726 14:25:24.977414 31263 solver.cpp:243] Iteration 240, loss = 7.0326
I0726 14:25:24.977557 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.13653 (* 1 = 7.13653 loss)
I0726 14:25:24.977568 31263 sgd_solver.cpp:138] Iteration 240, lr = 0.001
I0726 14:25:54.460978 31263 solver.cpp:243] Iteration 250, loss = 6.90023
I0726 14:25:54.461009 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.80299 (* 1 = 6.80299 loss)
I0726 14:25:54.461016 31263 sgd_solver.cpp:138] Iteration 250, lr = 0.001
I0726 14:26:23.880120 31263 solver.cpp:243] Iteration 260, loss = 7.05291
I0726 14:26:23.880220 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.56526 (* 1 = 7.56526 loss)
I0726 14:26:23.880229 31263 sgd_solver.cpp:138] Iteration 260, lr = 0.001
I0726 14:26:53.183621 31263 solver.cpp:243] Iteration 270, loss = 6.78447
I0726 14:26:53.183672 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.52532 (* 1 = 6.52532 loss)
I0726 14:26:53.183684 31263 sgd_solver.cpp:138] Iteration 270, lr = 0.001
I0726 14:27:22.766516 31263 solver.cpp:243] Iteration 280, loss = 6.76463
I0726 14:27:22.766628 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.45611 (* 1 = 7.45611 loss)
I0726 14:27:22.766636 31263 sgd_solver.cpp:138] Iteration 280, lr = 0.001
I0726 14:27:52.176303 31263 solver.cpp:243] Iteration 290, loss = 6.72815
I0726 14:27:52.176357 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.06373 (* 1 = 7.06373 loss)
I0726 14:27:52.176369 31263 sgd_solver.cpp:138] Iteration 290, lr = 0.001
I0726 14:28:21.743603 31263 solver.cpp:243] Iteration 300, loss = 6.60235
I0726 14:28:21.743759 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.24281 (* 1 = 6.24281 loss)
I0726 14:28:21.743770 31263 sgd_solver.cpp:138] Iteration 300, lr = 0.001
I0726 14:28:51.306113 31263 solver.cpp:243] Iteration 310, loss = 6.5804
I0726 14:28:51.306187 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.18952 (* 1 = 6.18952 loss)
I0726 14:28:51.306195 31263 sgd_solver.cpp:138] Iteration 310, lr = 0.001
I0726 14:29:21.152932 31263 solver.cpp:243] Iteration 320, loss = 6.73924
I0726 14:29:21.153080 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.21392 (* 1 = 6.21392 loss)
I0726 14:29:21.153095 31263 sgd_solver.cpp:138] Iteration 320, lr = 0.001
I0726 14:29:50.983073 31263 solver.cpp:243] Iteration 330, loss = 6.58461
I0726 14:29:50.983105 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.23389 (* 1 = 6.23389 loss)
I0726 14:29:50.983114 31263 sgd_solver.cpp:138] Iteration 330, lr = 0.001
I0726 14:30:20.314281 31263 solver.cpp:243] Iteration 340, loss = 6.53149
I0726 14:30:20.314450 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.26839 (* 1 = 6.26839 loss)
I0726 14:30:20.314462 31263 sgd_solver.cpp:138] Iteration 340, lr = 0.001
I0726 14:30:50.065734 31263 solver.cpp:243] Iteration 350, loss = 6.59073
I0726 14:30:50.065791 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.08467 (* 1 = 6.08467 loss)
I0726 14:30:50.065798 31263 sgd_solver.cpp:138] Iteration 350, lr = 0.001
I0726 14:31:19.556025 31263 solver.cpp:243] Iteration 360, loss = 6.58748
I0726 14:31:19.556265 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.19178 (* 1 = 7.19178 loss)
I0726 14:31:19.556280 31263 sgd_solver.cpp:138] Iteration 360, lr = 0.001
I0726 14:31:49.021325 31263 solver.cpp:243] Iteration 370, loss = 6.49719
I0726 14:31:49.021370 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.33113 (* 1 = 6.33113 loss)
I0726 14:31:49.021381 31263 sgd_solver.cpp:138] Iteration 370, lr = 0.001
I0726 14:32:18.560235 31263 solver.cpp:243] Iteration 380, loss = 6.43718
I0726 14:32:18.560397 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.24111 (* 1 = 6.24111 loss)
I0726 14:32:18.560407 31263 sgd_solver.cpp:138] Iteration 380, lr = 0.001
I0726 14:32:48.010493 31263 solver.cpp:243] Iteration 390, loss = 6.43616
I0726 14:32:48.010537 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.60047 (* 1 = 6.60047 loss)
I0726 14:32:48.010545 31263 sgd_solver.cpp:138] Iteration 390, lr = 0.001
I0726 14:33:17.576849 31263 solver.cpp:243] Iteration 400, loss = 6.40621
I0726 14:33:17.577020 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.91812 (* 1 = 6.91812 loss)
I0726 14:33:17.577029 31263 sgd_solver.cpp:138] Iteration 400, lr = 0.001
I0726 14:33:47.211869 31263 solver.cpp:243] Iteration 410, loss = 6.21685
I0726 14:33:47.212003 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.61991 (* 1 = 6.61991 loss)
I0726 14:33:47.212021 31263 sgd_solver.cpp:138] Iteration 410, lr = 0.001
I0726 14:34:16.579311 31263 solver.cpp:243] Iteration 420, loss = 6.45379
I0726 14:34:16.579502 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.21397 (* 1 = 6.21397 loss)
I0726 14:34:16.579512 31263 sgd_solver.cpp:138] Iteration 420, lr = 0.001
I0726 14:34:46.049062 31263 solver.cpp:243] Iteration 430, loss = 6.27848
I0726 14:34:46.049094 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.4058 (* 1 = 6.4058 loss)
I0726 14:34:46.049103 31263 sgd_solver.cpp:138] Iteration 430, lr = 0.001
I0726 14:35:15.633163 31263 solver.cpp:243] Iteration 440, loss = 6.27743
I0726 14:35:15.633483 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.09284 (* 1 = 6.09284 loss)
I0726 14:35:15.633502 31263 sgd_solver.cpp:138] Iteration 440, lr = 0.001
I0726 14:35:45.179694 31263 solver.cpp:243] Iteration 450, loss = 6.39861
I0726 14:35:45.179726 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.54953 (* 1 = 5.54953 loss)
I0726 14:35:45.179733 31263 sgd_solver.cpp:138] Iteration 450, lr = 0.001
I0726 14:36:14.584571 31263 solver.cpp:243] Iteration 460, loss = 6.4854
I0726 14:36:14.584713 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.93581 (* 1 = 6.93581 loss)
I0726 14:36:14.584720 31263 sgd_solver.cpp:138] Iteration 460, lr = 0.001
I0726 14:36:44.106951 31263 solver.cpp:243] Iteration 470, loss = 6.18493
I0726 14:36:44.106984 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.57231 (* 1 = 6.57231 loss)
I0726 14:36:44.106990 31263 sgd_solver.cpp:138] Iteration 470, lr = 0.001
I0726 14:37:13.656790 31263 solver.cpp:243] Iteration 480, loss = 6.25765
I0726 14:37:13.657485 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.42502 (* 1 = 6.42502 loss)
I0726 14:37:13.657523 31263 sgd_solver.cpp:138] Iteration 480, lr = 0.001
I0726 14:37:43.250130 31263 solver.cpp:243] Iteration 490, loss = 6.25503
I0726 14:37:43.250171 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.29725 (* 1 = 5.29725 loss)
I0726 14:37:43.250180 31263 sgd_solver.cpp:138] Iteration 490, lr = 0.001
I0726 14:38:12.702659 31263 solver.cpp:243] Iteration 500, loss = 6.10641
I0726 14:38:12.702888 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.87866 (* 1 = 5.87866 loss)
I0726 14:38:12.702909 31263 sgd_solver.cpp:138] Iteration 500, lr = 0.001
I0726 14:38:42.333631 31263 solver.cpp:243] Iteration 510, loss = 6.18143
I0726 14:38:42.333683 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.88978 (* 1 = 5.88978 loss)
I0726 14:38:42.333688 31263 sgd_solver.cpp:138] Iteration 510, lr = 0.001
I0726 14:39:11.820935 31263 solver.cpp:243] Iteration 520, loss = 6.25994
I0726 14:39:11.821372 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.4342 (* 1 = 5.4342 loss)
I0726 14:39:11.821380 31263 sgd_solver.cpp:138] Iteration 520, lr = 0.001
I0726 14:39:41.492771 31263 solver.cpp:243] Iteration 530, loss = 6.09272
I0726 14:39:41.492904 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.21767 (* 1 = 6.21767 loss)
I0726 14:39:41.492928 31263 sgd_solver.cpp:138] Iteration 530, lr = 0.001
I0726 14:40:11.089756 31263 solver.cpp:243] Iteration 540, loss = 5.98779
I0726 14:40:11.089890 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.75955 (* 1 = 5.75955 loss)
I0726 14:40:11.089898 31263 sgd_solver.cpp:138] Iteration 540, lr = 0.001
I0726 14:40:40.997673 31263 solver.cpp:243] Iteration 550, loss = 6.11045
I0726 14:40:40.997712 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.94138 (* 1 = 5.94138 loss)
I0726 14:40:40.997721 31263 sgd_solver.cpp:138] Iteration 550, lr = 0.001
I0726 14:41:10.875372 31263 solver.cpp:243] Iteration 560, loss = 6.16035
I0726 14:41:10.875493 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.22624 (* 1 = 6.22624 loss)
I0726 14:41:10.875507 31263 sgd_solver.cpp:138] Iteration 560, lr = 0.001
I0726 14:41:41.035161 31263 solver.cpp:243] Iteration 570, loss = 5.9368
I0726 14:41:41.035284 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.17292 (* 1 = 6.17292 loss)
I0726 14:41:41.035292 31263 sgd_solver.cpp:138] Iteration 570, lr = 0.001
I0726 14:42:10.672116 31263 solver.cpp:243] Iteration 580, loss = 6.08827
I0726 14:42:10.672180 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.75628 (* 1 = 5.75628 loss)
I0726 14:42:10.672190 31263 sgd_solver.cpp:138] Iteration 580, lr = 0.001
I0726 14:42:40.363567 31263 solver.cpp:243] Iteration 590, loss = 5.90697
I0726 14:42:40.363729 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.05659 (* 1 = 5.05659 loss)
I0726 14:42:40.363739 31263 sgd_solver.cpp:138] Iteration 590, lr = 0.001
I0726 14:43:10.151926 31263 solver.cpp:243] Iteration 600, loss = 6.02913
I0726 14:43:10.151962 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.05877 (* 1 = 6.05877 loss)
I0726 14:43:10.151968 31263 sgd_solver.cpp:138] Iteration 600, lr = 0.001
I0726 14:43:39.708711 31263 solver.cpp:243] Iteration 610, loss = 6.10697
I0726 14:43:39.708839 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.91098 (* 1 = 6.91098 loss)
I0726 14:43:39.708849 31263 sgd_solver.cpp:138] Iteration 610, lr = 0.001
I0726 14:44:09.295348 31263 solver.cpp:243] Iteration 620, loss = 5.99007
I0726 14:44:09.295382 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.47164 (* 1 = 5.47164 loss)
I0726 14:44:09.295389 31263 sgd_solver.cpp:138] Iteration 620, lr = 0.001
I0726 14:44:39.027248 31263 solver.cpp:243] Iteration 630, loss = 5.98641
I0726 14:44:39.027602 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.2313 (* 1 = 5.2313 loss)
I0726 14:44:39.027624 31263 sgd_solver.cpp:138] Iteration 630, lr = 0.001
I0726 14:45:08.593380 31263 solver.cpp:243] Iteration 640, loss = 5.95158
I0726 14:45:08.593416 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.92069 (* 1 = 5.92069 loss)
I0726 14:45:08.593422 31263 sgd_solver.cpp:138] Iteration 640, lr = 0.001
I0726 14:45:38.124896 31263 solver.cpp:243] Iteration 650, loss = 6.02826
I0726 14:45:38.125115 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.80504 (* 1 = 5.80504 loss)
I0726 14:45:38.125138 31263 sgd_solver.cpp:138] Iteration 650, lr = 0.001
I0726 14:46:07.914657 31263 solver.cpp:243] Iteration 660, loss = 6.01123
I0726 14:46:07.914687 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.15632 (* 1 = 5.15632 loss)
I0726 14:46:07.914693 31263 sgd_solver.cpp:138] Iteration 660, lr = 0.001
I0726 14:46:37.622005 31263 solver.cpp:243] Iteration 670, loss = 5.84505
I0726 14:46:37.622246 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.55928 (* 1 = 5.55928 loss)
I0726 14:46:37.622261 31263 sgd_solver.cpp:138] Iteration 670, lr = 0.001
I0726 14:47:07.191166 31263 solver.cpp:243] Iteration 680, loss = 5.91624
I0726 14:47:07.191207 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.95992 (* 1 = 5.95992 loss)
I0726 14:47:07.191215 31263 sgd_solver.cpp:138] Iteration 680, lr = 0.001
I0726 14:47:37.021708 31263 solver.cpp:243] Iteration 690, loss = 5.94976
I0726 14:47:37.021952 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.03884 (* 1 = 6.03884 loss)
I0726 14:47:37.021966 31263 sgd_solver.cpp:138] Iteration 690, lr = 0.001
I0726 14:48:06.779247 31263 solver.cpp:243] Iteration 700, loss = 5.93224
I0726 14:48:06.779278 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.86072 (* 1 = 5.86072 loss)
I0726 14:48:06.779284 31263 sgd_solver.cpp:138] Iteration 700, lr = 0.001
I0726 14:48:36.472537 31263 solver.cpp:243] Iteration 710, loss = 5.89344
I0726 14:48:36.472697 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.81503 (* 1 = 5.81503 loss)
I0726 14:48:36.472712 31263 sgd_solver.cpp:138] Iteration 710, lr = 0.001
I0726 14:49:06.139441 31263 solver.cpp:243] Iteration 720, loss = 5.91974
I0726 14:49:06.139533 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.26565 (* 1 = 5.26565 loss)
I0726 14:49:06.139550 31263 sgd_solver.cpp:138] Iteration 720, lr = 0.001
I0726 14:49:35.739511 31263 solver.cpp:243] Iteration 730, loss = 6.0661
I0726 14:49:35.739711 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.99252 (* 1 = 5.99252 loss)
I0726 14:49:35.739719 31263 sgd_solver.cpp:138] Iteration 730, lr = 0.001
I0726 14:50:05.285864 31263 solver.cpp:243] Iteration 740, loss = 5.88843
I0726 14:50:05.285910 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.65944 (* 1 = 5.65944 loss)
I0726 14:50:05.285920 31263 sgd_solver.cpp:138] Iteration 740, lr = 0.001
I0726 14:50:35.028802 31263 solver.cpp:243] Iteration 750, loss = 5.83557
I0726 14:50:35.029160 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.34271 (* 1 = 5.34271 loss)
I0726 14:50:35.029178 31263 sgd_solver.cpp:138] Iteration 750, lr = 0.001
I0726 14:51:04.919431 31263 solver.cpp:243] Iteration 760, loss = 5.77262
I0726 14:51:04.919536 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.195 (* 1 = 6.195 loss)
I0726 14:51:04.919548 31263 sgd_solver.cpp:138] Iteration 760, lr = 0.001
I0726 14:51:34.676750 31263 solver.cpp:243] Iteration 770, loss = 5.91621
I0726 14:51:34.676844 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.06408 (* 1 = 6.06408 loss)
I0726 14:51:34.676854 31263 sgd_solver.cpp:138] Iteration 770, lr = 0.001
I0726 14:52:04.322731 31263 solver.cpp:243] Iteration 780, loss = 5.78213
I0726 14:52:04.322796 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.92358 (* 1 = 5.92358 loss)
I0726 14:52:04.322803 31263 sgd_solver.cpp:138] Iteration 780, lr = 0.001
I0726 14:52:34.319711 31263 solver.cpp:243] Iteration 790, loss = 5.70193
I0726 14:52:34.319989 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.57808 (* 1 = 5.57808 loss)
I0726 14:52:34.320008 31263 sgd_solver.cpp:138] Iteration 790, lr = 0.001
I0726 14:53:03.969130 31263 solver.cpp:243] Iteration 800, loss = 5.82827
I0726 14:53:03.969158 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.16039 (* 1 = 6.16039 loss)
I0726 14:53:03.969166 31263 sgd_solver.cpp:138] Iteration 800, lr = 0.001
I0726 14:53:33.610607 31263 solver.cpp:243] Iteration 810, loss = 5.82146
I0726 14:53:33.610733 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.1338 (* 1 = 6.1338 loss)
I0726 14:53:33.610743 31263 sgd_solver.cpp:138] Iteration 810, lr = 0.001
I0726 14:54:03.267096 31263 solver.cpp:243] Iteration 820, loss = 5.69676
I0726 14:54:03.267122 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.21017 (* 1 = 5.21017 loss)
I0726 14:54:03.267128 31263 sgd_solver.cpp:138] Iteration 820, lr = 0.001
I0726 14:54:32.678504 31263 solver.cpp:243] Iteration 830, loss = 5.766
I0726 14:54:32.678640 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.635 (* 1 = 5.635 loss)
I0726 14:54:32.678647 31263 sgd_solver.cpp:138] Iteration 830, lr = 0.001
I0726 14:55:02.120095 31263 solver.cpp:243] Iteration 840, loss = 5.71317
I0726 14:55:02.120128 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.23815 (* 1 = 6.23815 loss)
I0726 14:55:02.120136 31263 sgd_solver.cpp:138] Iteration 840, lr = 0.001
I0726 14:55:31.557636 31263 solver.cpp:243] Iteration 850, loss = 5.82515
I0726 14:55:31.557754 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.4336 (* 1 = 7.4336 loss)
I0726 14:55:31.557765 31263 sgd_solver.cpp:138] Iteration 850, lr = 0.001
I0726 14:56:01.151916 31263 solver.cpp:243] Iteration 860, loss = 5.78728
I0726 14:56:01.151962 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.91119 (* 1 = 4.91119 loss)
I0726 14:56:01.151970 31263 sgd_solver.cpp:138] Iteration 860, lr = 0.001
I0726 14:56:30.790683 31263 solver.cpp:243] Iteration 870, loss = 5.72172
I0726 14:56:30.790758 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.08602 (* 1 = 6.08602 loss)
I0726 14:56:30.790769 31263 sgd_solver.cpp:138] Iteration 870, lr = 0.001
I0726 14:57:00.381176 31263 solver.cpp:243] Iteration 880, loss = 5.71718
I0726 14:57:00.381212 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.50421 (* 1 = 5.50421 loss)
I0726 14:57:00.381222 31263 sgd_solver.cpp:138] Iteration 880, lr = 0.001
I0726 14:57:30.193094 31263 solver.cpp:243] Iteration 890, loss = 5.64796
I0726 14:57:30.193269 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.27708 (* 1 = 6.27708 loss)
I0726 14:57:30.193279 31263 sgd_solver.cpp:138] Iteration 890, lr = 0.001
I0726 14:57:59.740980 31263 solver.cpp:243] Iteration 900, loss = 5.79799
I0726 14:57:59.741053 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.38517 (* 1 = 5.38517 loss)
I0726 14:57:59.741060 31263 sgd_solver.cpp:138] Iteration 900, lr = 0.001
I0726 14:58:29.315666 31263 solver.cpp:243] Iteration 910, loss = 5.52766
I0726 14:58:29.315908 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.55894 (* 1 = 5.55894 loss)
I0726 14:58:29.315917 31263 sgd_solver.cpp:138] Iteration 910, lr = 0.001
I0726 14:58:58.764755 31263 solver.cpp:243] Iteration 920, loss = 5.67333
I0726 14:58:58.764782 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.48385 (* 1 = 5.48385 loss)
I0726 14:58:58.764788 31263 sgd_solver.cpp:138] Iteration 920, lr = 0.001
I0726 14:59:28.314898 31263 solver.cpp:243] Iteration 930, loss = 5.73184
I0726 14:59:28.315210 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.7859 (* 1 = 5.7859 loss)
I0726 14:59:28.315227 31263 sgd_solver.cpp:138] Iteration 930, lr = 0.001
I0726 14:59:57.821123 31263 solver.cpp:243] Iteration 940, loss = 5.72769
I0726 14:59:57.821156 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.23371 (* 1 = 5.23371 loss)
I0726 14:59:57.821162 31263 sgd_solver.cpp:138] Iteration 940, lr = 0.001
I0726 15:00:27.214781 31263 solver.cpp:243] Iteration 950, loss = 5.61548
I0726 15:00:27.214936 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.48532 (* 1 = 6.48532 loss)
I0726 15:00:27.214943 31263 sgd_solver.cpp:138] Iteration 950, lr = 0.001
I0726 15:00:56.770781 31263 solver.cpp:243] Iteration 960, loss = 5.65427
I0726 15:00:56.770828 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.62387 (* 1 = 4.62387 loss)
I0726 15:00:56.770835 31263 sgd_solver.cpp:138] Iteration 960, lr = 0.001
I0726 15:01:26.299058 31263 solver.cpp:243] Iteration 970, loss = 5.72832
I0726 15:01:26.299197 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.77409 (* 1 = 5.77409 loss)
I0726 15:01:26.299204 31263 sgd_solver.cpp:138] Iteration 970, lr = 0.001
I0726 15:01:55.916532 31263 solver.cpp:243] Iteration 980, loss = 5.5327
I0726 15:01:55.916632 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.23926 (* 1 = 5.23926 loss)
I0726 15:01:55.916647 31263 sgd_solver.cpp:138] Iteration 980, lr = 0.001
I0726 15:02:25.452352 31263 solver.cpp:243] Iteration 990, loss = 5.52485
I0726 15:02:25.452471 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.77614 (* 1 = 5.77614 loss)
I0726 15:02:25.452479 31263 sgd_solver.cpp:138] Iteration 990, lr = 0.001
I0726 15:02:52.036002 31263 solver.cpp:433] Iteration 1000, Testing net (#0)
I0726 15:02:52.489214 31263 net.cpp:693] Ignoring source layer mbox_loss
W0726 15:02:55.641602 31263 solver.cpp:524] Missing true_pos for label: 6
W0726 15:02:55.641782 31263 solver.cpp:524] Missing true_pos for label: 8
W0726 15:02:55.641801 31263 solver.cpp:524] Missing true_pos for label: 9
W0726 15:02:55.641810 31263 solver.cpp:524] Missing true_pos for label: 11
W0726 15:02:55.641820 31263 solver.cpp:524] Missing true_pos for label: 12
W0726 15:02:55.641970 31263 solver.cpp:524] Missing true_pos for label: 15
W0726 15:02:55.641978 31263 solver.cpp:524] Missing true_pos for label: 16
W0726 15:02:55.641983 31263 solver.cpp:524] Missing true_pos for label: 17
W0726 15:02:55.641986 31263 solver.cpp:524] Missing true_pos for label: 18
W0726 15:02:55.642242 31263 solver.cpp:524] Missing true_pos for label: 21
W0726 15:02:55.642249 31263 solver.cpp:524] Missing true_pos for label: 22
W0726 15:02:55.642253 31263 solver.cpp:524] Missing true_pos for label: 23
W0726 15:02:55.642331 31263 solver.cpp:524] Missing true_pos for label: 28
W0726 15:02:55.642336 31263 solver.cpp:524] Missing true_pos for label: 29
W0726 15:02:55.642340 31263 solver.cpp:524] Missing true_pos for label: 30
W0726 15:02:55.642393 31263 solver.cpp:524] Missing true_pos for label: 32
W0726 15:02:55.642468 31263 solver.cpp:524] Missing true_pos for label: 34
W0726 15:02:55.644292 31263 solver.cpp:524] Missing true_pos for label: 43
W0726 15:02:55.644402 31263 solver.cpp:524] Missing true_pos for label: 49
W0726 15:02:55.644407 31263 solver.cpp:524] Missing true_pos for label: 50
W0726 15:02:55.644426 31263 solver.cpp:524] Missing true_pos for label: 52
W0726 15:02:55.644431 31263 solver.cpp:524] Missing true_pos for label: 53
W0726 15:02:55.644449 31263 solver.cpp:524] Missing true_pos for label: 56
W0726 15:02:55.644455 31263 solver.cpp:524] Missing true_pos for label: 57
W0726 15:02:55.644459 31263 solver.cpp:524] Missing true_pos for label: 58
I0726 15:02:55.644467 31263 solver.cpp:546]     Test net output #0: detection_eval = 0.129983
I0726 15:02:58.158171 31263 solver.cpp:243] Iteration 1000, loss = 5.57124
I0726 15:02:58.158241 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.3416 (* 1 = 6.3416 loss)
I0726 15:02:58.158248 31263 sgd_solver.cpp:138] Iteration 1000, lr = 0.001
I0726 15:03:27.602466 31263 solver.cpp:243] Iteration 1010, loss = 5.63818
I0726 15:03:27.602560 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.88277 (* 1 = 4.88277 loss)
I0726 15:03:27.602567 31263 sgd_solver.cpp:138] Iteration 1010, lr = 0.001
I0726 15:03:57.086195 31263 solver.cpp:243] Iteration 1020, loss = 5.48989
I0726 15:03:57.086249 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.26474 (* 1 = 5.26474 loss)
I0726 15:03:57.086256 31263 sgd_solver.cpp:138] Iteration 1020, lr = 0.001
I0726 15:04:26.603247 31263 solver.cpp:243] Iteration 1030, loss = 5.71428
I0726 15:04:26.603473 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.36678 (* 1 = 5.36678 loss)
I0726 15:04:26.603485 31263 sgd_solver.cpp:138] Iteration 1030, lr = 0.001
I0726 15:04:56.149562 31263 solver.cpp:243] Iteration 1040, loss = 5.64907
I0726 15:04:56.149598 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.87763 (* 1 = 4.87763 loss)
I0726 15:04:56.149606 31263 sgd_solver.cpp:138] Iteration 1040, lr = 0.001
I0726 15:05:25.683241 31263 solver.cpp:243] Iteration 1050, loss = 5.49537
I0726 15:05:25.683357 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.25146 (* 1 = 6.25146 loss)
I0726 15:05:25.683365 31263 sgd_solver.cpp:138] Iteration 1050, lr = 0.001
I0726 15:05:55.241585 31263 solver.cpp:243] Iteration 1060, loss = 5.47526
I0726 15:05:55.241652 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.87016 (* 1 = 5.87016 loss)
I0726 15:05:55.241662 31263 sgd_solver.cpp:138] Iteration 1060, lr = 0.001
I0726 15:06:24.758162 31263 solver.cpp:243] Iteration 1070, loss = 5.45765
I0726 15:06:24.758328 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.47996 (* 1 = 6.47996 loss)
I0726 15:06:24.758339 31263 sgd_solver.cpp:138] Iteration 1070, lr = 0.001
I0726 15:06:54.433985 31263 solver.cpp:243] Iteration 1080, loss = 5.56521
I0726 15:06:54.434021 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.26289 (* 1 = 6.26289 loss)
I0726 15:06:54.434031 31263 sgd_solver.cpp:138] Iteration 1080, lr = 0.001
I0726 15:07:24.011422 31263 solver.cpp:243] Iteration 1090, loss = 5.38989
I0726 15:07:24.011641 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.34406 (* 1 = 5.34406 loss)
I0726 15:07:24.011652 31263 sgd_solver.cpp:138] Iteration 1090, lr = 0.001
I0726 15:07:53.559001 31263 solver.cpp:243] Iteration 1100, loss = 5.36508
I0726 15:07:53.559075 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.45867 (* 1 = 4.45867 loss)
I0726 15:07:53.559082 31263 sgd_solver.cpp:138] Iteration 1100, lr = 0.001
I0726 15:08:23.127198 31263 solver.cpp:243] Iteration 1110, loss = 5.51918
I0726 15:08:23.127377 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.09697 (* 1 = 5.09697 loss)
I0726 15:08:23.127387 31263 sgd_solver.cpp:138] Iteration 1110, lr = 0.001
I0726 15:08:52.600101 31263 solver.cpp:243] Iteration 1120, loss = 5.41153
I0726 15:08:52.600131 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.97831 (* 1 = 5.97831 loss)
I0726 15:08:52.600137 31263 sgd_solver.cpp:138] Iteration 1120, lr = 0.001
I0726 15:09:22.238019 31263 solver.cpp:243] Iteration 1130, loss = 5.32665
I0726 15:09:22.238229 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.55243 (* 1 = 5.55243 loss)
I0726 15:09:22.238240 31263 sgd_solver.cpp:138] Iteration 1130, lr = 0.001
I0726 15:09:52.065783 31263 solver.cpp:243] Iteration 1140, loss = 5.41447
I0726 15:09:52.065956 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.22487 (* 1 = 5.22487 loss)
I0726 15:09:52.065978 31263 sgd_solver.cpp:138] Iteration 1140, lr = 0.001
I0726 15:10:21.584415 31263 solver.cpp:243] Iteration 1150, loss = 5.47966
I0726 15:10:21.584497 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.82847 (* 1 = 4.82847 loss)
I0726 15:10:21.584506 31263 sgd_solver.cpp:138] Iteration 1150, lr = 0.001
I0726 15:10:51.178990 31263 solver.cpp:243] Iteration 1160, loss = 5.46573
I0726 15:10:51.179024 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.08843 (* 1 = 5.08843 loss)
I0726 15:10:51.179031 31263 sgd_solver.cpp:138] Iteration 1160, lr = 0.001
I0726 15:11:20.731251 31263 solver.cpp:243] Iteration 1170, loss = 5.39093
I0726 15:11:20.731474 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.66374 (* 1 = 5.66374 loss)
I0726 15:11:20.731485 31263 sgd_solver.cpp:138] Iteration 1170, lr = 0.001
I0726 15:11:50.363888 31263 solver.cpp:243] Iteration 1180, loss = 5.49928
I0726 15:11:50.363927 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.08928 (* 1 = 6.08928 loss)
I0726 15:11:50.363941 31263 sgd_solver.cpp:138] Iteration 1180, lr = 0.001
I0726 15:12:19.854495 31263 solver.cpp:243] Iteration 1190, loss = 5.43016
I0726 15:12:19.854712 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.17008 (* 1 = 6.17008 loss)
I0726 15:12:19.854722 31263 sgd_solver.cpp:138] Iteration 1190, lr = 0.001
I0726 15:12:49.636315 31263 solver.cpp:243] Iteration 1200, loss = 5.42377
I0726 15:12:49.636379 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.87814 (* 1 = 5.87814 loss)
I0726 15:12:49.636390 31263 sgd_solver.cpp:138] Iteration 1200, lr = 0.001
I0726 15:13:19.680701 31263 solver.cpp:243] Iteration 1210, loss = 5.37714
I0726 15:13:19.680897 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.14844 (* 1 = 5.14844 loss)
I0726 15:13:19.680910 31263 sgd_solver.cpp:138] Iteration 1210, lr = 0.001
I0726 15:13:49.730005 31263 solver.cpp:243] Iteration 1220, loss = 5.44949
I0726 15:13:49.730193 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.35353 (* 1 = 5.35353 loss)
I0726 15:13:49.730223 31263 sgd_solver.cpp:138] Iteration 1220, lr = 0.001
I0726 15:14:19.532295 31263 solver.cpp:243] Iteration 1230, loss = 5.44006
I0726 15:14:19.532331 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.90208 (* 1 = 4.90208 loss)
I0726 15:14:19.532340 31263 sgd_solver.cpp:138] Iteration 1230, lr = 0.001
I0726 15:14:49.154049 31263 solver.cpp:243] Iteration 1240, loss = 5.45937
I0726 15:14:49.154505 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.68033 (* 1 = 4.68033 loss)
I0726 15:14:49.154551 31263 sgd_solver.cpp:138] Iteration 1240, lr = 0.001
I0726 15:15:18.860574 31263 solver.cpp:243] Iteration 1250, loss = 5.585
I0726 15:15:18.860625 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.18677 (* 1 = 5.18677 loss)
I0726 15:15:18.860633 31263 sgd_solver.cpp:138] Iteration 1250, lr = 0.001
I0726 15:15:48.762279 31263 solver.cpp:243] Iteration 1260, loss = 5.27545
I0726 15:15:48.762460 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.67832 (* 1 = 4.67832 loss)
I0726 15:15:48.762472 31263 sgd_solver.cpp:138] Iteration 1260, lr = 0.001
I0726 15:16:18.445370 31263 solver.cpp:243] Iteration 1270, loss = 5.44664
I0726 15:16:18.445447 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.63769 (* 1 = 6.63769 loss)
I0726 15:16:18.445456 31263 sgd_solver.cpp:138] Iteration 1270, lr = 0.001
I0726 15:16:48.071813 31263 solver.cpp:243] Iteration 1280, loss = 5.48509
I0726 15:16:48.072012 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.42207 (* 1 = 6.42207 loss)
I0726 15:16:48.072031 31263 sgd_solver.cpp:138] Iteration 1280, lr = 0.001
I0726 15:17:17.723269 31263 solver.cpp:243] Iteration 1290, loss = 5.44925
I0726 15:17:17.723307 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.44891 (* 1 = 5.44891 loss)
I0726 15:17:17.723314 31263 sgd_solver.cpp:138] Iteration 1290, lr = 0.001
I0726 15:17:47.463393 31263 solver.cpp:243] Iteration 1300, loss = 5.35824
I0726 15:17:47.463686 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.41571 (* 1 = 5.41571 loss)
I0726 15:17:47.463706 31263 sgd_solver.cpp:138] Iteration 1300, lr = 0.001
I0726 15:18:17.220177 31263 solver.cpp:243] Iteration 1310, loss = 5.39793
I0726 15:18:17.220209 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.14022 (* 1 = 5.14022 loss)
I0726 15:18:17.220216 31263 sgd_solver.cpp:138] Iteration 1310, lr = 0.001
I0726 15:18:47.126106 31263 solver.cpp:243] Iteration 1320, loss = 5.31168
I0726 15:18:47.126313 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.87338 (* 1 = 4.87338 loss)
I0726 15:18:47.126327 31263 sgd_solver.cpp:138] Iteration 1320, lr = 0.001
I0726 15:19:16.896373 31263 solver.cpp:243] Iteration 1330, loss = 5.42376
I0726 15:19:16.896407 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.08266 (* 1 = 5.08266 loss)
I0726 15:19:16.896414 31263 sgd_solver.cpp:138] Iteration 1330, lr = 0.001
I0726 15:19:46.501253 31263 solver.cpp:243] Iteration 1340, loss = 5.44889
I0726 15:19:46.501417 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.03827 (* 1 = 5.03827 loss)
I0726 15:19:46.501425 31263 sgd_solver.cpp:138] Iteration 1340, lr = 0.001
I0726 15:20:16.236021 31263 solver.cpp:243] Iteration 1350, loss = 5.31698
I0726 15:20:16.236048 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.28103 (* 1 = 5.28103 loss)
I0726 15:20:16.236054 31263 sgd_solver.cpp:138] Iteration 1350, lr = 0.001
I0726 15:20:45.812494 31263 solver.cpp:243] Iteration 1360, loss = 5.31223
I0726 15:20:45.812691 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.06724 (* 1 = 5.06724 loss)
I0726 15:20:45.812701 31263 sgd_solver.cpp:138] Iteration 1360, lr = 0.001
I0726 15:21:15.404603 31263 solver.cpp:243] Iteration 1370, loss = 5.40394
I0726 15:21:15.404641 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.67534 (* 1 = 5.67534 loss)
I0726 15:21:15.404649 31263 sgd_solver.cpp:138] Iteration 1370, lr = 0.001
I0726 15:21:44.906829 31263 solver.cpp:243] Iteration 1380, loss = 5.23159
I0726 15:21:44.906945 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.28118 (* 1 = 4.28118 loss)
I0726 15:21:44.906952 31263 sgd_solver.cpp:138] Iteration 1380, lr = 0.001
I0726 15:22:14.484814 31263 solver.cpp:243] Iteration 1390, loss = 5.39441
I0726 15:22:14.484845 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.78624 (* 1 = 5.78624 loss)
I0726 15:22:14.484851 31263 sgd_solver.cpp:138] Iteration 1390, lr = 0.001
I0726 15:22:43.847127 31263 solver.cpp:243] Iteration 1400, loss = 5.32438
I0726 15:22:43.847332 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.11208 (* 1 = 6.11208 loss)
I0726 15:22:43.847342 31263 sgd_solver.cpp:138] Iteration 1400, lr = 0.001
I0726 15:23:13.449846 31263 solver.cpp:243] Iteration 1410, loss = 5.33016
I0726 15:23:13.449898 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.76745 (* 1 = 5.76745 loss)
I0726 15:23:13.449905 31263 sgd_solver.cpp:138] Iteration 1410, lr = 0.001
I0726 15:23:43.013875 31263 solver.cpp:243] Iteration 1420, loss = 5.37403
I0726 15:23:43.014047 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.92793 (* 1 = 5.92793 loss)
I0726 15:23:43.014058 31263 sgd_solver.cpp:138] Iteration 1420, lr = 0.001
I0726 15:24:12.555506 31263 solver.cpp:243] Iteration 1430, loss = 5.23719
I0726 15:24:12.555538 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.67488 (* 1 = 4.67488 loss)
I0726 15:24:12.555547 31263 sgd_solver.cpp:138] Iteration 1430, lr = 0.001
I0726 15:24:42.130056 31263 solver.cpp:243] Iteration 1440, loss = 5.12727
I0726 15:24:42.130164 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.22195 (* 1 = 5.22195 loss)
I0726 15:24:42.130175 31263 sgd_solver.cpp:138] Iteration 1440, lr = 0.001
I0726 15:25:11.612722 31263 solver.cpp:243] Iteration 1450, loss = 5.50875
I0726 15:25:11.612790 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.31586 (* 1 = 5.31586 loss)
I0726 15:25:11.612799 31263 sgd_solver.cpp:138] Iteration 1450, lr = 0.001
I0726 15:25:41.211688 31263 solver.cpp:243] Iteration 1460, loss = 5.26206
I0726 15:25:41.211803 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.96074 (* 1 = 4.96074 loss)
I0726 15:25:41.211812 31263 sgd_solver.cpp:138] Iteration 1460, lr = 0.001
I0726 15:26:10.605087 31263 solver.cpp:243] Iteration 1470, loss = 5.3211
I0726 15:26:10.605176 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.56162 (* 1 = 5.56162 loss)
I0726 15:26:10.605192 31263 sgd_solver.cpp:138] Iteration 1470, lr = 0.001
I0726 15:26:40.170516 31263 solver.cpp:243] Iteration 1480, loss = 5.37769
I0726 15:26:40.170658 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.14997 (* 1 = 5.14997 loss)
I0726 15:26:40.170675 31263 sgd_solver.cpp:138] Iteration 1480, lr = 0.001
I0726 15:27:09.860518 31263 solver.cpp:243] Iteration 1490, loss = 5.44909
I0726 15:27:09.860574 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.96589 (* 1 = 5.96589 loss)
I0726 15:27:09.860585 31263 sgd_solver.cpp:138] Iteration 1490, lr = 0.001
I0726 15:27:39.503334 31263 solver.cpp:243] Iteration 1500, loss = 5.18636
I0726 15:27:39.503589 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.1277 (* 1 = 6.1277 loss)
I0726 15:27:39.503607 31263 sgd_solver.cpp:138] Iteration 1500, lr = 0.001
I0726 15:28:09.138871 31263 solver.cpp:243] Iteration 1510, loss = 5.214
I0726 15:28:09.138895 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.96839 (* 1 = 4.96839 loss)
I0726 15:28:09.138900 31263 sgd_solver.cpp:138] Iteration 1510, lr = 0.001
I0726 15:28:38.717360 31263 solver.cpp:243] Iteration 1520, loss = 5.2893
I0726 15:28:38.717614 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.74716 (* 1 = 5.74716 loss)
I0726 15:28:38.717630 31263 sgd_solver.cpp:138] Iteration 1520, lr = 0.001
I0726 15:29:08.297271 31263 solver.cpp:243] Iteration 1530, loss = 5.22406
I0726 15:29:08.297304 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.50445 (* 1 = 5.50445 loss)
I0726 15:29:08.297312 31263 sgd_solver.cpp:138] Iteration 1530, lr = 0.001
I0726 15:29:37.809118 31263 solver.cpp:243] Iteration 1540, loss = 5.11991
I0726 15:29:37.809595 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.12979 (* 1 = 4.12979 loss)
I0726 15:29:37.809604 31263 sgd_solver.cpp:138] Iteration 1540, lr = 0.001
I0726 15:30:07.527415 31263 solver.cpp:243] Iteration 1550, loss = 5.21362
I0726 15:30:07.527441 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.15633 (* 1 = 7.15633 loss)
I0726 15:30:07.527448 31263 sgd_solver.cpp:138] Iteration 1550, lr = 0.001
I0726 15:30:37.122619 31263 solver.cpp:243] Iteration 1560, loss = 5.22501
I0726 15:30:37.122913 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.50743 (* 1 = 5.50743 loss)
I0726 15:30:37.122922 31263 sgd_solver.cpp:138] Iteration 1560, lr = 0.001
I0726 15:31:06.633939 31263 solver.cpp:243] Iteration 1570, loss = 5.03185
I0726 15:31:06.633985 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.43112 (* 1 = 4.43112 loss)
I0726 15:31:06.633993 31263 sgd_solver.cpp:138] Iteration 1570, lr = 0.001
I0726 15:31:36.140336 31263 solver.cpp:243] Iteration 1580, loss = 5.14981
I0726 15:31:36.140497 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.00363 (* 1 = 5.00363 loss)
I0726 15:31:36.140507 31263 sgd_solver.cpp:138] Iteration 1580, lr = 0.001
I0726 15:32:05.727195 31263 solver.cpp:243] Iteration 1590, loss = 5.32648
I0726 15:32:05.727250 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.48537 (* 1 = 5.48537 loss)
I0726 15:32:05.727260 31263 sgd_solver.cpp:138] Iteration 1590, lr = 0.001
I0726 15:32:35.352190 31263 solver.cpp:243] Iteration 1600, loss = 5.21085
I0726 15:32:35.352421 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.11626 (* 1 = 5.11626 loss)
I0726 15:32:35.352433 31263 sgd_solver.cpp:138] Iteration 1600, lr = 0.001
I0726 15:33:05.131672 31263 solver.cpp:243] Iteration 1610, loss = 5.15275
I0726 15:33:05.131707 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.93351 (* 1 = 4.93351 loss)
I0726 15:33:05.131713 31263 sgd_solver.cpp:138] Iteration 1610, lr = 0.001
I0726 15:33:34.651998 31263 solver.cpp:243] Iteration 1620, loss = 5.17231
I0726 15:33:34.652261 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.43743 (* 1 = 4.43743 loss)
I0726 15:33:34.652278 31263 sgd_solver.cpp:138] Iteration 1620, lr = 0.001
I0726 15:34:04.129040 31263 solver.cpp:243] Iteration 1630, loss = 5.19765
I0726 15:34:04.129089 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.91993 (* 1 = 4.91993 loss)
I0726 15:34:04.129096 31263 sgd_solver.cpp:138] Iteration 1630, lr = 0.001
I0726 15:34:33.603250 31263 solver.cpp:243] Iteration 1640, loss = 5.13884
I0726 15:34:33.603811 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.99689 (* 1 = 4.99689 loss)
I0726 15:34:33.603821 31263 sgd_solver.cpp:138] Iteration 1640, lr = 0.001
I0726 15:35:03.165522 31263 solver.cpp:243] Iteration 1650, loss = 5.277
I0726 15:35:03.165617 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.28185 (* 1 = 5.28185 loss)
I0726 15:35:03.165632 31263 sgd_solver.cpp:138] Iteration 1650, lr = 0.001
I0726 15:35:32.745414 31263 solver.cpp:243] Iteration 1660, loss = 5.25119
I0726 15:35:32.745831 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.94472 (* 1 = 5.94472 loss)
I0726 15:35:32.745848 31263 sgd_solver.cpp:138] Iteration 1660, lr = 0.001
I0726 15:36:02.276212 31263 solver.cpp:243] Iteration 1670, loss = 5.24624
I0726 15:36:02.276248 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.50143 (* 1 = 5.50143 loss)
I0726 15:36:02.276257 31263 sgd_solver.cpp:138] Iteration 1670, lr = 0.001
I0726 15:36:31.969893 31263 solver.cpp:243] Iteration 1680, loss = 5.04094
I0726 15:36:31.970003 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.95231 (* 1 = 4.95231 loss)
I0726 15:36:31.970037 31263 sgd_solver.cpp:138] Iteration 1680, lr = 0.001
I0726 15:37:01.365675 31263 solver.cpp:243] Iteration 1690, loss = 5.17652
I0726 15:37:01.365712 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.71046 (* 1 = 5.71046 loss)
I0726 15:37:01.365718 31263 sgd_solver.cpp:138] Iteration 1690, lr = 0.001
I0726 15:37:30.755115 31263 solver.cpp:243] Iteration 1700, loss = 5.21883
I0726 15:37:30.755278 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.49037 (* 1 = 5.49037 loss)
I0726 15:37:30.755293 31263 sgd_solver.cpp:138] Iteration 1700, lr = 0.001
I0726 15:38:00.356603 31263 solver.cpp:243] Iteration 1710, loss = 5.0729
I0726 15:38:00.356644 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.26198 (* 1 = 5.26198 loss)
I0726 15:38:00.356652 31263 sgd_solver.cpp:138] Iteration 1710, lr = 0.001
I0726 15:38:29.924533 31263 solver.cpp:243] Iteration 1720, loss = 5.19312
I0726 15:38:29.924693 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.22694 (* 1 = 5.22694 loss)
I0726 15:38:29.924700 31263 sgd_solver.cpp:138] Iteration 1720, lr = 0.001
I0726 15:38:59.544245 31263 solver.cpp:243] Iteration 1730, loss = 5.21495
I0726 15:38:59.544286 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.83085 (* 1 = 4.83085 loss)
I0726 15:38:59.544293 31263 sgd_solver.cpp:138] Iteration 1730, lr = 0.001
I0726 15:39:29.103912 31263 solver.cpp:243] Iteration 1740, loss = 5.0756
I0726 15:39:29.104068 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.12755 (* 1 = 5.12755 loss)
I0726 15:39:29.104079 31263 sgd_solver.cpp:138] Iteration 1740, lr = 0.001
I0726 15:39:58.670497 31263 solver.cpp:243] Iteration 1750, loss = 5.21615
I0726 15:39:58.670543 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.55536 (* 1 = 5.55536 loss)
I0726 15:39:58.670552 31263 sgd_solver.cpp:138] Iteration 1750, lr = 0.001
I0726 15:40:28.476569 31263 solver.cpp:243] Iteration 1760, loss = 5.25283
I0726 15:40:28.476776 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.22537 (* 1 = 5.22537 loss)
I0726 15:40:28.476794 31263 sgd_solver.cpp:138] Iteration 1760, lr = 0.001
I0726 15:40:58.038964 31263 solver.cpp:243] Iteration 1770, loss = 5.11106
I0726 15:40:58.039000 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.61378 (* 1 = 4.61378 loss)
I0726 15:40:58.039005 31263 sgd_solver.cpp:138] Iteration 1770, lr = 0.001
I0726 15:41:27.636504 31263 solver.cpp:243] Iteration 1780, loss = 5.02624
I0726 15:41:27.637048 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.35802 (* 1 = 4.35802 loss)
I0726 15:41:27.637056 31263 sgd_solver.cpp:138] Iteration 1780, lr = 0.001
I0726 15:41:57.284812 31263 solver.cpp:243] Iteration 1790, loss = 5.03942
I0726 15:41:57.284859 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.21596 (* 1 = 4.21596 loss)
I0726 15:41:57.284868 31263 sgd_solver.cpp:138] Iteration 1790, lr = 0.001
I0726 15:42:26.801178 31263 solver.cpp:243] Iteration 1800, loss = 5.08163
I0726 15:42:26.801419 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.85698 (* 1 = 4.85698 loss)
I0726 15:42:26.801430 31263 sgd_solver.cpp:138] Iteration 1800, lr = 0.001
I0726 15:42:56.344398 31263 solver.cpp:243] Iteration 1810, loss = 5.21684
I0726 15:42:56.344478 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.46261 (* 1 = 6.46261 loss)
I0726 15:42:56.344497 31263 sgd_solver.cpp:138] Iteration 1810, lr = 0.001
I0726 15:43:25.841871 31263 solver.cpp:243] Iteration 1820, loss = 5.20335
I0726 15:43:25.842063 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.70827 (* 1 = 4.70827 loss)
I0726 15:43:25.842072 31263 sgd_solver.cpp:138] Iteration 1820, lr = 0.001
I0726 15:43:55.279156 31263 solver.cpp:243] Iteration 1830, loss = 5.25255
I0726 15:43:55.279259 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.2669 (* 1 = 5.2669 loss)
I0726 15:43:55.279278 31263 sgd_solver.cpp:138] Iteration 1830, lr = 0.001
I0726 15:44:25.011011 31263 solver.cpp:243] Iteration 1840, loss = 5.16008
I0726 15:44:25.011174 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.75858 (* 1 = 5.75858 loss)
I0726 15:44:25.011183 31263 sgd_solver.cpp:138] Iteration 1840, lr = 0.001
I0726 15:44:54.482414 31263 solver.cpp:243] Iteration 1850, loss = 5.04137
I0726 15:44:54.482470 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.52647 (* 1 = 4.52647 loss)
I0726 15:44:54.482476 31263 sgd_solver.cpp:138] Iteration 1850, lr = 0.001
I0726 15:45:24.008353 31263 solver.cpp:243] Iteration 1860, loss = 5.1788
I0726 15:45:24.008589 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.07986 (* 1 = 5.07986 loss)
I0726 15:45:24.008602 31263 sgd_solver.cpp:138] Iteration 1860, lr = 0.001
I0726 15:45:53.541555 31263 solver.cpp:243] Iteration 1870, loss = 5.16601
I0726 15:45:53.541585 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.27166 (* 1 = 5.27166 loss)
I0726 15:45:53.541592 31263 sgd_solver.cpp:138] Iteration 1870, lr = 0.001
I0726 15:46:23.091262 31263 solver.cpp:243] Iteration 1880, loss = 4.92845
I0726 15:46:23.091460 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.38029 (* 1 = 5.38029 loss)
I0726 15:46:23.091470 31263 sgd_solver.cpp:138] Iteration 1880, lr = 0.001
I0726 15:46:52.612229 31263 solver.cpp:243] Iteration 1890, loss = 5.06769
I0726 15:46:52.612287 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.53339 (* 1 = 4.53339 loss)
I0726 15:46:52.612298 31263 sgd_solver.cpp:138] Iteration 1890, lr = 0.001
I0726 15:47:22.224160 31263 solver.cpp:243] Iteration 1900, loss = 5.23896
I0726 15:47:22.224267 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.54615 (* 1 = 4.54615 loss)
I0726 15:47:22.224274 31263 sgd_solver.cpp:138] Iteration 1900, lr = 0.001
I0726 15:47:51.771879 31263 solver.cpp:243] Iteration 1910, loss = 4.99576
I0726 15:47:51.771916 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.85188 (* 1 = 4.85188 loss)
I0726 15:47:51.771924 31263 sgd_solver.cpp:138] Iteration 1910, lr = 0.001
I0726 15:48:21.311301 31263 solver.cpp:243] Iteration 1920, loss = 5.02627
I0726 15:48:21.311494 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.07274 (* 1 = 5.07274 loss)
I0726 15:48:21.311502 31263 sgd_solver.cpp:138] Iteration 1920, lr = 0.001
I0726 15:48:51.010609 31263 solver.cpp:243] Iteration 1930, loss = 5.14713
I0726 15:48:51.010645 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.58149 (* 1 = 5.58149 loss)
I0726 15:48:51.010654 31263 sgd_solver.cpp:138] Iteration 1930, lr = 0.001
I0726 15:49:20.567407 31263 solver.cpp:243] Iteration 1940, loss = 4.98843
I0726 15:49:20.567528 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.19653 (* 1 = 6.19653 loss)
I0726 15:49:20.567536 31263 sgd_solver.cpp:138] Iteration 1940, lr = 0.001
I0726 15:49:49.988314 31263 solver.cpp:243] Iteration 1950, loss = 5.04213
I0726 15:49:49.988348 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.2332 (* 1 = 5.2332 loss)
I0726 15:49:49.988355 31263 sgd_solver.cpp:138] Iteration 1950, lr = 0.001
I0726 15:50:19.538614 31263 solver.cpp:243] Iteration 1960, loss = 5.13658
I0726 15:50:19.538746 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.59556 (* 1 = 4.59556 loss)
I0726 15:50:19.538759 31263 sgd_solver.cpp:138] Iteration 1960, lr = 0.001
I0726 15:50:49.135258 31263 solver.cpp:243] Iteration 1970, loss = 4.87938
I0726 15:50:49.135293 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.78315 (* 1 = 4.78315 loss)
I0726 15:50:49.135300 31263 sgd_solver.cpp:138] Iteration 1970, lr = 0.001
I0726 15:51:18.667716 31263 solver.cpp:243] Iteration 1980, loss = 5.07157
I0726 15:51:18.668046 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.50605 (* 1 = 5.50605 loss)
I0726 15:51:18.668073 31263 sgd_solver.cpp:138] Iteration 1980, lr = 0.001
I0726 15:51:48.148674 31263 solver.cpp:243] Iteration 1990, loss = 5.10842
I0726 15:51:48.148707 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.47623 (* 1 = 4.47623 loss)
I0726 15:51:48.148732 31263 sgd_solver.cpp:138] Iteration 1990, lr = 0.001
I0726 15:52:14.767312 31263 solver.cpp:433] Iteration 2000, Testing net (#0)
I0726 15:52:14.767560 31263 net.cpp:693] Ignoring source layer mbox_loss
W0726 15:52:18.293062 31263 solver.cpp:524] Missing true_pos for label: 8
W0726 15:52:18.293107 31263 solver.cpp:524] Missing true_pos for label: 12
W0726 15:52:18.293211 31263 solver.cpp:524] Missing true_pos for label: 15
W0726 15:52:18.293216 31263 solver.cpp:524] Missing true_pos for label: 16
W0726 15:52:18.293220 31263 solver.cpp:524] Missing true_pos for label: 17
W0726 15:52:18.293222 31263 solver.cpp:524] Missing true_pos for label: 18
W0726 15:52:18.293370 31263 solver.cpp:524] Missing true_pos for label: 21
W0726 15:52:18.293373 31263 solver.cpp:524] Missing true_pos for label: 22
W0726 15:52:18.293376 31263 solver.cpp:524] Missing true_pos for label: 23
W0726 15:52:18.293424 31263 solver.cpp:524] Missing true_pos for label: 30
W0726 15:52:18.293478 31263 solver.cpp:524] Missing true_pos for label: 32
W0726 15:52:18.293532 31263 solver.cpp:524] Missing true_pos for label: 34
W0726 15:52:18.294991 31263 solver.cpp:524] Missing true_pos for label: 50
W0726 15:52:18.295019 31263 solver.cpp:524] Missing true_pos for label: 53
W0726 15:52:18.295035 31263 solver.cpp:524] Missing true_pos for label: 56
W0726 15:52:18.295039 31263 solver.cpp:524] Missing true_pos for label: 57
W0726 15:52:18.295042 31263 solver.cpp:524] Missing true_pos for label: 58
I0726 15:52:18.295045 31263 solver.cpp:546]     Test net output #0: detection_eval = 0.151298
I0726 15:52:20.867566 31263 solver.cpp:243] Iteration 2000, loss = 5.14222
I0726 15:52:20.867606 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.72284 (* 1 = 4.72284 loss)
I0726 15:52:20.867614 31263 sgd_solver.cpp:138] Iteration 2000, lr = 0.001
I0726 15:52:50.580103 31263 solver.cpp:243] Iteration 2010, loss = 4.88594
I0726 15:52:50.580349 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.53375 (* 1 = 4.53375 loss)
I0726 15:52:50.580363 31263 sgd_solver.cpp:138] Iteration 2010, lr = 0.001
I0726 15:53:20.113081 31263 solver.cpp:243] Iteration 2020, loss = 5.00753
I0726 15:53:20.113113 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.35992 (* 1 = 4.35992 loss)
I0726 15:53:20.113121 31263 sgd_solver.cpp:138] Iteration 2020, lr = 0.001
I0726 15:53:49.638239 31263 solver.cpp:243] Iteration 2030, loss = 5.0549
I0726 15:53:49.638475 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.57689 (* 1 = 4.57689 loss)
I0726 15:53:49.638494 31263 sgd_solver.cpp:138] Iteration 2030, lr = 0.001
I0726 15:54:19.160575 31263 solver.cpp:243] Iteration 2040, loss = 5.06966
I0726 15:54:19.160609 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.45954 (* 1 = 4.45954 loss)
I0726 15:54:19.160616 31263 sgd_solver.cpp:138] Iteration 2040, lr = 0.001
I0726 15:54:48.588197 31263 solver.cpp:243] Iteration 2050, loss = 4.9698
I0726 15:54:48.588508 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.30857 (* 1 = 4.30857 loss)
I0726 15:54:48.588532 31263 sgd_solver.cpp:138] Iteration 2050, lr = 0.001
I0726 15:55:18.298089 31263 solver.cpp:243] Iteration 2060, loss = 5.01929
I0726 15:55:18.298135 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.55438 (* 1 = 4.55438 loss)
I0726 15:55:18.298144 31263 sgd_solver.cpp:138] Iteration 2060, lr = 0.001
I0726 15:55:47.899245 31263 solver.cpp:243] Iteration 2070, loss = 5.04087
I0726 15:55:47.899443 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.48842 (* 1 = 5.48842 loss)
I0726 15:55:47.899453 31263 sgd_solver.cpp:138] Iteration 2070, lr = 0.001
I0726 15:56:17.437947 31263 solver.cpp:243] Iteration 2080, loss = 5.02391
I0726 15:56:17.437999 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.71792 (* 1 = 5.71792 loss)
I0726 15:56:17.438005 31263 sgd_solver.cpp:138] Iteration 2080, lr = 0.001
I0726 15:56:47.099045 31263 solver.cpp:243] Iteration 2090, loss = 4.76895
I0726 15:56:47.099210 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.97346 (* 1 = 4.97346 loss)
I0726 15:56:47.099218 31263 sgd_solver.cpp:138] Iteration 2090, lr = 0.001
I0726 15:57:16.616915 31263 solver.cpp:243] Iteration 2100, loss = 5.15536
I0726 15:57:16.616950 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.2886 (* 1 = 5.2886 loss)
I0726 15:57:16.616956 31263 sgd_solver.cpp:138] Iteration 2100, lr = 0.001
I0726 15:57:46.129547 31263 solver.cpp:243] Iteration 2110, loss = 4.98586
I0726 15:57:46.129750 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.11169 (* 1 = 5.11169 loss)
I0726 15:57:46.129768 31263 sgd_solver.cpp:138] Iteration 2110, lr = 0.001
I0726 15:58:15.465914 31263 solver.cpp:243] Iteration 2120, loss = 4.87229
I0726 15:58:15.465941 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.64243 (* 1 = 5.64243 loss)
I0726 15:58:15.465947 31263 sgd_solver.cpp:138] Iteration 2120, lr = 0.001
I0726 15:58:44.817945 31263 solver.cpp:243] Iteration 2130, loss = 5.08327
I0726 15:58:44.818184 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.2477 (* 1 = 4.2477 loss)
I0726 15:58:44.818212 31263 sgd_solver.cpp:138] Iteration 2130, lr = 0.001
I0726 15:59:14.242136 31263 solver.cpp:243] Iteration 2140, loss = 4.9875
I0726 15:59:14.242233 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.1026 (* 1 = 5.1026 loss)
I0726 15:59:14.242245 31263 sgd_solver.cpp:138] Iteration 2140, lr = 0.001
I0726 15:59:43.618506 31263 solver.cpp:243] Iteration 2150, loss = 5.11562
I0726 15:59:43.618669 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.88461 (* 1 = 4.88461 loss)
I0726 15:59:43.618680 31263 sgd_solver.cpp:138] Iteration 2150, lr = 0.001
I0726 16:00:13.021252 31263 solver.cpp:243] Iteration 2160, loss = 4.8919
I0726 16:00:13.021289 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.11621 (* 1 = 4.11621 loss)
I0726 16:00:13.021296 31263 sgd_solver.cpp:138] Iteration 2160, lr = 0.001
I0726 16:00:42.535430 31263 solver.cpp:243] Iteration 2170, loss = 4.96946
I0726 16:00:42.535560 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.80961 (* 1 = 4.80961 loss)
I0726 16:00:42.535574 31263 sgd_solver.cpp:138] Iteration 2170, lr = 0.001
I0726 16:01:12.152865 31263 solver.cpp:243] Iteration 2180, loss = 5.08485
I0726 16:01:12.153007 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.94384 (* 1 = 4.94384 loss)
I0726 16:01:12.153041 31263 sgd_solver.cpp:138] Iteration 2180, lr = 0.001
I0726 16:01:41.628600 31263 solver.cpp:243] Iteration 2190, loss = 4.87598
I0726 16:01:41.628772 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.79012 (* 1 = 5.79012 loss)
I0726 16:01:41.628780 31263 sgd_solver.cpp:138] Iteration 2190, lr = 0.001
I0726 16:02:11.195178 31263 solver.cpp:243] Iteration 2200, loss = 4.90673
I0726 16:02:11.195226 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.98225 (* 1 = 5.98225 loss)
I0726 16:02:11.195233 31263 sgd_solver.cpp:138] Iteration 2200, lr = 0.001
I0726 16:02:40.707355 31263 solver.cpp:243] Iteration 2210, loss = 4.94839
I0726 16:02:40.707592 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.93081 (* 1 = 4.93081 loss)
I0726 16:02:40.707608 31263 sgd_solver.cpp:138] Iteration 2210, lr = 0.001
I0726 16:03:10.523191 31263 solver.cpp:243] Iteration 2220, loss = 4.91691
I0726 16:03:10.523313 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.37258 (* 1 = 4.37258 loss)
I0726 16:03:10.523330 31263 sgd_solver.cpp:138] Iteration 2220, lr = 0.001
I0726 16:03:40.024475 31263 solver.cpp:243] Iteration 2230, loss = 5.02151
I0726 16:03:40.024646 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.81742 (* 1 = 3.81742 loss)
I0726 16:03:40.024657 31263 sgd_solver.cpp:138] Iteration 2230, lr = 0.001
I0726 16:04:09.592022 31263 solver.cpp:243] Iteration 2240, loss = 5.02811
I0726 16:04:09.592051 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.44644 (* 1 = 4.44644 loss)
I0726 16:04:09.592057 31263 sgd_solver.cpp:138] Iteration 2240, lr = 0.001
I0726 16:04:39.016203 31263 solver.cpp:243] Iteration 2250, loss = 4.88484
I0726 16:04:39.016366 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.27619 (* 1 = 4.27619 loss)
I0726 16:04:39.016378 31263 sgd_solver.cpp:138] Iteration 2250, lr = 0.001
I0726 16:05:08.424736 31263 solver.cpp:243] Iteration 2260, loss = 4.83982
I0726 16:05:08.424765 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.86746 (* 1 = 4.86746 loss)
I0726 16:05:08.424773 31263 sgd_solver.cpp:138] Iteration 2260, lr = 0.001
I0726 16:05:37.929013 31263 solver.cpp:243] Iteration 2270, loss = 4.90705
I0726 16:05:37.929265 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.85704 (* 1 = 4.85704 loss)
I0726 16:05:37.929280 31263 sgd_solver.cpp:138] Iteration 2270, lr = 0.001
I0726 16:06:07.363912 31263 solver.cpp:243] Iteration 2280, loss = 4.98576
I0726 16:06:07.363950 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.45452 (* 1 = 5.45452 loss)
I0726 16:06:07.363956 31263 sgd_solver.cpp:138] Iteration 2280, lr = 0.001
I0726 16:06:37.074579 31263 solver.cpp:243] Iteration 2290, loss = 4.94797
I0726 16:06:37.074743 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.24907 (* 1 = 5.24907 loss)
I0726 16:06:37.074759 31263 sgd_solver.cpp:138] Iteration 2290, lr = 0.001
I0726 16:07:06.445374 31263 solver.cpp:243] Iteration 2300, loss = 5.01866
I0726 16:07:06.445423 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.30217 (* 1 = 4.30217 loss)
I0726 16:07:06.445430 31263 sgd_solver.cpp:138] Iteration 2300, lr = 0.001
I0726 16:07:35.872422 31263 solver.cpp:243] Iteration 2310, loss = 4.85813
I0726 16:07:35.872634 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.04556 (* 1 = 5.04556 loss)
I0726 16:07:35.872643 31263 sgd_solver.cpp:138] Iteration 2310, lr = 0.001
I0726 16:08:05.470962 31263 solver.cpp:243] Iteration 2320, loss = 4.98927
I0726 16:08:05.471000 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.69274 (* 1 = 5.69274 loss)
I0726 16:08:05.471009 31263 sgd_solver.cpp:138] Iteration 2320, lr = 0.001
I0726 16:08:34.941033 31263 solver.cpp:243] Iteration 2330, loss = 4.91178
I0726 16:08:34.941154 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.02865 (* 1 = 5.02865 loss)
I0726 16:08:34.941165 31263 sgd_solver.cpp:138] Iteration 2330, lr = 0.001
I0726 16:09:04.337826 31263 solver.cpp:243] Iteration 2340, loss = 4.97671
I0726 16:09:04.337863 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.15882 (* 1 = 6.15882 loss)
I0726 16:09:04.337870 31263 sgd_solver.cpp:138] Iteration 2340, lr = 0.001
I0726 16:09:33.864184 31263 solver.cpp:243] Iteration 2350, loss = 4.93945
I0726 16:09:33.864295 31263 solver.cpp:259]     Train net output #0: mbox_loss = 7.06622 (* 1 = 7.06622 loss)
I0726 16:09:33.864305 31263 sgd_solver.cpp:138] Iteration 2350, lr = 0.001
I0726 16:10:03.134197 31263 solver.cpp:243] Iteration 2360, loss = 4.77688
I0726 16:10:03.134266 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.09693 (* 1 = 4.09693 loss)
I0726 16:10:03.134276 31263 sgd_solver.cpp:138] Iteration 2360, lr = 0.001
I0726 16:10:37.387846 31263 solver.cpp:243] Iteration 2370, loss = 4.8629
I0726 16:10:37.388077 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.28304 (* 1 = 4.28304 loss)
I0726 16:10:37.388101 31263 sgd_solver.cpp:138] Iteration 2370, lr = 0.001
I0726 16:11:24.126121 31263 solver.cpp:243] Iteration 2380, loss = 4.9402
I0726 16:11:24.126250 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.53641 (* 1 = 4.53641 loss)
I0726 16:11:24.126256 31263 sgd_solver.cpp:138] Iteration 2380, lr = 0.001
I0726 16:12:11.167253 31263 solver.cpp:243] Iteration 2390, loss = 4.89158
I0726 16:12:11.167376 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.14807 (* 1 = 4.14807 loss)
I0726 16:12:11.167382 31263 sgd_solver.cpp:138] Iteration 2390, lr = 0.001
I0726 16:12:58.667395 31263 solver.cpp:243] Iteration 2400, loss = 4.95157
I0726 16:12:58.667539 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.74729 (* 1 = 4.74729 loss)
I0726 16:12:58.667547 31263 sgd_solver.cpp:138] Iteration 2400, lr = 0.001
I0726 16:13:43.052889 31263 solver.cpp:243] Iteration 2410, loss = 4.82708
I0726 16:13:43.052985 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.52937 (* 1 = 4.52937 loss)
I0726 16:13:43.052997 31263 sgd_solver.cpp:138] Iteration 2410, lr = 0.001
I0726 16:14:12.476402 31263 solver.cpp:243] Iteration 2420, loss = 4.78105
I0726 16:14:12.476464 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.20356 (* 1 = 5.20356 loss)
I0726 16:14:12.476474 31263 sgd_solver.cpp:138] Iteration 2420, lr = 0.001
I0726 16:14:41.874325 31263 solver.cpp:243] Iteration 2430, loss = 4.89824
I0726 16:14:41.874430 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.44793 (* 1 = 5.44793 loss)
I0726 16:14:41.874441 31263 sgd_solver.cpp:138] Iteration 2430, lr = 0.001
I0726 16:15:11.243924 31263 solver.cpp:243] Iteration 2440, loss = 4.8794
I0726 16:15:11.243963 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.01918 (* 1 = 5.01918 loss)
I0726 16:15:11.243969 31263 sgd_solver.cpp:138] Iteration 2440, lr = 0.001
I0726 16:15:40.582551 31263 solver.cpp:243] Iteration 2450, loss = 4.99539
I0726 16:15:40.582734 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.3243 (* 1 = 5.3243 loss)
I0726 16:15:40.582743 31263 sgd_solver.cpp:138] Iteration 2450, lr = 0.001
I0726 16:16:10.039772 31263 solver.cpp:243] Iteration 2460, loss = 4.85918
I0726 16:16:10.039803 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.44284 (* 1 = 4.44284 loss)
I0726 16:16:10.039811 31263 sgd_solver.cpp:138] Iteration 2460, lr = 0.001
I0726 16:16:39.454577 31263 solver.cpp:243] Iteration 2470, loss = 4.807
I0726 16:16:39.457630 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.83695 (* 1 = 4.83695 loss)
I0726 16:16:39.457640 31263 sgd_solver.cpp:138] Iteration 2470, lr = 0.001
I0726 16:17:08.745484 31263 solver.cpp:243] Iteration 2480, loss = 5.04766
I0726 16:17:08.745517 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.31959 (* 1 = 4.31959 loss)
I0726 16:17:08.745525 31263 sgd_solver.cpp:138] Iteration 2480, lr = 0.001
I0726 16:17:38.209971 31263 solver.cpp:243] Iteration 2490, loss = 4.85442
I0726 16:17:38.210242 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.97834 (* 1 = 4.97834 loss)
I0726 16:17:38.210263 31263 sgd_solver.cpp:138] Iteration 2490, lr = 0.001
I0726 16:18:07.673444 31263 solver.cpp:243] Iteration 2500, loss = 4.83233
I0726 16:18:07.673482 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.90742 (* 1 = 4.90742 loss)
I0726 16:18:07.673491 31263 sgd_solver.cpp:138] Iteration 2500, lr = 0.001
I0726 16:18:37.020560 31263 solver.cpp:243] Iteration 2510, loss = 4.8611
I0726 16:18:37.020686 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.89686 (* 1 = 3.89686 loss)
I0726 16:18:37.020699 31263 sgd_solver.cpp:138] Iteration 2510, lr = 0.001
I0726 16:19:06.463302 31263 solver.cpp:243] Iteration 2520, loss = 4.99466
I0726 16:19:06.463356 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.00349 (* 1 = 5.00349 loss)
I0726 16:19:06.463366 31263 sgd_solver.cpp:138] Iteration 2520, lr = 0.001
I0726 16:19:35.769268 31263 solver.cpp:243] Iteration 2530, loss = 4.88492
I0726 16:19:35.769472 31263 solver.cpp:259]     Train net output #0: mbox_loss = 6.15082 (* 1 = 6.15082 loss)
I0726 16:19:35.769489 31263 sgd_solver.cpp:138] Iteration 2530, lr = 0.001
I0726 16:20:05.174327 31263 solver.cpp:243] Iteration 2540, loss = 4.75295
I0726 16:20:05.174361 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.38548 (* 1 = 5.38548 loss)
I0726 16:20:05.174371 31263 sgd_solver.cpp:138] Iteration 2540, lr = 0.001
I0726 16:20:34.571322 31263 solver.cpp:243] Iteration 2550, loss = 4.95157
I0726 16:20:34.571532 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.59299 (* 1 = 4.59299 loss)
I0726 16:20:34.571542 31263 sgd_solver.cpp:138] Iteration 2550, lr = 0.001
I0726 16:21:03.906500 31263 solver.cpp:243] Iteration 2560, loss = 4.89658
I0726 16:21:03.906563 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.22591 (* 1 = 5.22591 loss)
I0726 16:21:03.906572 31263 sgd_solver.cpp:138] Iteration 2560, lr = 0.001
I0726 16:21:33.231894 31263 solver.cpp:243] Iteration 2570, loss = 4.86563
I0726 16:21:33.231993 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.95236 (* 1 = 3.95236 loss)
I0726 16:21:33.232004 31263 sgd_solver.cpp:138] Iteration 2570, lr = 0.001
I0726 16:22:02.695675 31263 solver.cpp:243] Iteration 2580, loss = 4.78869
I0726 16:22:02.695706 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.47009 (* 1 = 4.47009 loss)
I0726 16:22:02.695714 31263 sgd_solver.cpp:138] Iteration 2580, lr = 0.001
I0726 16:22:32.037873 31263 solver.cpp:243] Iteration 2590, loss = 4.75798
I0726 16:22:32.038075 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.04445 (* 1 = 5.04445 loss)
I0726 16:22:32.038084 31263 sgd_solver.cpp:138] Iteration 2590, lr = 0.001
I0726 16:23:01.455742 31263 solver.cpp:243] Iteration 2600, loss = 4.73833
I0726 16:23:01.455801 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.59051 (* 1 = 5.59051 loss)
I0726 16:23:01.455811 31263 sgd_solver.cpp:138] Iteration 2600, lr = 0.001
I0726 16:23:30.712934 31263 solver.cpp:243] Iteration 2610, loss = 4.83559
I0726 16:23:30.713126 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.4369 (* 1 = 5.4369 loss)
I0726 16:23:30.713135 31263 sgd_solver.cpp:138] Iteration 2610, lr = 0.001
I0726 16:24:00.093127 31263 solver.cpp:243] Iteration 2620, loss = 4.82087
I0726 16:24:00.093216 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.8219 (* 1 = 4.8219 loss)
I0726 16:24:00.093252 31263 sgd_solver.cpp:138] Iteration 2620, lr = 0.001
I0726 16:24:29.540251 31263 solver.cpp:243] Iteration 2630, loss = 4.8341
I0726 16:24:29.540382 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.23713 (* 1 = 4.23713 loss)
I0726 16:24:29.540391 31263 sgd_solver.cpp:138] Iteration 2630, lr = 0.001
I0726 16:24:58.808732 31263 solver.cpp:243] Iteration 2640, loss = 4.74142
I0726 16:24:58.808764 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.71966 (* 1 = 4.71966 loss)
I0726 16:24:58.808773 31263 sgd_solver.cpp:138] Iteration 2640, lr = 0.001
I0726 16:25:28.063822 31263 solver.cpp:243] Iteration 2650, loss = 4.84985
I0726 16:25:28.064177 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.38656 (* 1 = 4.38656 loss)
I0726 16:25:28.064201 31263 sgd_solver.cpp:138] Iteration 2650, lr = 0.001
I0726 16:25:57.493959 31263 solver.cpp:243] Iteration 2660, loss = 4.85213
I0726 16:25:57.493993 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.33333 (* 1 = 5.33333 loss)
I0726 16:25:57.493999 31263 sgd_solver.cpp:138] Iteration 2660, lr = 0.001
I0726 16:26:26.873551 31263 solver.cpp:243] Iteration 2670, loss = 4.67419
I0726 16:26:26.873692 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.08245 (* 1 = 5.08245 loss)
I0726 16:26:26.873706 31263 sgd_solver.cpp:138] Iteration 2670, lr = 0.001
I0726 16:26:56.326695 31263 solver.cpp:243] Iteration 2680, loss = 4.86555
I0726 16:26:56.326725 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.56271 (* 1 = 4.56271 loss)
I0726 16:26:56.326731 31263 sgd_solver.cpp:138] Iteration 2680, lr = 0.001
I0726 16:27:25.822896 31263 solver.cpp:243] Iteration 2690, loss = 4.65298
I0726 16:27:25.823024 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.67081 (* 1 = 4.67081 loss)
I0726 16:27:25.823032 31263 sgd_solver.cpp:138] Iteration 2690, lr = 0.001
I0726 16:27:55.127764 31263 solver.cpp:243] Iteration 2700, loss = 4.66919
I0726 16:27:55.127797 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.28723 (* 1 = 4.28723 loss)
I0726 16:27:55.127805 31263 sgd_solver.cpp:138] Iteration 2700, lr = 0.001
I0726 16:28:24.440207 31263 solver.cpp:243] Iteration 2710, loss = 4.77159
I0726 16:28:24.440330 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.15165 (* 1 = 5.15165 loss)
I0726 16:28:24.440343 31263 sgd_solver.cpp:138] Iteration 2710, lr = 0.001
I0726 16:28:53.864656 31263 solver.cpp:243] Iteration 2720, loss = 4.73801
I0726 16:28:53.864707 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.50375 (* 1 = 4.50375 loss)
I0726 16:28:53.864712 31263 sgd_solver.cpp:138] Iteration 2720, lr = 0.001
I0726 16:29:23.203485 31263 solver.cpp:243] Iteration 2730, loss = 4.67364
I0726 16:29:23.203608 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.93646 (* 1 = 4.93646 loss)
I0726 16:29:23.203621 31263 sgd_solver.cpp:138] Iteration 2730, lr = 0.001
I0726 16:29:52.537441 31263 solver.cpp:243] Iteration 2740, loss = 4.76754
I0726 16:29:52.537473 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36273 (* 1 = 4.36273 loss)
I0726 16:29:52.537479 31263 sgd_solver.cpp:138] Iteration 2740, lr = 0.001
I0726 16:30:21.925781 31263 solver.cpp:243] Iteration 2750, loss = 4.87322
I0726 16:30:21.925879 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.69709 (* 1 = 4.69709 loss)
I0726 16:30:21.925889 31263 sgd_solver.cpp:138] Iteration 2750, lr = 0.001
I0726 16:30:51.341301 31263 solver.cpp:243] Iteration 2760, loss = 4.65098
I0726 16:30:51.341341 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.41541 (* 1 = 5.41541 loss)
I0726 16:30:51.341346 31263 sgd_solver.cpp:138] Iteration 2760, lr = 0.001
I0726 16:31:20.696118 31263 solver.cpp:243] Iteration 2770, loss = 4.84627
I0726 16:31:20.696233 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.66334 (* 1 = 4.66334 loss)
I0726 16:31:20.696243 31263 sgd_solver.cpp:138] Iteration 2770, lr = 0.001
I0726 16:31:50.025301 31263 solver.cpp:243] Iteration 2780, loss = 4.75451
I0726 16:31:50.025352 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.51507 (* 1 = 4.51507 loss)
I0726 16:31:50.025358 31263 sgd_solver.cpp:138] Iteration 2780, lr = 0.001
I0726 16:32:19.385695 31263 solver.cpp:243] Iteration 2790, loss = 4.81952
I0726 16:32:19.387286 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.92445 (* 1 = 3.92445 loss)
I0726 16:32:19.387295 31263 sgd_solver.cpp:138] Iteration 2790, lr = 0.001
I0726 16:32:48.789252 31263 solver.cpp:243] Iteration 2800, loss = 4.68759
I0726 16:32:48.789335 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36452 (* 1 = 4.36452 loss)
I0726 16:32:48.789348 31263 sgd_solver.cpp:138] Iteration 2800, lr = 0.001
I0726 16:33:18.198086 31263 solver.cpp:243] Iteration 2810, loss = 4.66019
I0726 16:33:18.198246 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.6223 (* 1 = 5.6223 loss)
I0726 16:33:18.198258 31263 sgd_solver.cpp:138] Iteration 2810, lr = 0.001
I0726 16:33:47.458528 31263 solver.cpp:243] Iteration 2820, loss = 4.61892
I0726 16:33:47.458561 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.21864 (* 1 = 4.21864 loss)
I0726 16:33:47.458569 31263 sgd_solver.cpp:138] Iteration 2820, lr = 0.001
I0726 16:34:16.715744 31263 solver.cpp:243] Iteration 2830, loss = 4.88761
I0726 16:34:16.715893 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.02372 (* 1 = 4.02372 loss)
I0726 16:34:16.715908 31263 sgd_solver.cpp:138] Iteration 2830, lr = 0.001
I0726 16:34:45.944597 31263 solver.cpp:243] Iteration 2840, loss = 4.72924
I0726 16:34:45.944658 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.04986 (* 1 = 5.04986 loss)
I0726 16:34:45.944666 31263 sgd_solver.cpp:138] Iteration 2840, lr = 0.001
I0726 16:35:15.230617 31263 solver.cpp:243] Iteration 2850, loss = 4.78138
I0726 16:35:15.230782 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.70236 (* 1 = 4.70236 loss)
I0726 16:35:15.230795 31263 sgd_solver.cpp:138] Iteration 2850, lr = 0.001
I0726 16:35:44.633710 31263 solver.cpp:243] Iteration 2860, loss = 4.68962
I0726 16:35:44.633751 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.18529 (* 1 = 5.18529 loss)
I0726 16:35:44.633775 31263 sgd_solver.cpp:138] Iteration 2860, lr = 0.001
I0726 16:36:13.813472 31263 solver.cpp:243] Iteration 2870, loss = 4.69541
I0726 16:36:13.813660 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.18857 (* 1 = 5.18857 loss)
I0726 16:36:13.813673 31263 sgd_solver.cpp:138] Iteration 2870, lr = 0.001
I0726 16:36:43.171825 31263 solver.cpp:243] Iteration 2880, loss = 4.63997
I0726 16:36:43.171861 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.18103 (* 1 = 4.18103 loss)
I0726 16:36:43.171886 31263 sgd_solver.cpp:138] Iteration 2880, lr = 0.001
I0726 16:37:12.605754 31263 solver.cpp:243] Iteration 2890, loss = 4.64451
I0726 16:37:12.605911 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.95504 (* 1 = 4.95504 loss)
I0726 16:37:12.605921 31263 sgd_solver.cpp:138] Iteration 2890, lr = 0.001
I0726 16:37:41.894487 31263 solver.cpp:243] Iteration 2900, loss = 4.58097
I0726 16:37:41.894526 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.35044 (* 1 = 4.35044 loss)
I0726 16:37:41.894536 31263 sgd_solver.cpp:138] Iteration 2900, lr = 0.001
I0726 16:38:11.324904 31263 solver.cpp:243] Iteration 2910, loss = 4.61882
I0726 16:38:11.325003 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.52066 (* 1 = 4.52066 loss)
I0726 16:38:11.325009 31263 sgd_solver.cpp:138] Iteration 2910, lr = 0.001
I0726 16:38:40.765826 31263 solver.cpp:243] Iteration 2920, loss = 4.65714
I0726 16:38:40.765885 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.89711 (* 1 = 3.89711 loss)
I0726 16:38:40.765892 31263 sgd_solver.cpp:138] Iteration 2920, lr = 0.001
I0726 16:39:10.144682 31263 solver.cpp:243] Iteration 2930, loss = 4.63861
I0726 16:39:10.144793 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.57749 (* 1 = 4.57749 loss)
I0726 16:39:10.144799 31263 sgd_solver.cpp:138] Iteration 2930, lr = 0.001
I0726 16:39:39.574080 31263 solver.cpp:243] Iteration 2940, loss = 4.69107
I0726 16:39:39.574110 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.33951 (* 1 = 4.33951 loss)
I0726 16:39:39.574115 31263 sgd_solver.cpp:138] Iteration 2940, lr = 0.001
I0726 16:40:08.920518 31263 solver.cpp:243] Iteration 2950, loss = 4.55529
I0726 16:40:08.920593 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.76571 (* 1 = 4.76571 loss)
I0726 16:40:08.920600 31263 sgd_solver.cpp:138] Iteration 2950, lr = 0.001
I0726 16:40:38.223352 31263 solver.cpp:243] Iteration 2960, loss = 4.74956
I0726 16:40:38.223424 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.4277 (* 1 = 5.4277 loss)
I0726 16:40:38.223439 31263 sgd_solver.cpp:138] Iteration 2960, lr = 0.001
I0726 16:41:07.570334 31263 solver.cpp:243] Iteration 2970, loss = 4.69237
I0726 16:41:07.570487 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.60398 (* 1 = 4.60398 loss)
I0726 16:41:07.570515 31263 sgd_solver.cpp:138] Iteration 2970, lr = 0.001
I0726 16:41:36.896080 31263 solver.cpp:243] Iteration 2980, loss = 4.49273
I0726 16:41:36.896121 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.15544 (* 1 = 4.15544 loss)
I0726 16:41:36.896127 31263 sgd_solver.cpp:138] Iteration 2980, lr = 0.001
I0726 16:42:06.168172 31263 solver.cpp:243] Iteration 2990, loss = 4.8013
I0726 16:42:06.168341 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36344 (* 1 = 4.36344 loss)
I0726 16:42:06.168352 31263 sgd_solver.cpp:138] Iteration 2990, lr = 0.001
I0726 16:42:32.557410 31263 solver.cpp:433] Iteration 3000, Testing net (#0)
I0726 16:42:32.560264 31263 net.cpp:693] Ignoring source layer mbox_loss
W0726 16:42:36.268110 31263 solver.cpp:524] Missing true_pos for label: 8
W0726 16:42:36.268390 31263 solver.cpp:524] Missing true_pos for label: 11
W0726 16:42:36.268404 31263 solver.cpp:524] Missing true_pos for label: 12
W0726 16:42:36.268493 31263 solver.cpp:524] Missing true_pos for label: 15
W0726 16:42:36.268499 31263 solver.cpp:524] Missing true_pos for label: 16
W0726 16:42:36.268506 31263 solver.cpp:524] Missing true_pos for label: 17
W0726 16:42:36.268682 31263 solver.cpp:524] Missing true_pos for label: 21
W0726 16:42:36.268687 31263 solver.cpp:524] Missing true_pos for label: 22
W0726 16:42:36.268710 31263 solver.cpp:524] Missing true_pos for label: 23
W0726 16:42:36.268788 31263 solver.cpp:524] Missing true_pos for label: 30
W0726 16:42:36.268903 31263 solver.cpp:524] Missing true_pos for label: 34
W0726 16:42:36.270257 31263 solver.cpp:524] Missing true_pos for label: 50
W0726 16:42:36.270290 31263 solver.cpp:524] Missing true_pos for label: 53
W0726 16:42:36.270320 31263 solver.cpp:524] Missing true_pos for label: 57
W0726 16:42:36.270325 31263 solver.cpp:524] Missing true_pos for label: 58
I0726 16:42:36.270329 31263 solver.cpp:546]     Test net output #0: detection_eval = 0.180785
I0726 16:42:38.716542 31263 solver.cpp:243] Iteration 3000, loss = 4.69429
I0726 16:42:38.716578 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.12121 (* 1 = 4.12121 loss)
I0726 16:42:38.716591 31263 sgd_solver.cpp:138] Iteration 3000, lr = 0.001
I0726 16:43:08.083133 31263 solver.cpp:243] Iteration 3010, loss = 4.67844
I0726 16:43:08.083267 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.19713 (* 1 = 5.19713 loss)
I0726 16:43:08.083279 31263 sgd_solver.cpp:138] Iteration 3010, lr = 0.001
I0726 16:43:37.441965 31263 solver.cpp:243] Iteration 3020, loss = 4.63074
I0726 16:43:37.442049 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.72911 (* 1 = 3.72911 loss)
I0726 16:43:37.442059 31263 sgd_solver.cpp:138] Iteration 3020, lr = 0.001
I0726 16:44:06.982198 31263 solver.cpp:243] Iteration 3030, loss = 4.67221
I0726 16:44:06.982411 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.84575 (* 1 = 4.84575 loss)
I0726 16:44:06.982419 31263 sgd_solver.cpp:138] Iteration 3030, lr = 0.001
I0726 16:44:36.395184 31263 solver.cpp:243] Iteration 3040, loss = 4.62103
I0726 16:44:36.395212 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.15074 (* 1 = 4.15074 loss)
I0726 16:44:36.395218 31263 sgd_solver.cpp:138] Iteration 3040, lr = 0.001
I0726 16:45:05.740644 31263 solver.cpp:243] Iteration 3050, loss = 4.62413
I0726 16:45:05.741204 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.61362 (* 1 = 4.61362 loss)
I0726 16:45:05.741243 31263 sgd_solver.cpp:138] Iteration 3050, lr = 0.001
I0726 16:45:35.060897 31263 solver.cpp:243] Iteration 3060, loss = 4.7957
I0726 16:45:35.060981 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.96241 (* 1 = 4.96241 loss)
I0726 16:45:35.060995 31263 sgd_solver.cpp:138] Iteration 3060, lr = 0.001
I0726 16:46:04.474573 31263 solver.cpp:243] Iteration 3070, loss = 4.62576
I0726 16:46:04.474680 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.53396 (* 1 = 5.53396 loss)
I0726 16:46:04.474689 31263 sgd_solver.cpp:138] Iteration 3070, lr = 0.001
I0726 16:46:33.934502 31263 solver.cpp:243] Iteration 3080, loss = 4.58599
I0726 16:46:33.934540 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.22469 (* 1 = 4.22469 loss)
I0726 16:46:33.934547 31263 sgd_solver.cpp:138] Iteration 3080, lr = 0.001
I0726 16:47:03.186043 31263 solver.cpp:243] Iteration 3090, loss = 4.68403
I0726 16:47:03.186164 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.09263 (* 1 = 4.09263 loss)
I0726 16:47:03.186174 31263 sgd_solver.cpp:138] Iteration 3090, lr = 0.001
I0726 16:47:32.644393 31263 solver.cpp:243] Iteration 3100, loss = 4.73463
I0726 16:47:32.644438 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.05235 (* 1 = 4.05235 loss)
I0726 16:47:32.644445 31263 sgd_solver.cpp:138] Iteration 3100, lr = 0.001
I0726 16:48:01.928259 31263 solver.cpp:243] Iteration 3110, loss = 4.72293
I0726 16:48:01.928421 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.69175 (* 1 = 4.69175 loss)
I0726 16:48:01.928432 31263 sgd_solver.cpp:138] Iteration 3110, lr = 0.001
I0726 16:48:31.342625 31263 solver.cpp:243] Iteration 3120, loss = 4.61454
I0726 16:48:31.342664 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.9429 (* 1 = 4.9429 loss)
I0726 16:48:31.342670 31263 sgd_solver.cpp:138] Iteration 3120, lr = 0.001
I0726 16:49:00.680872 31263 solver.cpp:243] Iteration 3130, loss = 4.67405
I0726 16:49:00.681005 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.9554 (* 1 = 4.9554 loss)
I0726 16:49:00.681015 31263 sgd_solver.cpp:138] Iteration 3130, lr = 0.001
I0726 16:49:30.130020 31263 solver.cpp:243] Iteration 3140, loss = 4.671
I0726 16:49:30.130091 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.69519 (* 1 = 4.69519 loss)
I0726 16:49:30.130105 31263 sgd_solver.cpp:138] Iteration 3140, lr = 0.001
I0726 16:49:59.542542 31263 solver.cpp:243] Iteration 3150, loss = 4.55048
I0726 16:49:59.542641 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.86654 (* 1 = 4.86654 loss)
I0726 16:49:59.542652 31263 sgd_solver.cpp:138] Iteration 3150, lr = 0.001
I0726 16:50:28.895824 31263 solver.cpp:243] Iteration 3160, loss = 4.63689
I0726 16:50:28.895856 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.00024 (* 1 = 4.00024 loss)
I0726 16:50:28.895864 31263 sgd_solver.cpp:138] Iteration 3160, lr = 0.001
I0726 16:50:58.325150 31263 solver.cpp:243] Iteration 3170, loss = 4.72313
I0726 16:50:58.327535 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.51848 (* 1 = 4.51848 loss)
I0726 16:50:58.327546 31263 sgd_solver.cpp:138] Iteration 3170, lr = 0.001
I0726 16:51:27.688302 31263 solver.cpp:243] Iteration 3180, loss = 4.55724
I0726 16:51:27.688382 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.21357 (* 1 = 4.21357 loss)
I0726 16:51:27.688396 31263 sgd_solver.cpp:138] Iteration 3180, lr = 0.001
I0726 16:51:57.124342 31263 solver.cpp:243] Iteration 3190, loss = 4.58993
I0726 16:51:57.124444 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.38164 (* 1 = 5.38164 loss)
I0726 16:51:57.124454 31263 sgd_solver.cpp:138] Iteration 3190, lr = 0.001
I0726 16:52:26.474684 31263 solver.cpp:243] Iteration 3200, loss = 4.67926
I0726 16:52:26.474737 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.09097 (* 1 = 4.09097 loss)
I0726 16:52:26.474746 31263 sgd_solver.cpp:138] Iteration 3200, lr = 0.001
I0726 16:52:56.010882 31263 solver.cpp:243] Iteration 3210, loss = 4.63503
I0726 16:52:56.011157 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.73442 (* 1 = 4.73442 loss)
I0726 16:52:56.011191 31263 sgd_solver.cpp:138] Iteration 3210, lr = 0.001
I0726 16:53:25.567009 31263 solver.cpp:243] Iteration 3220, loss = 4.55322
I0726 16:53:25.567049 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.60772 (* 1 = 4.60772 loss)
I0726 16:53:25.567057 31263 sgd_solver.cpp:138] Iteration 3220, lr = 0.001
I0726 16:53:54.920150 31263 solver.cpp:243] Iteration 3230, loss = 4.73848
I0726 16:53:54.920323 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.18999 (* 1 = 4.18999 loss)
I0726 16:53:54.920331 31263 sgd_solver.cpp:138] Iteration 3230, lr = 0.001
I0726 16:54:24.386667 31263 solver.cpp:243] Iteration 3240, loss = 4.56776
I0726 16:54:24.386698 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.34824 (* 1 = 4.34824 loss)
I0726 16:54:24.386703 31263 sgd_solver.cpp:138] Iteration 3240, lr = 0.001
I0726 16:54:53.841015 31263 solver.cpp:243] Iteration 3250, loss = 4.54858
I0726 16:54:53.841122 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.30055 (* 1 = 4.30055 loss)
I0726 16:54:53.841131 31263 sgd_solver.cpp:138] Iteration 3250, lr = 0.001
I0726 16:55:23.075611 31263 solver.cpp:243] Iteration 3260, loss = 4.61908
I0726 16:55:23.075645 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.29597 (* 1 = 4.29597 loss)
I0726 16:55:23.075651 31263 sgd_solver.cpp:138] Iteration 3260, lr = 0.001
I0726 16:55:52.547878 31263 solver.cpp:243] Iteration 3270, loss = 4.49875
I0726 16:55:52.548034 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.64234 (* 1 = 4.64234 loss)
I0726 16:55:52.548046 31263 sgd_solver.cpp:138] Iteration 3270, lr = 0.001
I0726 16:56:21.838618 31263 solver.cpp:243] Iteration 3280, loss = 4.54017
I0726 16:56:21.838687 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.78989 (* 1 = 4.78989 loss)
I0726 16:56:21.838693 31263 sgd_solver.cpp:138] Iteration 3280, lr = 0.001
I0726 16:56:51.221376 31263 solver.cpp:243] Iteration 3290, loss = 4.49538
I0726 16:56:51.221530 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.65621 (* 1 = 4.65621 loss)
I0726 16:56:51.221539 31263 sgd_solver.cpp:138] Iteration 3290, lr = 0.001
I0726 16:57:20.634109 31263 solver.cpp:243] Iteration 3300, loss = 4.61758
I0726 16:57:20.634148 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.97279 (* 1 = 3.97279 loss)
I0726 16:57:20.634156 31263 sgd_solver.cpp:138] Iteration 3300, lr = 0.001
I0726 16:57:50.070611 31263 solver.cpp:243] Iteration 3310, loss = 4.66262
I0726 16:57:50.070751 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.27618 (* 1 = 5.27618 loss)
I0726 16:57:50.070771 31263 sgd_solver.cpp:138] Iteration 3310, lr = 0.001
I0726 16:58:19.437865 31263 solver.cpp:243] Iteration 3320, loss = 4.58826
I0726 16:58:19.437898 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.1836 (* 1 = 4.1836 loss)
I0726 16:58:19.437906 31263 sgd_solver.cpp:138] Iteration 3320, lr = 0.001
I0726 16:58:48.736667 31263 solver.cpp:243] Iteration 3330, loss = 4.48275
I0726 16:58:48.736881 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.15962 (* 1 = 4.15962 loss)
I0726 16:58:48.736898 31263 sgd_solver.cpp:138] Iteration 3330, lr = 0.001
I0726 16:59:18.189782 31263 solver.cpp:243] Iteration 3340, loss = 4.49953
I0726 16:59:18.189822 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.58131 (* 1 = 4.58131 loss)
I0726 16:59:18.189831 31263 sgd_solver.cpp:138] Iteration 3340, lr = 0.001
I0726 16:59:47.625802 31263 solver.cpp:243] Iteration 3350, loss = 4.61602
I0726 16:59:47.625892 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.81837 (* 1 = 4.81837 loss)
I0726 16:59:47.625900 31263 sgd_solver.cpp:138] Iteration 3350, lr = 0.001
I0726 17:00:17.047809 31263 solver.cpp:243] Iteration 3360, loss = 4.51386
I0726 17:00:17.047849 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.74469 (* 1 = 4.74469 loss)
I0726 17:00:17.047857 31263 sgd_solver.cpp:138] Iteration 3360, lr = 0.001
I0726 17:00:46.521050 31263 solver.cpp:243] Iteration 3370, loss = 4.54448
I0726 17:00:46.521147 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.18854 (* 1 = 5.18854 loss)
I0726 17:00:46.521153 31263 sgd_solver.cpp:138] Iteration 3370, lr = 0.001
I0726 17:01:15.935286 31263 solver.cpp:243] Iteration 3380, loss = 4.53253
I0726 17:01:15.935389 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.34602 (* 1 = 4.34602 loss)
I0726 17:01:15.935402 31263 sgd_solver.cpp:138] Iteration 3380, lr = 0.001
I0726 17:01:45.355947 31263 solver.cpp:243] Iteration 3390, loss = 4.50789
I0726 17:01:45.356112 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.45497 (* 1 = 4.45497 loss)
I0726 17:01:45.356122 31263 sgd_solver.cpp:138] Iteration 3390, lr = 0.001
I0726 17:02:14.708442 31263 solver.cpp:243] Iteration 3400, loss = 4.57357
I0726 17:02:14.708497 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.30501 (* 1 = 5.30501 loss)
I0726 17:02:14.708505 31263 sgd_solver.cpp:138] Iteration 3400, lr = 0.001
I0726 17:02:44.140004 31263 solver.cpp:243] Iteration 3410, loss = 4.49883
I0726 17:02:44.140180 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.17995 (* 1 = 5.17995 loss)
I0726 17:02:44.140193 31263 sgd_solver.cpp:138] Iteration 3410, lr = 0.001
I0726 17:03:13.670617 31263 solver.cpp:243] Iteration 3420, loss = 4.50356
I0726 17:03:13.670670 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.564 (* 1 = 4.564 loss)
I0726 17:03:13.670676 31263 sgd_solver.cpp:138] Iteration 3420, lr = 0.001
I0726 17:03:42.944098 31263 solver.cpp:243] Iteration 3430, loss = 4.60227
I0726 17:03:42.944339 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.23876 (* 1 = 3.23876 loss)
I0726 17:03:42.944363 31263 sgd_solver.cpp:138] Iteration 3430, lr = 0.001
I0726 17:04:12.358711 31263 solver.cpp:243] Iteration 3440, loss = 4.56704
I0726 17:04:12.358742 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.45978 (* 1 = 4.45978 loss)
I0726 17:04:12.358748 31263 sgd_solver.cpp:138] Iteration 3440, lr = 0.001
I0726 17:04:41.819774 31263 solver.cpp:243] Iteration 3450, loss = 4.49645
I0726 17:04:41.819946 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.87865 (* 1 = 3.87865 loss)
I0726 17:04:41.819953 31263 sgd_solver.cpp:138] Iteration 3450, lr = 0.001
I0726 17:05:11.162477 31263 solver.cpp:243] Iteration 3460, loss = 4.56358
I0726 17:05:11.162572 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.2585 (* 1 = 5.2585 loss)
I0726 17:05:11.162588 31263 sgd_solver.cpp:138] Iteration 3460, lr = 0.001
I0726 17:05:40.431227 31263 solver.cpp:243] Iteration 3470, loss = 4.63643
I0726 17:05:40.431342 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.56014 (* 1 = 4.56014 loss)
I0726 17:05:40.431351 31263 sgd_solver.cpp:138] Iteration 3470, lr = 0.001
I0726 17:06:09.789721 31263 solver.cpp:243] Iteration 3480, loss = 4.55183
I0726 17:06:09.789806 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.05212 (* 1 = 4.05212 loss)
I0726 17:06:09.789824 31263 sgd_solver.cpp:138] Iteration 3480, lr = 0.001
I0726 17:06:39.166321 31263 solver.cpp:243] Iteration 3490, loss = 4.52711
I0726 17:06:39.166438 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.17679 (* 1 = 4.17679 loss)
I0726 17:06:39.166445 31263 sgd_solver.cpp:138] Iteration 3490, lr = 0.001
I0726 17:07:08.593864 31263 solver.cpp:243] Iteration 3500, loss = 4.50348
I0726 17:07:08.593924 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.51459 (* 1 = 4.51459 loss)
I0726 17:07:08.593932 31263 sgd_solver.cpp:138] Iteration 3500, lr = 0.001
I0726 17:07:38.000046 31263 solver.cpp:243] Iteration 3510, loss = 4.52098
I0726 17:07:38.000329 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.34628 (* 1 = 4.34628 loss)
I0726 17:07:38.000340 31263 sgd_solver.cpp:138] Iteration 3510, lr = 0.001
I0726 17:08:07.348773 31263 solver.cpp:243] Iteration 3520, loss = 4.33668
I0726 17:08:07.348809 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.38085 (* 1 = 3.38085 loss)
I0726 17:08:07.348829 31263 sgd_solver.cpp:138] Iteration 3520, lr = 0.001
I0726 17:08:36.718528 31263 solver.cpp:243] Iteration 3530, loss = 4.59218
I0726 17:08:36.718621 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.40346 (* 1 = 5.40346 loss)
I0726 17:08:36.718632 31263 sgd_solver.cpp:138] Iteration 3530, lr = 0.001
I0726 17:09:06.133065 31263 solver.cpp:243] Iteration 3540, loss = 4.58195
I0726 17:09:06.133105 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.79718 (* 1 = 4.79718 loss)
I0726 17:09:06.133112 31263 sgd_solver.cpp:138] Iteration 3540, lr = 0.001
I0726 17:09:35.431536 31263 solver.cpp:243] Iteration 3550, loss = 4.53471
I0726 17:09:35.431633 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.74442 (* 1 = 4.74442 loss)
I0726 17:09:35.431641 31263 sgd_solver.cpp:138] Iteration 3550, lr = 0.001
I0726 17:10:04.760933 31263 solver.cpp:243] Iteration 3560, loss = 4.48865
I0726 17:10:04.760969 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.18807 (* 1 = 4.18807 loss)
I0726 17:10:04.760979 31263 sgd_solver.cpp:138] Iteration 3560, lr = 0.001
I0726 17:10:34.264655 31263 solver.cpp:243] Iteration 3570, loss = 4.45636
I0726 17:10:34.264812 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.6881 (* 1 = 4.6881 loss)
I0726 17:10:34.264823 31263 sgd_solver.cpp:138] Iteration 3570, lr = 0.001
I0726 17:11:03.619005 31263 solver.cpp:243] Iteration 3580, loss = 4.6327
I0726 17:11:03.619073 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.22594 (* 1 = 4.22594 loss)
I0726 17:11:03.619083 31263 sgd_solver.cpp:138] Iteration 3580, lr = 0.001
I0726 17:11:33.097149 31263 solver.cpp:243] Iteration 3590, loss = 4.56411
I0726 17:11:33.097317 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.12751 (* 1 = 4.12751 loss)
I0726 17:11:33.097324 31263 sgd_solver.cpp:138] Iteration 3590, lr = 0.001
I0726 17:12:02.368412 31263 solver.cpp:243] Iteration 3600, loss = 4.39352
I0726 17:12:02.368445 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.71033 (* 1 = 3.71033 loss)
I0726 17:12:02.368453 31263 sgd_solver.cpp:138] Iteration 3600, lr = 0.001
I0726 17:12:31.718165 31263 solver.cpp:243] Iteration 3610, loss = 4.43263
I0726 17:12:31.718348 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.64047 (* 1 = 3.64047 loss)
I0726 17:12:31.718358 31263 sgd_solver.cpp:138] Iteration 3610, lr = 0.001
I0726 17:13:01.121582 31263 solver.cpp:243] Iteration 3620, loss = 4.7189
I0726 17:13:01.121635 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.86866 (* 1 = 4.86866 loss)
I0726 17:13:01.121642 31263 sgd_solver.cpp:138] Iteration 3620, lr = 0.001
I0726 17:13:30.478073 31263 solver.cpp:243] Iteration 3630, loss = 4.41227
I0726 17:13:30.478356 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.35701 (* 1 = 4.35701 loss)
I0726 17:13:30.478366 31263 sgd_solver.cpp:138] Iteration 3630, lr = 0.001
I0726 17:14:00.069274 31263 solver.cpp:243] Iteration 3640, loss = 4.58142
I0726 17:14:00.071429 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.95159 (* 1 = 4.95159 loss)
I0726 17:14:00.071449 31263 sgd_solver.cpp:138] Iteration 3640, lr = 0.001
I0726 17:14:29.456409 31263 solver.cpp:243] Iteration 3650, loss = 4.61971
I0726 17:14:29.456719 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.49772 (* 1 = 5.49772 loss)
I0726 17:14:29.456729 31263 sgd_solver.cpp:138] Iteration 3650, lr = 0.001
I0726 17:14:58.765573 31263 solver.cpp:243] Iteration 3660, loss = 4.44456
I0726 17:14:58.765605 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.58221 (* 1 = 4.58221 loss)
I0726 17:14:58.765611 31263 sgd_solver.cpp:138] Iteration 3660, lr = 0.001
I0726 17:15:28.150902 31263 solver.cpp:243] Iteration 3670, loss = 4.44875
I0726 17:15:28.151191 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.45389 (* 1 = 4.45389 loss)
I0726 17:15:28.151199 31263 sgd_solver.cpp:138] Iteration 3670, lr = 0.001
I0726 17:15:57.500905 31263 solver.cpp:243] Iteration 3680, loss = 4.50787
I0726 17:15:57.500936 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.14754 (* 1 = 4.14754 loss)
I0726 17:15:57.500943 31263 sgd_solver.cpp:138] Iteration 3680, lr = 0.001
I0726 17:16:26.827113 31263 solver.cpp:243] Iteration 3690, loss = 4.57595
I0726 17:16:26.827262 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.29561 (* 1 = 4.29561 loss)
I0726 17:16:26.827272 31263 sgd_solver.cpp:138] Iteration 3690, lr = 0.001
I0726 17:16:56.240573 31263 solver.cpp:243] Iteration 3700, loss = 4.41754
I0726 17:16:56.240613 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.315 (* 1 = 4.315 loss)
I0726 17:16:56.240623 31263 sgd_solver.cpp:138] Iteration 3700, lr = 0.001
I0726 17:17:25.588454 31263 solver.cpp:243] Iteration 3710, loss = 4.48313
I0726 17:17:25.588600 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.03344 (* 1 = 4.03344 loss)
I0726 17:17:25.588611 31263 sgd_solver.cpp:138] Iteration 3710, lr = 0.001
I0726 17:17:54.935324 31263 solver.cpp:243] Iteration 3720, loss = 4.4513
I0726 17:17:54.935356 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.94142 (* 1 = 4.94142 loss)
I0726 17:17:54.935364 31263 sgd_solver.cpp:138] Iteration 3720, lr = 0.001
I0726 17:18:24.350229 31263 solver.cpp:243] Iteration 3730, loss = 4.43225
I0726 17:18:24.350685 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.2976 (* 1 = 4.2976 loss)
I0726 17:18:24.350705 31263 sgd_solver.cpp:138] Iteration 3730, lr = 0.001
I0726 17:18:53.544437 31263 solver.cpp:243] Iteration 3740, loss = 4.40522
I0726 17:18:53.544481 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.49194 (* 1 = 4.49194 loss)
I0726 17:18:53.544488 31263 sgd_solver.cpp:138] Iteration 3740, lr = 0.001
I0726 17:19:22.875844 31263 solver.cpp:243] Iteration 3750, loss = 4.41811
I0726 17:19:22.876010 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.00743 (* 1 = 4.00743 loss)
I0726 17:19:22.876022 31263 sgd_solver.cpp:138] Iteration 3750, lr = 0.001
I0726 17:19:52.249111 31263 solver.cpp:243] Iteration 3760, loss = 4.42589
I0726 17:19:52.249173 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.3127 (* 1 = 4.3127 loss)
I0726 17:19:52.249181 31263 sgd_solver.cpp:138] Iteration 3760, lr = 0.001
I0726 17:20:21.525382 31263 solver.cpp:243] Iteration 3770, loss = 4.46027
I0726 17:20:21.525643 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.52283 (* 1 = 4.52283 loss)
I0726 17:20:21.525653 31263 sgd_solver.cpp:138] Iteration 3770, lr = 0.001
I0726 17:20:50.889555 31263 solver.cpp:243] Iteration 3780, loss = 4.43428
I0726 17:20:50.889595 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.64981 (* 1 = 4.64981 loss)
I0726 17:20:50.889606 31263 sgd_solver.cpp:138] Iteration 3780, lr = 0.001
I0726 17:21:20.297662 31263 solver.cpp:243] Iteration 3790, loss = 4.40858
I0726 17:21:20.297963 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.1706 (* 1 = 4.1706 loss)
I0726 17:21:20.297976 31263 sgd_solver.cpp:138] Iteration 3790, lr = 0.001
I0726 17:21:49.707074 31263 solver.cpp:243] Iteration 3800, loss = 4.39418
I0726 17:21:49.707131 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.89179 (* 1 = 4.89179 loss)
I0726 17:21:49.707156 31263 sgd_solver.cpp:138] Iteration 3800, lr = 0.001
I0726 17:22:19.077109 31263 solver.cpp:243] Iteration 3810, loss = 4.42839
I0726 17:22:19.077251 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.76183 (* 1 = 3.76183 loss)
I0726 17:22:19.077260 31263 sgd_solver.cpp:138] Iteration 3810, lr = 0.001
I0726 17:22:48.522104 31263 solver.cpp:243] Iteration 3820, loss = 4.60924
I0726 17:22:48.522150 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.72399 (* 1 = 4.72399 loss)
I0726 17:22:48.522159 31263 sgd_solver.cpp:138] Iteration 3820, lr = 0.001
I0726 17:23:17.871886 31263 solver.cpp:243] Iteration 3830, loss = 4.47032
I0726 17:23:17.874914 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.22726 (* 1 = 4.22726 loss)
I0726 17:23:17.874925 31263 sgd_solver.cpp:138] Iteration 3830, lr = 0.001
I0726 17:23:47.254125 31263 solver.cpp:243] Iteration 3840, loss = 4.47039
I0726 17:23:47.254223 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.13585 (* 1 = 4.13585 loss)
I0726 17:23:47.254238 31263 sgd_solver.cpp:138] Iteration 3840, lr = 0.001
I0726 17:24:16.694629 31263 solver.cpp:243] Iteration 3850, loss = 4.33411
I0726 17:24:16.695502 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.40671 (* 1 = 3.40671 loss)
I0726 17:24:16.695513 31263 sgd_solver.cpp:138] Iteration 3850, lr = 0.001
I0726 17:24:46.128589 31263 solver.cpp:243] Iteration 3860, loss = 4.48679
I0726 17:24:46.131191 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.39095 (* 1 = 5.39095 loss)
I0726 17:24:46.131217 31263 sgd_solver.cpp:138] Iteration 3860, lr = 0.001
I0726 17:25:33.028853 31263 solver.cpp:243] Iteration 3870, loss = 4.39801
I0726 17:25:33.045022 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.20889 (* 1 = 4.20889 loss)
I0726 17:25:33.051353 31263 sgd_solver.cpp:138] Iteration 3870, lr = 0.001
I0726 17:26:07.646404 31263 solver.cpp:243] Iteration 3880, loss = 4.45416
I0726 17:26:07.647927 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.03516 (* 1 = 5.03516 loss)
I0726 17:26:07.647938 31263 sgd_solver.cpp:138] Iteration 3880, lr = 0.001
I0726 17:26:37.109596 31263 solver.cpp:243] Iteration 3890, loss = 4.52608
I0726 17:26:37.109632 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.87068 (* 1 = 3.87068 loss)
I0726 17:26:37.109638 31263 sgd_solver.cpp:138] Iteration 3890, lr = 0.001
I0726 17:27:06.789794 31263 solver.cpp:243] Iteration 3900, loss = 4.42515
I0726 17:27:06.789978 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.0263 (* 1 = 4.0263 loss)
I0726 17:27:06.789988 31263 sgd_solver.cpp:138] Iteration 3900, lr = 0.001
I0726 17:27:36.571420 31263 solver.cpp:243] Iteration 3910, loss = 4.45003
I0726 17:27:36.571490 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.99647 (* 1 = 3.99647 loss)
I0726 17:27:36.571498 31263 sgd_solver.cpp:138] Iteration 3910, lr = 0.001
I0726 17:28:06.339560 31263 solver.cpp:243] Iteration 3920, loss = 4.39218
I0726 17:28:06.339711 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.19906 (* 1 = 4.19906 loss)
I0726 17:28:06.339720 31263 sgd_solver.cpp:138] Iteration 3920, lr = 0.001
I0726 17:28:36.067167 31263 solver.cpp:243] Iteration 3930, loss = 4.44723
I0726 17:28:36.067219 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.28209 (* 1 = 4.28209 loss)
I0726 17:28:36.067224 31263 sgd_solver.cpp:138] Iteration 3930, lr = 0.001
I0726 17:29:05.750324 31263 solver.cpp:243] Iteration 3940, loss = 4.26349
I0726 17:29:05.750644 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.82232 (* 1 = 4.82232 loss)
I0726 17:29:05.750668 31263 sgd_solver.cpp:138] Iteration 3940, lr = 0.001
I0726 17:29:35.464718 31263 solver.cpp:243] Iteration 3950, loss = 4.3423
I0726 17:29:35.464809 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.25972 (* 1 = 4.25972 loss)
I0726 17:29:35.464824 31263 sgd_solver.cpp:138] Iteration 3950, lr = 0.001
I0726 17:30:05.207520 31263 solver.cpp:243] Iteration 3960, loss = 4.51344
I0726 17:30:05.207778 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.07063 (* 1 = 5.07063 loss)
I0726 17:30:05.207795 31263 sgd_solver.cpp:138] Iteration 3960, lr = 0.001
I0726 17:30:34.724318 31263 solver.cpp:243] Iteration 3970, loss = 4.31245
I0726 17:30:34.724349 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.3281 (* 1 = 4.3281 loss)
I0726 17:30:34.724354 31263 sgd_solver.cpp:138] Iteration 3970, lr = 0.001
I0726 17:31:04.388226 31263 solver.cpp:243] Iteration 3980, loss = 4.4547
I0726 17:31:04.388382 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.77937 (* 1 = 4.77937 loss)
I0726 17:31:04.388401 31263 sgd_solver.cpp:138] Iteration 3980, lr = 0.001
I0726 17:31:34.708060 31263 solver.cpp:243] Iteration 3990, loss = 4.53316
I0726 17:31:34.711238 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.28389 (* 1 = 4.28389 loss)
I0726 17:31:34.711275 31263 sgd_solver.cpp:138] Iteration 3990, lr = 0.001
I0726 17:32:01.566268 31263 solver.cpp:433] Iteration 4000, Testing net (#0)
I0726 17:32:01.575343 31263 net.cpp:693] Ignoring source layer mbox_loss
W0726 17:32:05.590180 31263 solver.cpp:524] Missing true_pos for label: 8
W0726 17:32:05.590725 31263 solver.cpp:524] Missing true_pos for label: 12
W0726 17:32:05.590854 31263 solver.cpp:524] Missing true_pos for label: 15
W0726 17:32:05.590869 31263 solver.cpp:524] Missing true_pos for label: 16
W0726 17:32:05.591061 31263 solver.cpp:524] Missing true_pos for label: 22
W0726 17:32:05.591068 31263 solver.cpp:524] Missing true_pos for label: 23
W0726 17:32:05.591152 31263 solver.cpp:524] Missing true_pos for label: 30
W0726 17:32:05.591199 31263 solver.cpp:524] Missing true_pos for label: 32
W0726 17:32:05.591274 31263 solver.cpp:524] Missing true_pos for label: 34
W0726 17:32:05.592833 31263 solver.cpp:524] Missing true_pos for label: 50
W0726 17:32:05.592877 31263 solver.cpp:524] Missing true_pos for label: 53
W0726 17:32:05.592900 31263 solver.cpp:524] Missing true_pos for label: 57
W0726 17:32:05.592905 31263 solver.cpp:524] Missing true_pos for label: 58
I0726 17:32:05.592909 31263 solver.cpp:546]     Test net output #0: detection_eval = 0.196603
I0726 17:32:08.120970 31263 solver.cpp:243] Iteration 4000, loss = 4.25267
I0726 17:32:08.121013 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.14512 (* 1 = 4.14512 loss)
I0726 17:32:08.121021 31263 sgd_solver.cpp:138] Iteration 4000, lr = 0.001
I0726 17:32:38.340817 31263 solver.cpp:243] Iteration 4010, loss = 4.33893
I0726 17:32:38.340968 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36112 (* 1 = 4.36112 loss)
I0726 17:32:38.340978 31263 sgd_solver.cpp:138] Iteration 4010, lr = 0.001
I0726 17:33:08.129528 31263 solver.cpp:243] Iteration 4020, loss = 4.4363
I0726 17:33:08.129606 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.25629 (* 1 = 4.25629 loss)
I0726 17:33:08.129612 31263 sgd_solver.cpp:138] Iteration 4020, lr = 0.001
I0726 17:33:38.068034 31263 solver.cpp:243] Iteration 4030, loss = 4.37171
I0726 17:33:38.068212 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.22331 (* 1 = 4.22331 loss)
I0726 17:33:38.068220 31263 sgd_solver.cpp:138] Iteration 4030, lr = 0.001
I0726 17:34:07.772842 31263 solver.cpp:243] Iteration 4040, loss = 4.46911
I0726 17:34:07.772872 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.63158 (* 1 = 5.63158 loss)
I0726 17:34:07.772878 31263 sgd_solver.cpp:138] Iteration 4040, lr = 0.001
I0726 17:34:37.428442 31263 solver.cpp:243] Iteration 4050, loss = 4.42551
I0726 17:34:37.428550 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.90116 (* 1 = 3.90116 loss)
I0726 17:34:37.428557 31263 sgd_solver.cpp:138] Iteration 4050, lr = 0.001
I0726 17:35:07.088572 31263 solver.cpp:243] Iteration 4060, loss = 4.4675
I0726 17:35:07.088613 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.47501 (* 1 = 4.47501 loss)
I0726 17:35:07.088620 31263 sgd_solver.cpp:138] Iteration 4060, lr = 0.001
I0726 17:35:36.872205 31263 solver.cpp:243] Iteration 4070, loss = 4.55358
I0726 17:35:36.872339 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.87122 (* 1 = 4.87122 loss)
I0726 17:35:36.872366 31263 sgd_solver.cpp:138] Iteration 4070, lr = 0.001
I0726 17:36:06.415076 31263 solver.cpp:243] Iteration 4080, loss = 4.41725
I0726 17:36:06.415112 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.07482 (* 1 = 5.07482 loss)
I0726 17:36:06.415118 31263 sgd_solver.cpp:138] Iteration 4080, lr = 0.001
I0726 17:36:36.113123 31263 solver.cpp:243] Iteration 4090, loss = 4.43966
I0726 17:36:36.113302 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.32463 (* 1 = 3.32463 loss)
I0726 17:36:36.113312 31263 sgd_solver.cpp:138] Iteration 4090, lr = 0.001
I0726 17:37:05.897001 31263 solver.cpp:243] Iteration 4100, loss = 4.43507
I0726 17:37:05.897053 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.59536 (* 1 = 3.59536 loss)
I0726 17:37:05.897083 31263 sgd_solver.cpp:138] Iteration 4100, lr = 0.001
I0726 17:37:35.394481 31263 solver.cpp:243] Iteration 4110, loss = 4.264
I0726 17:37:35.394636 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.76069 (* 1 = 3.76069 loss)
I0726 17:37:35.394645 31263 sgd_solver.cpp:138] Iteration 4110, lr = 0.001
I0726 17:38:05.092228 31263 solver.cpp:243] Iteration 4120, loss = 4.384
I0726 17:38:05.092356 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.35104 (* 1 = 5.35104 loss)
I0726 17:38:05.092377 31263 sgd_solver.cpp:138] Iteration 4120, lr = 0.001
I0726 17:38:34.916919 31263 solver.cpp:243] Iteration 4130, loss = 4.43703
I0726 17:38:34.917141 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.55488 (* 1 = 4.55488 loss)
I0726 17:38:34.917151 31263 sgd_solver.cpp:138] Iteration 4130, lr = 0.001
I0726 17:39:04.616817 31263 solver.cpp:243] Iteration 4140, loss = 4.26201
I0726 17:39:04.616870 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.08217 (* 1 = 4.08217 loss)
I0726 17:39:04.616879 31263 sgd_solver.cpp:138] Iteration 4140, lr = 0.001
I0726 17:39:34.241762 31263 solver.cpp:243] Iteration 4150, loss = 4.32225
I0726 17:39:34.241987 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.70131 (* 1 = 3.70131 loss)
I0726 17:39:34.241997 31263 sgd_solver.cpp:138] Iteration 4150, lr = 0.001
I0726 17:40:04.100227 31263 solver.cpp:243] Iteration 4160, loss = 4.39678
I0726 17:40:04.100327 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.43786 (* 1 = 4.43786 loss)
I0726 17:40:04.100339 31263 sgd_solver.cpp:138] Iteration 4160, lr = 0.001
I0726 17:40:33.986932 31263 solver.cpp:243] Iteration 4170, loss = 4.41924
I0726 17:40:33.987160 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.6072 (* 1 = 4.6072 loss)
I0726 17:40:33.987169 31263 sgd_solver.cpp:138] Iteration 4170, lr = 0.001
I0726 17:41:03.861490 31263 solver.cpp:243] Iteration 4180, loss = 4.33351
I0726 17:41:03.861582 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.351 (* 1 = 4.351 loss)
I0726 17:41:03.861596 31263 sgd_solver.cpp:138] Iteration 4180, lr = 0.001
I0726 17:41:33.738384 31263 solver.cpp:243] Iteration 4190, loss = 4.22516
I0726 17:41:33.738535 31263 solver.cpp:259]     Train net output #0: mbox_loss = 2.96107 (* 1 = 2.96107 loss)
I0726 17:41:33.738546 31263 sgd_solver.cpp:138] Iteration 4190, lr = 0.001
I0726 17:42:03.296319 31263 solver.cpp:243] Iteration 4200, loss = 4.31121
I0726 17:42:03.296430 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.44593 (* 1 = 4.44593 loss)
I0726 17:42:03.296445 31263 sgd_solver.cpp:138] Iteration 4200, lr = 0.001
I0726 17:42:32.868443 31263 solver.cpp:243] Iteration 4210, loss = 4.40184
I0726 17:42:32.868585 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.90712 (* 1 = 4.90712 loss)
I0726 17:42:32.868594 31263 sgd_solver.cpp:138] Iteration 4210, lr = 0.001
I0726 17:43:02.746366 31263 solver.cpp:243] Iteration 4220, loss = 4.32096
I0726 17:43:02.746408 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36292 (* 1 = 4.36292 loss)
I0726 17:43:02.746419 31263 sgd_solver.cpp:138] Iteration 4220, lr = 0.001
I0726 17:43:32.613188 31263 solver.cpp:243] Iteration 4230, loss = 4.33131
I0726 17:43:32.613934 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.77876 (* 1 = 4.77876 loss)
I0726 17:43:32.613976 31263 sgd_solver.cpp:138] Iteration 4230, lr = 0.001
I0726 17:44:02.058781 31263 solver.cpp:243] Iteration 4240, loss = 4.41345
I0726 17:44:02.058913 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.01829 (* 1 = 4.01829 loss)
I0726 17:44:02.058931 31263 sgd_solver.cpp:138] Iteration 4240, lr = 0.001
I0726 17:44:31.397006 31263 solver.cpp:243] Iteration 4250, loss = 4.30377
I0726 17:44:31.397106 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36316 (* 1 = 4.36316 loss)
I0726 17:44:31.397116 31263 sgd_solver.cpp:138] Iteration 4250, lr = 0.001
I0726 17:45:00.992135 31263 solver.cpp:243] Iteration 4260, loss = 4.36739
I0726 17:45:00.992163 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.46137 (* 1 = 4.46137 loss)
I0726 17:45:00.992169 31263 sgd_solver.cpp:138] Iteration 4260, lr = 0.001
I0726 17:45:30.715517 31263 solver.cpp:243] Iteration 4270, loss = 4.31086
I0726 17:45:30.715698 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.71017 (* 1 = 4.71017 loss)
I0726 17:45:30.715713 31263 sgd_solver.cpp:138] Iteration 4270, lr = 0.001
I0726 17:46:00.082195 31263 solver.cpp:243] Iteration 4280, loss = 4.25302
I0726 17:46:00.082226 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.864 (* 1 = 3.864 loss)
I0726 17:46:00.082231 31263 sgd_solver.cpp:138] Iteration 4280, lr = 0.001
I0726 17:46:29.612370 31263 solver.cpp:243] Iteration 4290, loss = 4.26465
I0726 17:46:29.612534 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.35021 (* 1 = 4.35021 loss)
I0726 17:46:29.612542 31263 sgd_solver.cpp:138] Iteration 4290, lr = 0.001
I0726 17:46:59.095052 31263 solver.cpp:243] Iteration 4300, loss = 4.37331
I0726 17:46:59.095103 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.91217 (* 1 = 3.91217 loss)
I0726 17:46:59.095110 31263 sgd_solver.cpp:138] Iteration 4300, lr = 0.001
I0726 17:47:28.653829 31263 solver.cpp:243] Iteration 4310, loss = 4.29393
I0726 17:47:28.654187 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.16801 (* 1 = 4.16801 loss)
I0726 17:47:28.654213 31263 sgd_solver.cpp:138] Iteration 4310, lr = 0.001
I0726 17:47:58.104424 31263 solver.cpp:243] Iteration 4320, loss = 4.39869
I0726 17:47:58.104492 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.03356 (* 1 = 4.03356 loss)
I0726 17:47:58.104507 31263 sgd_solver.cpp:138] Iteration 4320, lr = 0.001
I0726 17:48:27.697402 31263 solver.cpp:243] Iteration 4330, loss = 4.38839
I0726 17:48:27.700350 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.66585 (* 1 = 3.66585 loss)
I0726 17:48:27.700359 31263 sgd_solver.cpp:138] Iteration 4330, lr = 0.001
I0726 17:48:57.272620 31263 solver.cpp:243] Iteration 4340, loss = 4.26587
I0726 17:48:57.272653 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.83731 (* 1 = 4.83731 loss)
I0726 17:48:57.272660 31263 sgd_solver.cpp:138] Iteration 4340, lr = 0.001
I0726 17:49:26.916239 31263 solver.cpp:243] Iteration 4350, loss = 4.21343
I0726 17:49:26.916357 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.37589 (* 1 = 4.37589 loss)
I0726 17:49:26.916366 31263 sgd_solver.cpp:138] Iteration 4350, lr = 0.001
I0726 17:49:56.604328 31263 solver.cpp:243] Iteration 4360, loss = 4.3227
I0726 17:49:56.604358 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.13522 (* 1 = 4.13522 loss)
I0726 17:49:56.604364 31263 sgd_solver.cpp:138] Iteration 4360, lr = 0.001
I0726 17:50:26.372248 31263 solver.cpp:243] Iteration 4370, loss = 4.34227
I0726 17:50:26.375344 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.67489 (* 1 = 4.67489 loss)
I0726 17:50:26.375391 31263 sgd_solver.cpp:138] Iteration 4370, lr = 0.001
I0726 17:50:56.078737 31263 solver.cpp:243] Iteration 4380, loss = 4.29574
I0726 17:50:56.078778 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.21713 (* 1 = 4.21713 loss)
I0726 17:50:56.078784 31263 sgd_solver.cpp:138] Iteration 4380, lr = 0.001
I0726 17:51:29.680016 31263 solver.cpp:243] Iteration 4390, loss = 4.35396
I0726 17:51:29.680147 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.53924 (* 1 = 3.53924 loss)
I0726 17:51:29.680156 31263 sgd_solver.cpp:138] Iteration 4390, lr = 0.001
I0726 17:52:00.011157 31263 solver.cpp:243] Iteration 4400, loss = 4.35989
I0726 17:52:00.011333 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.11105 (* 1 = 5.11105 loss)
I0726 17:52:00.011350 31263 sgd_solver.cpp:138] Iteration 4400, lr = 0.001
I0726 17:52:30.414362 31263 solver.cpp:243] Iteration 4410, loss = 4.41776
I0726 17:52:30.415154 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.91356 (* 1 = 4.91356 loss)
I0726 17:52:30.415235 31263 sgd_solver.cpp:138] Iteration 4410, lr = 0.001
I0726 17:53:00.305106 31263 solver.cpp:243] Iteration 4420, loss = 4.28984
I0726 17:53:00.305135 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.45464 (* 1 = 3.45464 loss)
I0726 17:53:00.305141 31263 sgd_solver.cpp:138] Iteration 4420, lr = 0.001
I0726 17:53:30.431852 31263 solver.cpp:243] Iteration 4430, loss = 4.31751
I0726 17:53:30.431932 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.93548 (* 1 = 3.93548 loss)
I0726 17:53:30.431941 31263 sgd_solver.cpp:138] Iteration 4430, lr = 0.001
I0726 17:54:00.105983 31263 solver.cpp:243] Iteration 4440, loss = 4.49374
I0726 17:54:00.106007 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.11298 (* 1 = 4.11298 loss)
I0726 17:54:00.106014 31263 sgd_solver.cpp:138] Iteration 4440, lr = 0.001
I0726 17:54:29.284994 31263 solver.cpp:243] Iteration 4450, loss = 4.23608
I0726 17:54:29.285137 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.62602 (* 1 = 5.62602 loss)
I0726 17:54:29.285148 31263 sgd_solver.cpp:138] Iteration 4450, lr = 0.001
I0726 17:54:58.462556 31263 solver.cpp:243] Iteration 4460, loss = 4.27417
I0726 17:54:58.462631 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.17303 (* 1 = 4.17303 loss)
I0726 17:54:58.462640 31263 sgd_solver.cpp:138] Iteration 4460, lr = 0.001
I0726 17:55:27.691783 31263 solver.cpp:243] Iteration 4470, loss = 4.3235
I0726 17:55:27.691923 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.65022 (* 1 = 4.65022 loss)
I0726 17:55:27.691936 31263 sgd_solver.cpp:138] Iteration 4470, lr = 0.001
I0726 17:55:56.862676 31263 solver.cpp:243] Iteration 4480, loss = 4.2625
I0726 17:55:56.862763 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36859 (* 1 = 4.36859 loss)
I0726 17:55:56.862779 31263 sgd_solver.cpp:138] Iteration 4480, lr = 0.001
I0726 17:56:26.195263 31263 solver.cpp:243] Iteration 4490, loss = 4.33685
I0726 17:56:26.195427 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.19648 (* 1 = 5.19648 loss)
I0726 17:56:26.195437 31263 sgd_solver.cpp:138] Iteration 4490, lr = 0.001
I0726 17:56:55.386746 31263 solver.cpp:243] Iteration 4500, loss = 4.21166
I0726 17:56:55.386776 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.82682 (* 1 = 3.82682 loss)
I0726 17:56:55.386785 31263 sgd_solver.cpp:138] Iteration 4500, lr = 0.001
I0726 17:57:24.646255 31263 solver.cpp:243] Iteration 4510, loss = 4.24547
I0726 17:57:24.646397 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.94459 (* 1 = 3.94459 loss)
I0726 17:57:24.646409 31263 sgd_solver.cpp:138] Iteration 4510, lr = 0.001
I0726 17:57:53.913903 31263 solver.cpp:243] Iteration 4520, loss = 4.36661
I0726 17:57:53.913940 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.48166 (* 1 = 4.48166 loss)
I0726 17:57:53.913947 31263 sgd_solver.cpp:138] Iteration 4520, lr = 0.001
I0726 17:58:23.162997 31263 solver.cpp:243] Iteration 4530, loss = 4.2914
I0726 17:58:23.163128 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.85792 (* 1 = 4.85792 loss)
I0726 17:58:23.163136 31263 sgd_solver.cpp:138] Iteration 4530, lr = 0.001
I0726 17:58:52.343456 31263 solver.cpp:243] Iteration 4540, loss = 4.30125
I0726 17:58:52.343483 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.36794 (* 1 = 3.36794 loss)
I0726 17:58:52.343490 31263 sgd_solver.cpp:138] Iteration 4540, lr = 0.001
I0726 17:59:21.596415 31263 solver.cpp:243] Iteration 4550, loss = 4.30657
I0726 17:59:21.596573 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.16138 (* 1 = 5.16138 loss)
I0726 17:59:21.596582 31263 sgd_solver.cpp:138] Iteration 4550, lr = 0.001
I0726 17:59:51.040261 31263 solver.cpp:243] Iteration 4560, loss = 4.09613
I0726 17:59:51.040284 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.3683 (* 1 = 3.3683 loss)
I0726 17:59:51.040290 31263 sgd_solver.cpp:138] Iteration 4560, lr = 0.001
I0726 18:00:20.352983 31263 solver.cpp:243] Iteration 4570, loss = 4.30429
I0726 18:00:20.353046 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.06582 (* 1 = 4.06582 loss)
I0726 18:00:20.353055 31263 sgd_solver.cpp:138] Iteration 4570, lr = 0.001
I0726 18:00:49.610720 31263 solver.cpp:243] Iteration 4580, loss = 4.23998
I0726 18:00:49.610750 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.79442 (* 1 = 3.79442 loss)
I0726 18:00:49.610756 31263 sgd_solver.cpp:138] Iteration 4580, lr = 0.001
I0726 18:01:18.870326 31263 solver.cpp:243] Iteration 4590, loss = 4.14692
I0726 18:01:18.870448 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.95961 (* 1 = 3.95961 loss)
I0726 18:01:18.870456 31263 sgd_solver.cpp:138] Iteration 4590, lr = 0.001
I0726 18:01:48.472334 31263 solver.cpp:243] Iteration 4600, loss = 4.13152
I0726 18:01:48.472396 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.038 (* 1 = 4.038 loss)
I0726 18:01:48.472404 31263 sgd_solver.cpp:138] Iteration 4600, lr = 0.001
I0726 18:02:17.904813 31263 solver.cpp:243] Iteration 4610, loss = 4.30555
I0726 18:02:17.904886 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.27285 (* 1 = 4.27285 loss)
I0726 18:02:17.904894 31263 sgd_solver.cpp:138] Iteration 4610, lr = 0.001
I0726 18:02:47.261973 31263 solver.cpp:243] Iteration 4620, loss = 4.27793
I0726 18:02:47.262100 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.85116 (* 1 = 3.85116 loss)
I0726 18:02:47.262118 31263 sgd_solver.cpp:138] Iteration 4620, lr = 0.001
I0726 18:03:16.757114 31263 solver.cpp:243] Iteration 4630, loss = 4.23951
I0726 18:03:16.757243 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.74246 (* 1 = 3.74246 loss)
I0726 18:03:16.757256 31263 sgd_solver.cpp:138] Iteration 4630, lr = 0.001
I0726 18:03:46.178551 31263 solver.cpp:243] Iteration 4640, loss = 4.21986
I0726 18:03:46.178581 31263 solver.cpp:259]     Train net output #0: mbox_loss = 5.46559 (* 1 = 5.46559 loss)
I0726 18:03:46.178587 31263 sgd_solver.cpp:138] Iteration 4640, lr = 0.001
I0726 18:04:15.609314 31263 solver.cpp:243] Iteration 4650, loss = 4.3264
I0726 18:04:15.609433 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.18842 (* 1 = 4.18842 loss)
I0726 18:04:15.609442 31263 sgd_solver.cpp:138] Iteration 4650, lr = 0.001
I0726 18:04:45.021054 31263 solver.cpp:243] Iteration 4660, loss = 4.26379
I0726 18:04:45.021121 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.35211 (* 1 = 4.35211 loss)
I0726 18:04:45.021127 31263 sgd_solver.cpp:138] Iteration 4660, lr = 0.001
I0726 18:05:14.462733 31263 solver.cpp:243] Iteration 4670, loss = 4.18757
I0726 18:05:14.462890 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.38222 (* 1 = 4.38222 loss)
I0726 18:05:14.462901 31263 sgd_solver.cpp:138] Iteration 4670, lr = 0.001
I0726 18:05:43.923327 31263 solver.cpp:243] Iteration 4680, loss = 4.22039
I0726 18:05:43.923354 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.91375 (* 1 = 3.91375 loss)
I0726 18:05:43.923360 31263 sgd_solver.cpp:138] Iteration 4680, lr = 0.001
I0726 18:06:13.520864 31263 solver.cpp:243] Iteration 4690, loss = 4.24972
I0726 18:06:13.520961 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.35766 (* 1 = 4.35766 loss)
I0726 18:06:13.520970 31263 sgd_solver.cpp:138] Iteration 4690, lr = 0.001
I0726 18:06:43.028168 31263 solver.cpp:243] Iteration 4700, loss = 4.26203
I0726 18:06:43.028213 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.12819 (* 1 = 4.12819 loss)
I0726 18:06:43.028219 31263 sgd_solver.cpp:138] Iteration 4700, lr = 0.001
I0726 18:07:12.411842 31263 solver.cpp:243] Iteration 4710, loss = 4.29652
I0726 18:07:12.415071 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.67598 (* 1 = 3.67598 loss)
I0726 18:07:12.415081 31263 sgd_solver.cpp:138] Iteration 4710, lr = 0.001
I0726 18:07:42.004189 31263 solver.cpp:243] Iteration 4720, loss = 4.16206
I0726 18:07:42.004247 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.28356 (* 1 = 4.28356 loss)
I0726 18:07:42.004259 31263 sgd_solver.cpp:138] Iteration 4720, lr = 0.001
I0726 18:08:11.476071 31263 solver.cpp:243] Iteration 4730, loss = 4.2668
I0726 18:08:11.476197 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.76871 (* 1 = 4.76871 loss)
I0726 18:08:11.476207 31263 sgd_solver.cpp:138] Iteration 4730, lr = 0.001
I0726 18:08:41.015219 31263 solver.cpp:243] Iteration 4740, loss = 4.21346
I0726 18:08:41.015271 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.43025 (* 1 = 4.43025 loss)
I0726 18:08:41.015278 31263 sgd_solver.cpp:138] Iteration 4740, lr = 0.001
I0726 18:09:10.569231 31263 solver.cpp:243] Iteration 4750, loss = 4.28802
I0726 18:09:10.569442 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.95418 (* 1 = 3.95418 loss)
I0726 18:09:10.569456 31263 sgd_solver.cpp:138] Iteration 4750, lr = 0.001
I0726 18:09:40.182173 31263 solver.cpp:243] Iteration 4760, loss = 4.19385
I0726 18:09:40.182292 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.53137 (* 1 = 4.53137 loss)
I0726 18:09:40.182309 31263 sgd_solver.cpp:138] Iteration 4760, lr = 0.001
I0726 18:10:09.891774 31263 solver.cpp:243] Iteration 4770, loss = 4.26149
I0726 18:10:09.891871 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.15974 (* 1 = 4.15974 loss)
I0726 18:10:09.891894 31263 sgd_solver.cpp:138] Iteration 4770, lr = 0.001
I0726 18:10:39.833518 31263 solver.cpp:243] Iteration 4780, loss = 4.1175
I0726 18:10:39.833544 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.42456 (* 1 = 4.42456 loss)
I0726 18:10:39.833552 31263 sgd_solver.cpp:138] Iteration 4780, lr = 0.001
I0726 18:11:09.302503 31263 solver.cpp:243] Iteration 4790, loss = 4.10782
I0726 18:11:09.302624 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.11601 (* 1 = 4.11601 loss)
I0726 18:11:09.302634 31263 sgd_solver.cpp:138] Iteration 4790, lr = 0.001
I0726 18:11:38.687144 31263 solver.cpp:243] Iteration 4800, loss = 4.19419
I0726 18:11:38.687173 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.51834 (* 1 = 4.51834 loss)
I0726 18:11:38.687178 31263 sgd_solver.cpp:138] Iteration 4800, lr = 0.001
I0726 18:12:08.190194 31263 solver.cpp:243] Iteration 4810, loss = 4.27791
I0726 18:12:08.190353 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.76422 (* 1 = 4.76422 loss)
I0726 18:12:08.190362 31263 sgd_solver.cpp:138] Iteration 4810, lr = 0.001
I0726 18:12:37.815088 31263 solver.cpp:243] Iteration 4820, loss = 4.16278
I0726 18:12:37.815127 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.64161 (* 1 = 3.64161 loss)
I0726 18:12:37.815134 31263 sgd_solver.cpp:138] Iteration 4820, lr = 0.001
I0726 18:13:07.435616 31263 solver.cpp:243] Iteration 4830, loss = 4.16833
I0726 18:13:07.435811 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.22234 (* 1 = 4.22234 loss)
I0726 18:13:07.435834 31263 sgd_solver.cpp:138] Iteration 4830, lr = 0.001
I0726 18:13:37.064914 31263 solver.cpp:243] Iteration 4840, loss = 4.09807
I0726 18:13:37.064975 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.07298 (* 1 = 4.07298 loss)
I0726 18:13:37.064981 31263 sgd_solver.cpp:138] Iteration 4840, lr = 0.001
I0726 18:14:06.630466 31263 solver.cpp:243] Iteration 4850, loss = 4.15819
I0726 18:14:06.630630 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.2136 (* 1 = 4.2136 loss)
I0726 18:14:06.630641 31263 sgd_solver.cpp:138] Iteration 4850, lr = 0.001
I0726 18:14:36.253840 31263 solver.cpp:243] Iteration 4860, loss = 4.19473
I0726 18:14:36.253868 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.77474 (* 1 = 3.77474 loss)
I0726 18:14:36.253875 31263 sgd_solver.cpp:138] Iteration 4860, lr = 0.001
I0726 18:15:05.845116 31263 solver.cpp:243] Iteration 4870, loss = 4.1695
I0726 18:15:05.845374 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.30745 (* 1 = 4.30745 loss)
I0726 18:15:05.845386 31263 sgd_solver.cpp:138] Iteration 4870, lr = 0.001
I0726 18:15:35.903548 31263 solver.cpp:243] Iteration 4880, loss = 4.14646
I0726 18:15:35.903657 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.12099 (* 1 = 3.12099 loss)
I0726 18:15:35.903684 31263 sgd_solver.cpp:138] Iteration 4880, lr = 0.001
I0726 18:16:05.505236 31263 solver.cpp:243] Iteration 4890, loss = 4.26676
I0726 18:16:05.505300 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.55463 (* 1 = 3.55463 loss)
I0726 18:16:05.505311 31263 sgd_solver.cpp:138] Iteration 4890, lr = 0.001
I0726 18:16:34.893563 31263 solver.cpp:243] Iteration 4900, loss = 4.26887
I0726 18:16:34.894152 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.60597 (* 1 = 4.60597 loss)
I0726 18:16:34.894163 31263 sgd_solver.cpp:138] Iteration 4900, lr = 0.001
I0726 18:17:04.403726 31263 solver.cpp:243] Iteration 4910, loss = 3.96866
I0726 18:17:04.403766 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.74018 (* 1 = 3.74018 loss)
I0726 18:17:04.403774 31263 sgd_solver.cpp:138] Iteration 4910, lr = 0.001
I0726 18:17:33.893025 31263 solver.cpp:243] Iteration 4920, loss = 4.23955
I0726 18:17:33.893208 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.72795 (* 1 = 4.72795 loss)
I0726 18:17:33.893218 31263 sgd_solver.cpp:138] Iteration 4920, lr = 0.001
I0726 18:18:03.260840 31263 solver.cpp:243] Iteration 4930, loss = 4.09359
I0726 18:18:03.260880 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.22225 (* 1 = 4.22225 loss)
I0726 18:18:03.260890 31263 sgd_solver.cpp:138] Iteration 4930, lr = 0.001
I0726 18:18:32.715401 31263 solver.cpp:243] Iteration 4940, loss = 4.14162
I0726 18:18:32.715617 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.71792 (* 1 = 3.71792 loss)
I0726 18:18:32.715627 31263 sgd_solver.cpp:138] Iteration 4940, lr = 0.001
I0726 18:19:02.416774 31263 solver.cpp:243] Iteration 4950, loss = 4.17883
I0726 18:19:02.416826 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.82972 (* 1 = 4.82972 loss)
I0726 18:19:02.416834 31263 sgd_solver.cpp:138] Iteration 4950, lr = 0.001
I0726 18:19:31.807809 31263 solver.cpp:243] Iteration 4960, loss = 4.1036
I0726 18:19:31.807885 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.36493 (* 1 = 4.36493 loss)
I0726 18:19:31.807896 31263 sgd_solver.cpp:138] Iteration 4960, lr = 0.001
I0726 18:20:01.287809 31263 solver.cpp:243] Iteration 4970, loss = 4.17554
I0726 18:20:01.287889 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.23749 (* 1 = 4.23749 loss)
I0726 18:20:01.287900 31263 sgd_solver.cpp:138] Iteration 4970, lr = 0.001
I0726 18:20:30.773735 31263 solver.cpp:243] Iteration 4980, loss = 4.12029
I0726 18:20:30.773855 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.84898 (* 1 = 3.84898 loss)
I0726 18:20:30.773865 31263 sgd_solver.cpp:138] Iteration 4980, lr = 0.001
I0726 18:21:00.224089 31263 solver.cpp:243] Iteration 4990, loss = 4.029
I0726 18:21:00.224145 31263 solver.cpp:259]     Train net output #0: mbox_loss = 3.9988 (* 1 = 3.9988 loss)
I0726 18:21:00.224159 31263 sgd_solver.cpp:138] Iteration 4990, lr = 0.001
I0726 18:21:26.824563 31263 solver.cpp:433] Iteration 5000, Testing net (#0)
I0726 18:21:26.824779 31263 net.cpp:693] Ignoring source layer mbox_loss
W0726 18:21:30.341106 31263 solver.cpp:524] Missing true_pos for label: 8
W0726 18:21:30.341259 31263 solver.cpp:524] Missing true_pos for label: 12
W0726 18:21:30.341353 31263 solver.cpp:524] Missing true_pos for label: 15
W0726 18:21:30.341559 31263 solver.cpp:524] Missing true_pos for label: 22
W0726 18:21:30.341567 31263 solver.cpp:524] Missing true_pos for label: 23
W0726 18:21:30.341634 31263 solver.cpp:524] Missing true_pos for label: 30
W0726 18:21:30.341722 31263 solver.cpp:524] Missing true_pos for label: 34
W0726 18:21:30.343046 31263 solver.cpp:524] Missing true_pos for label: 50
W0726 18:21:30.343077 31263 solver.cpp:524] Missing true_pos for label: 53
W0726 18:21:30.343114 31263 solver.cpp:524] Missing true_pos for label: 58
I0726 18:21:30.343122 31263 solver.cpp:546]     Test net output #0: detection_eval = 0.205629
I0726 18:21:32.865177 31263 solver.cpp:243] Iteration 5000, loss = 4.20979
I0726 18:21:32.865209 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.57298 (* 1 = 4.57298 loss)
I0726 18:21:32.865216 31263 sgd_solver.cpp:138] Iteration 5000, lr = 0.001
I0726 18:22:02.355624 31263 solver.cpp:243] Iteration 5010, loss = 4.19199
I0726 18:22:02.355726 31263 solver.cpp:259]     Train net output #0: mbox_loss = 4.96151 (* 1 = 4.96151 loss)
I0726 18:22:02.355741 31263 sgd_solver.cpp:138] Iteration 5010, lr = 0.001
